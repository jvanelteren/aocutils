{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp cfg\n",
    "from nbdev import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context free grammar\n",
    "\n",
    "> Takes a grammar, converts it into Chomsky Normal Form (CNF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from collections import defaultdict\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class CFG():\n",
    "    \"\"\"Takes a grammer as dict with tuple of options as values. Terminal values should not be in a tuple but as a string\n",
    "    Usage:\n",
    "        cfg = CFG(grammar_dict)\n",
    "            reverse as optional parameter when k,v are reversed\n",
    "            converts the grammar to Chomsky Normal form by taking care of options, unit productions and triplets\n",
    "        cfg.solve(messages_list) returns dict of substrings with possible rules to make them\n",
    "    \"\"\"\n",
    "    def __init__(self, grammar, terminals = None, reverse = True):\n",
    "        self.outcomes = defaultdict(set)\n",
    "        self.extra = 1\n",
    "        if not terminals:\n",
    "            print('no terminals specified!')\n",
    "            sys.exit()\n",
    "        self.terminals = terminals\n",
    "        self.grammar = grammar\n",
    "        # convert grammar to CNF and add terminals to outcomes\n",
    "        self.grammar_to_cnf(reverse)\n",
    "        assert all(isinstance(v, set) for k,v in self.grammar.items()), 'not all set'\n",
    "        assert all(isinstance(option, tuple) for k,v in self.grammar.items() for option in v), 'not all tuples'\n",
    "        assert all(isinstance(el, str) for k,v in self.grammar.items() for option in v for el in option), 'not all strings'\n",
    "        assert  all(1 <= len(option) <=2 for k,v in self.grammar.items() for option in v), 'len not 1 or 2'\n",
    "                    \n",
    "        self.finalgrammar = defaultdict(set)\n",
    "        for k,v in self.grammar.items():\n",
    "            for option in v:\n",
    "                self.finalgrammar[option].add(k)\n",
    "\n",
    "        for t in self.terminals:\n",
    "            if (t,) in self.finalgrammar:\n",
    "                self.outcomes[t] = self.finalgrammar[(t,)]\n",
    "\n",
    "\n",
    "        print('outcomes after grammar', self.outcomes)\n",
    "                \n",
    "\n",
    "\n",
    "    def grammar_to_cnf(self, reverse):\n",
    "        self.grammar = self.to_cnf_remove_options(self.grammar, reverse)\n",
    "        # eliminate unit rules\n",
    "        self.grammar = self.to_cnf_remove_triplets(self.grammar)\n",
    "        self.grammar = self.to_cnf_remove_unit_productions(self.grammar)\n",
    "\n",
    "    def to_cnf_remove_options(self, grammar, reverse):\n",
    "        # if reverse change from X : AB to AB : {X}\n",
    "        # if there are options, these are given a separate entry, e.g.\n",
    "        # X : (AB, CD) --> X: AB and X: CD\n",
    "        new_grammar = defaultdict(set)\n",
    "        \n",
    "        for k,v in grammar.items():\n",
    "            for option in v:\n",
    "                print(k,v, 'option', option)\n",
    "                new_grammar[k].add(option)\n",
    "        return new_grammar\n",
    "        \n",
    "    def to_cnf_remove_triplets(self, grammar):\n",
    "        # reduces triplets or larger to pairs\n",
    "        # changes X : ABC to\n",
    "        # X: AY, Y = BC\n",
    "        new_grammar = defaultdict(set)\n",
    "        for k,v in grammar.items():\n",
    "            for option in v:\n",
    "                if len(option) > 2:\n",
    "                    option = list(option)\n",
    "                    while len(option) > 2:\n",
    "                        new_grammar['extra' + str(self.extra)].add(tuple(option[1:3]))\n",
    "                        option[1:3] = ['extra' + str(self.extra)]\n",
    "                        self.extra += 1\n",
    "                    new_grammar[k].add(tuple(option))                    \n",
    "                else:\n",
    "                    new_grammar[k].add(option)\n",
    "        return new_grammar\n",
    "           \n",
    "    \n",
    "    def to_cnf_remove_unit_productions(self,grammar):\n",
    "        # step to get to Chomsky Normal Form\n",
    "        # if X : A, duplicate all A : Y with X : Y\n",
    "        found = True\n",
    "        while found:\n",
    "            found = False\n",
    "            for k,v in grammar.items():\n",
    "                to_remove = set()\n",
    "                singulars = {option[0] for option in v if len(option) == 1 and option[0] not in self.terminals}\n",
    "                if singulars:\n",
    "                    found = True\n",
    "                grammar[k] = {option for option in grammar[k] if len(option) != 1 or option[0] not in singulars}\n",
    "                for singular in singulars:\n",
    "                    grammar[k] |= grammar[singular]\n",
    "                        \n",
    "        return grammar\n",
    "\n",
    "    def pieces(self, test,l):\n",
    "        # gets all possibilities of len l out of a string\n",
    "        assert isinstance(test, str)\n",
    "        return {test[i:i+l] for i in range(len(test)-l+1) if test[i:i+l] not in self.outcomes}\n",
    "\n",
    "    def splitter(self,option):\n",
    "        # splits string into all options of two substrings\n",
    "        assert isinstance(option, str)\n",
    "        return {(option[:i], option[i:]) for i in range(1,len(option))}\n",
    "\n",
    "    def check_possible_option(self, option):\n",
    "        first = self.outcomes.get(option[0],set())\n",
    "        second = self.outcomes.get(option[1],set())\n",
    "        res = set()\n",
    "        for potential in product(first,second):\n",
    "            print('            this is a potential', potential)\n",
    "            if potential in self.finalgrammar:\n",
    "                print('             and found!')\n",
    "                res |= self.finalgrammar[potential]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def solve(self, messages):\n",
    "        # takes a list of messages and returns all possibilities for the substrings of m\n",
    "        # print(self.outcomes)\n",
    "        for num, m in enumerate(messages):\n",
    "            # print(m, len(m))\n",
    "            if num % 100 == 0: print(num*10, 'messages done')\n",
    "            for i in range(1,len(m)+1):\n",
    "                print(i)\n",
    "                for j in self.pieces(m, i):\n",
    "                    print('  ' + j)\n",
    "                    for k in self.splitter(j):\n",
    "                        print('    ', k)\n",
    "                        res = self.check_possible_option(k)\n",
    "                        if res:\n",
    "                            print('      yes')\n",
    "                            self.outcomes[j] |= res # this was a bug\n",
    "                            \n",
    "        print('finished all messages, returning dict')\n",
    "        return self.outcomes\n",
    "          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (('4', '1', '5'),) option ('4', '1', '5')\n",
      "1 (('2', '3'), ('3', '2')) option ('2', '3')\n",
      "1 (('2', '3'), ('3', '2')) option ('3', '2')\n",
      "2 (('4', '4'), ('5', '5')) option ('4', '4')\n",
      "2 (('4', '4'), ('5', '5')) option ('5', '5')\n",
      "3 (('4', '5'), ('5', '4')) option ('4', '5')\n",
      "3 (('4', '5'), ('5', '4')) option ('5', '4')\n",
      "4 (('a',),) option ('a',)\n",
      "5 (('b',),) option ('b',)\n",
      "outcomes after grammar defaultdict(<class 'set'>, {'a': {'4'}, 'b': {'5'}})\n",
      "0 messages done\n",
      "1\n",
      "2\n",
      "  ab\n",
      "     ('a', 'b')\n",
      "            this is a potential ('4', '5')\n",
      "             and found!\n",
      "      yes\n",
      "  bb\n",
      "     ('b', 'b')\n",
      "            this is a potential ('5', '5')\n",
      "             and found!\n",
      "      yes\n",
      "  ba\n",
      "     ('b', 'a')\n",
      "            this is a potential ('5', '4')\n",
      "             and found!\n",
      "      yes\n",
      "3\n",
      "  bab\n",
      "     ('ba', 'b')\n",
      "            this is a potential ('3', '5')\n",
      "     ('b', 'ab')\n",
      "            this is a potential ('5', '3')\n",
      "  aba\n",
      "     ('ab', 'a')\n",
      "            this is a potential ('3', '4')\n",
      "     ('a', 'ba')\n",
      "            this is a potential ('4', '3')\n",
      "  bbb\n",
      "     ('bb', 'b')\n",
      "            this is a potential ('2', '5')\n",
      "     ('b', 'bb')\n",
      "            this is a potential ('5', '2')\n",
      "  abb\n",
      "     ('ab', 'b')\n",
      "            this is a potential ('3', '5')\n",
      "     ('a', 'bb')\n",
      "            this is a potential ('4', '2')\n",
      "4\n",
      "  abab\n",
      "     ('a', 'bab')\n",
      "     ('aba', 'b')\n",
      "     ('ab', 'ab')\n",
      "            this is a potential ('3', '3')\n",
      "  abbb\n",
      "     ('ab', 'bb')\n",
      "            this is a potential ('3', '2')\n",
      "             and found!\n",
      "      yes\n",
      "     ('a', 'bbb')\n",
      "     ('abb', 'b')\n",
      "  babb\n",
      "     ('bab', 'b')\n",
      "     ('b', 'abb')\n",
      "     ('ba', 'bb')\n",
      "            this is a potential ('3', '2')\n",
      "             and found!\n",
      "      yes\n",
      "5\n",
      "  ababb\n",
      "     ('ab', 'abb')\n",
      "     ('abab', 'b')\n",
      "     ('aba', 'bb')\n",
      "     ('a', 'babb')\n",
      "            this is a potential ('4', '1')\n",
      "  babbb\n",
      "     ('ba', 'bbb')\n",
      "     ('bab', 'bb')\n",
      "     ('babb', 'b')\n",
      "            this is a potential ('1', '5')\n",
      "             and found!\n",
      "      yes\n",
      "     ('b', 'abbb')\n",
      "            this is a potential ('5', '1')\n",
      "6\n",
      "  ababbb\n",
      "     ('ab', 'abbb')\n",
      "            this is a potential ('3', '1')\n",
      "     ('aba', 'bbb')\n",
      "     ('a', 'babbb')\n",
      "            this is a potential ('4', 'extra1')\n",
      "             and found!\n",
      "      yes\n",
      "     ('ababb', 'b')\n",
      "     ('abab', 'bb')\n",
      "1\n",
      "2\n",
      "3\n",
      "  bab\n",
      "     ('ba', 'b')\n",
      "            this is a potential ('3', '5')\n",
      "     ('b', 'ab')\n",
      "            this is a potential ('5', '3')\n",
      "  aba\n",
      "     ('ab', 'a')\n",
      "            this is a potential ('3', '4')\n",
      "     ('a', 'ba')\n",
      "            this is a potential ('4', '3')\n",
      "4\n",
      "  baba\n",
      "     ('bab', 'a')\n",
      "     ('ba', 'ba')\n",
      "            this is a potential ('3', '3')\n",
      "     ('b', 'aba')\n",
      "  abab\n",
      "     ('a', 'bab')\n",
      "     ('aba', 'b')\n",
      "     ('ab', 'ab')\n",
      "            this is a potential ('3', '3')\n",
      "5\n",
      "  babab\n",
      "     ('b', 'abab')\n",
      "     ('bab', 'ab')\n",
      "     ('ba', 'bab')\n",
      "     ('baba', 'b')\n",
      "  ababa\n",
      "     ('ab', 'aba')\n",
      "     ('a', 'baba')\n",
      "     ('abab', 'a')\n",
      "     ('aba', 'ba')\n",
      "6\n",
      "  bababa\n",
      "     ('baba', 'ba')\n",
      "     ('ba', 'baba')\n",
      "     ('b', 'ababa')\n",
      "     ('babab', 'a')\n",
      "     ('bab', 'aba')\n",
      "1\n",
      "2\n",
      "3\n",
      "  bba\n",
      "     ('bb', 'a')\n",
      "            this is a potential ('2', '4')\n",
      "     ('b', 'ba')\n",
      "            this is a potential ('5', '3')\n",
      "  bab\n",
      "     ('ba', 'b')\n",
      "            this is a potential ('3', '5')\n",
      "     ('b', 'ab')\n",
      "            this is a potential ('5', '3')\n",
      "  bbb\n",
      "     ('bb', 'b')\n",
      "            this is a potential ('2', '5')\n",
      "     ('b', 'bb')\n",
      "            this is a potential ('5', '2')\n",
      "  abb\n",
      "     ('ab', 'b')\n",
      "            this is a potential ('3', '5')\n",
      "     ('a', 'bb')\n",
      "            this is a potential ('4', '2')\n",
      "4\n",
      "  bbba\n",
      "     ('bb', 'ba')\n",
      "            this is a potential ('2', '3')\n",
      "             and found!\n",
      "      yes\n",
      "     ('bbb', 'a')\n",
      "     ('b', 'bba')\n",
      "  bbab\n",
      "     ('b', 'bab')\n",
      "     ('bba', 'b')\n",
      "     ('bb', 'ab')\n",
      "            this is a potential ('2', '3')\n",
      "             and found!\n",
      "      yes\n",
      "5\n",
      "  abbba\n",
      "     ('abbb', 'a')\n",
      "            this is a potential ('1', '4')\n",
      "     ('ab', 'bba')\n",
      "     ('abb', 'ba')\n",
      "     ('a', 'bbba')\n",
      "            this is a potential ('4', '1')\n",
      "  bbbab\n",
      "     ('bbb', 'ab')\n",
      "     ('bb', 'bab')\n",
      "     ('b', 'bbab')\n",
      "            this is a potential ('5', '1')\n",
      "     ('bbba', 'b')\n",
      "            this is a potential ('1', '5')\n",
      "             and found!\n",
      "      yes\n",
      "6\n",
      "  abbbab\n",
      "     ('abb', 'bab')\n",
      "     ('a', 'bbbab')\n",
      "            this is a potential ('4', 'extra1')\n",
      "             and found!\n",
      "      yes\n",
      "     ('abbb', 'ab')\n",
      "            this is a potential ('1', '3')\n",
      "     ('ab', 'bbab')\n",
      "            this is a potential ('3', '1')\n",
      "     ('abbba', 'b')\n",
      "1\n",
      "2\n",
      "  aa\n",
      "     ('a', 'a')\n",
      "            this is a potential ('4', '4')\n",
      "             and found!\n",
      "      yes\n",
      "3\n",
      "  aab\n",
      "     ('aa', 'b')\n",
      "            this is a potential ('2', '5')\n",
      "     ('a', 'ab')\n",
      "            this is a potential ('4', '3')\n",
      "  aaa\n",
      "     ('a', 'aa')\n",
      "            this is a potential ('4', '2')\n",
      "     ('aa', 'a')\n",
      "            this is a potential ('2', '4')\n",
      "  bbb\n",
      "     ('bb', 'b')\n",
      "            this is a potential ('2', '5')\n",
      "     ('b', 'bb')\n",
      "            this is a potential ('5', '2')\n",
      "  abb\n",
      "     ('ab', 'b')\n",
      "            this is a potential ('3', '5')\n",
      "     ('a', 'bb')\n",
      "            this is a potential ('4', '2')\n",
      "4\n",
      "  aabb\n",
      "     ('aa', 'bb')\n",
      "            this is a potential ('2', '2')\n",
      "     ('aab', 'b')\n",
      "     ('a', 'abb')\n",
      "  aaab\n",
      "     ('aa', 'ab')\n",
      "            this is a potential ('2', '3')\n",
      "             and found!\n",
      "      yes\n",
      "     ('aaa', 'b')\n",
      "     ('a', 'aab')\n",
      "5\n",
      "  aaabb\n",
      "     ('aa', 'abb')\n",
      "     ('aaab', 'b')\n",
      "            this is a potential ('1', '5')\n",
      "             and found!\n",
      "      yes\n",
      "     ('a', 'aabb')\n",
      "     ('aaa', 'bb')\n",
      "  aabbb\n",
      "     ('a', 'abbb')\n",
      "            this is a potential ('4', '1')\n",
      "     ('aa', 'bbb')\n",
      "     ('aab', 'bb')\n",
      "     ('aabb', 'b')\n",
      "6\n",
      "  aaabbb\n",
      "     ('aaab', 'bb')\n",
      "            this is a potential ('1', '2')\n",
      "     ('aa', 'abbb')\n",
      "            this is a potential ('2', '1')\n",
      "     ('aaa', 'bbb')\n",
      "     ('aaabb', 'b')\n",
      "            this is a potential ('extra1', '5')\n",
      "     ('a', 'aabbb')\n",
      "1\n",
      "2\n",
      "3\n",
      "  aab\n",
      "     ('aa', 'b')\n",
      "            this is a potential ('2', '5')\n",
      "     ('a', 'ab')\n",
      "            this is a potential ('4', '3')\n",
      "  aaa\n",
      "     ('a', 'aa')\n",
      "            this is a potential ('4', '2')\n",
      "     ('aa', 'a')\n",
      "            this is a potential ('2', '4')\n",
      "  bbb\n",
      "     ('bb', 'b')\n",
      "            this is a potential ('2', '5')\n",
      "     ('b', 'bb')\n",
      "            this is a potential ('5', '2')\n",
      "  abb\n",
      "     ('ab', 'b')\n",
      "            this is a potential ('3', '5')\n",
      "     ('a', 'bb')\n",
      "            this is a potential ('4', '2')\n",
      "4\n",
      "  aabb\n",
      "     ('aa', 'bb')\n",
      "            this is a potential ('2', '2')\n",
      "     ('aab', 'b')\n",
      "     ('a', 'abb')\n",
      "  aaaa\n",
      "     ('aa', 'aa')\n",
      "            this is a potential ('2', '2')\n",
      "     ('a', 'aaa')\n",
      "     ('aaa', 'a')\n",
      "5\n",
      "  aabbb\n",
      "     ('a', 'abbb')\n",
      "            this is a potential ('4', '1')\n",
      "     ('aa', 'bbb')\n",
      "     ('aab', 'bb')\n",
      "     ('aabb', 'b')\n",
      "  aaaab\n",
      "     ('a', 'aaab')\n",
      "            this is a potential ('4', '1')\n",
      "     ('aa', 'aab')\n",
      "     ('aaaa', 'b')\n",
      "     ('aaa', 'ab')\n",
      "6\n",
      "  aaaabb\n",
      "     ('aa', 'aabb')\n",
      "     ('a', 'aaabb')\n",
      "            this is a potential ('4', 'extra1')\n",
      "             and found!\n",
      "      yes\n",
      "     ('aaaa', 'bb')\n",
      "     ('aaaab', 'b')\n",
      "     ('aaa', 'abb')\n",
      "  aaabbb\n",
      "     ('aaab', 'bb')\n",
      "            this is a potential ('1', '2')\n",
      "     ('aa', 'abbb')\n",
      "            this is a potential ('2', '1')\n",
      "     ('aaa', 'bbb')\n",
      "     ('aaabb', 'b')\n",
      "            this is a potential ('extra1', '5')\n",
      "     ('a', 'aabbb')\n",
      "7\n",
      "  aaaabbb\n",
      "     ('a', 'aaabbb')\n",
      "     ('aaaabb', 'b')\n",
      "            this is a potential ('0', '5')\n",
      "     ('aaa', 'abbb')\n",
      "     ('aaaab', 'bb')\n",
      "     ('aa', 'aabbb')\n",
      "     ('aaaa', 'bbb')\n",
      "finished all messages, returning dict\n"
     ]
    }
   ],
   "source": [
    "grammar = {'0': (('4', '1', '5'),),\n",
    " '1': (('2', '3'), ('3', '2')),\n",
    " '2': (('4', '4'), ('5', '5')),\n",
    " '3': (('4', '5'), ('5', '4')),\n",
    " '4': (('a',),),\n",
    " '5': (('b',),)}\n",
    "\n",
    "messages = ['ababbb', 'bababa', 'abbbab', 'aaabbb', 'aaaabbb']\n",
    "cfg = CFG(grammar, terminals = {'a', 'b'})\n",
    "out = cfg.solve(messages)\n",
    "assert sum([1 for m in messages if (m in out) and ('0' in out[m])]) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ar', 'B', 'Ca', 'F', 'P', 'Rn', 'Si', 'Th', 'Ti'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 (('138', '57'), ('12', '83')) option ('138', '57')\n",
      "97 (('138', '57'), ('12', '83')) option ('12', '83')\n",
      "131 (('20', '83'), ('74', '57')) option ('20', '83')\n",
      "131 (('20', '83'), ('74', '57')) option ('74', '57')\n",
      "7 (('57', '110'), ('83', '51')) option ('57', '110')\n",
      "7 (('57', '110'), ('83', '51')) option ('83', '51')\n",
      "48 (('17', '83'), ('56', '57')) option ('17', '83')\n",
      "48 (('17', '83'), ('56', '57')) option ('56', '57')\n",
      "2 (('83', '57'),) option ('83', '57')\n",
      "40 (('57', '101'), ('83', '93')) option ('57', '101')\n",
      "40 (('57', '101'), ('83', '93')) option ('83', '93')\n",
      "16 (('12', '83'), ('47', '57')) option ('12', '83')\n",
      "16 (('12', '83'), ('47', '57')) option ('47', '57')\n",
      "42 (('15', '83'), ('66', '57')) option ('15', '83')\n",
      "42 (('15', '83'), ('66', '57')) option ('66', '57')\n",
      "62 (('83', '134'), ('57', '18')) option ('83', '134')\n",
      "62 (('83', '134'), ('57', '18')) option ('57', '18')\n",
      "55 (('124', '57'), ('45', '83')) option ('124', '57')\n",
      "55 (('124', '57'), ('45', '83')) option ('45', '83')\n",
      "1 (('57', '116'), ('83', '93')) option ('57', '116')\n",
      "1 (('57', '116'), ('83', '93')) option ('83', '93')\n",
      "63 (('83', '1'), ('57', '32')) option ('83', '1')\n",
      "63 (('83', '1'), ('57', '32')) option ('57', '32')\n",
      "83 (('a',),) option ('a',)\n",
      "72 (('57', '83'), ('83', '83')) option ('57', '83')\n",
      "72 (('57', '83'), ('83', '83')) option ('83', '83')\n",
      "18 (('83', '57'), ('57', '83')) option ('83', '57')\n",
      "18 (('83', '57'), ('57', '83')) option ('57', '83')\n",
      "67 (('90', '83'), ('99', '57')) option ('90', '83')\n",
      "67 (('90', '83'), ('99', '57')) option ('99', '57')\n",
      "91 (('83', '108'), ('57', '72')) option ('83', '108')\n",
      "91 (('83', '108'), ('57', '72')) option ('57', '72')\n",
      "8 (('42',), ('42', '8')) option ('42',)\n",
      "8 (('42',), ('42', '8')) option ('42', '8')\n",
      "116 (('83', '18'), ('57', '72')) option ('83', '18')\n",
      "116 (('83', '18'), ('57', '72')) option ('57', '72')\n",
      "41 (('57', '83'),) option ('57', '83')\n",
      "130 (('57', '84'), ('83', '50')) option ('57', '84')\n",
      "130 (('57', '84'), ('83', '50')) option ('83', '50')\n",
      "26 (('57', '12'), ('83', '124')) option ('57', '12')\n",
      "26 (('57', '12'), ('83', '124')) option ('83', '124')\n",
      "103 (('134', '57'), ('45', '83')) option ('134', '57')\n",
      "103 (('134', '57'), ('45', '83')) option ('45', '83')\n",
      "39 (('83', '18'), ('57', '138')) option ('83', '18')\n",
      "39 (('83', '18'), ('57', '138')) option ('57', '138')\n",
      "46 (('83', '47'), ('57', '138')) option ('83', '47')\n",
      "46 (('83', '47'), ('57', '138')) option ('57', '138')\n",
      "129 (('57', '138'), ('83', '108')) option ('57', '138')\n",
      "129 (('57', '138'), ('83', '108')) option ('83', '108')\n",
      "58 (('108', '57'), ('72', '83')) option ('108', '57')\n",
      "58 (('108', '57'), ('72', '83')) option ('72', '83')\n",
      "138 (('57', '57'), ('83', '57')) option ('57', '57')\n",
      "138 (('57', '57'), ('83', '57')) option ('83', '57')\n",
      "49 (('58', '57'), ('26', '83')) option ('58', '57')\n",
      "49 (('58', '57'), ('26', '83')) option ('26', '83')\n",
      "133 (('57', '79'), ('83', '13')) option ('57', '79')\n",
      "133 (('57', '79'), ('83', '13')) option ('83', '13')\n",
      "125 (('83', '124'), ('57', '72')) option ('83', '124')\n",
      "125 (('83', '124'), ('57', '72')) option ('57', '72')\n",
      "123 (('105', '83'), ('134', '57')) option ('105', '83')\n",
      "123 (('105', '83'), ('134', '57')) option ('134', '57')\n",
      "128 (('45', '57'), ('2', '83')) option ('45', '57')\n",
      "128 (('45', '57'), ('2', '83')) option ('2', '83')\n",
      "24 (('83', '117'), ('57', '76')) option ('83', '117')\n",
      "24 (('83', '117'), ('57', '76')) option ('57', '76')\n",
      "86 (('57', '12'), ('83', '85')) option ('57', '12')\n",
      "86 (('57', '12'), ('83', '85')) option ('83', '85')\n",
      "76 (('107', '57'), ('123', '83')) option ('107', '57')\n",
      "76 (('107', '57'), ('123', '83')) option ('123', '83')\n",
      "70 (('83', '37'), ('57', '112')) option ('83', '37')\n",
      "70 (('83', '37'), ('57', '112')) option ('57', '112')\n",
      "51 (('83', '45'), ('57', '54')) option ('83', '45')\n",
      "51 (('83', '45'), ('57', '54')) option ('57', '54')\n",
      "37 (('47', '57'), ('72', '83')) option ('47', '57')\n",
      "37 (('47', '57'), ('72', '83')) option ('72', '83')\n",
      "9 (('57', '124'), ('83', '105')) option ('57', '124')\n",
      "9 (('57', '124'), ('83', '105')) option ('83', '105')\n",
      "61 (('57', '19'), ('83', '47')) option ('57', '19')\n",
      "61 (('57', '19'), ('83', '47')) option ('83', '47')\n",
      "75 (('108', '83'), ('105', '57')) option ('108', '83')\n",
      "75 (('108', '83'), ('105', '57')) option ('105', '57')\n",
      "120 (('83', '105'), ('57', '18')) option ('83', '105')\n",
      "120 (('83', '105'), ('57', '18')) option ('57', '18')\n",
      "124 (('57', '57'), ('83', '83')) option ('57', '57')\n",
      "124 (('57', '57'), ('83', '83')) option ('83', '83')\n",
      "4 (('41', '83'), ('12', '57')) option ('41', '83')\n",
      "4 (('41', '83'), ('12', '57')) option ('12', '57')\n",
      "0 (('8', '11'),) option ('8', '11')\n",
      "27 (('83', '41'),) option ('83', '41')\n",
      "89 (('57', '29'), ('83', '40')) option ('57', '29')\n",
      "89 (('57', '29'), ('83', '40')) option ('83', '40')\n",
      "111 (('54', '83'), ('18', '57')) option ('54', '83')\n",
      "111 (('54', '83'), ('18', '57')) option ('18', '57')\n",
      "12 (('57', '57'),) option ('57', '57')\n",
      "53 (('57', '52'), ('83', '73')) option ('57', '52')\n",
      "53 (('57', '52'), ('83', '73')) option ('83', '73')\n",
      "90 (('83', '130'), ('57', '48')) option ('83', '130')\n",
      "90 (('83', '130'), ('57', '48')) option ('57', '48')\n",
      "59 (('55', '83'), ('125', '57')) option ('55', '83')\n",
      "59 (('55', '83'), ('125', '57')) option ('125', '57')\n",
      "21 (('45', '83'), ('19', '57')) option ('45', '83')\n",
      "21 (('45', '83'), ('19', '57')) option ('19', '57')\n",
      "30 (('83', '7'), ('57', '70')) option ('83', '7')\n",
      "30 (('83', '7'), ('57', '70')) option ('57', '70')\n",
      "88 (('41', '57'), ('2', '83')) option ('41', '57')\n",
      "88 (('41', '57'), ('2', '83')) option ('2', '83')\n",
      "71 (('60', '57'), ('44', '83')) option ('60', '57')\n",
      "71 (('60', '57'), ('44', '83')) option ('44', '83')\n",
      "74 (('98', '57'), ('14', '83')) option ('98', '57')\n",
      "74 (('98', '57'), ('14', '83')) option ('14', '83')\n",
      "87 (('131', '57'), ('30', '83')) option ('131', '57')\n",
      "87 (('131', '57'), ('30', '83')) option ('30', '83')\n",
      "73 (('49', '83'), ('94', '57')) option ('49', '83')\n",
      "73 (('49', '83'), ('94', '57')) option ('94', '57')\n",
      "82 (('83', '41'), ('57', '138')) option ('83', '41')\n",
      "82 (('83', '41'), ('57', '138')) option ('57', '138')\n",
      "35 (('83', '22'), ('57', '89')) option ('83', '22')\n",
      "35 (('83', '22'), ('57', '89')) option ('57', '89')\n",
      "136 (('57', '105'), ('83', '108')) option ('57', '105')\n",
      "136 (('57', '105'), ('83', '108')) option ('83', '108')\n",
      "94 (('83', '129'), ('57', '86')) option ('83', '129')\n",
      "94 (('83', '129'), ('57', '86')) option ('57', '86')\n",
      "65 (('83', '72'), ('57', '108')) option ('83', '72')\n",
      "65 (('83', '72'), ('57', '108')) option ('57', '108')\n",
      "105 (('95', '95'),) option ('95', '95')\n",
      "77 (('83', '78'), ('57', '92')) option ('83', '78')\n",
      "77 (('83', '78'), ('57', '92')) option ('57', '92')\n",
      "19 (('83', '83'),) option ('83', '83')\n",
      "92 (('95', '138'),) option ('95', '138')\n",
      "104 (('18', '83'), ('124', '57')) option ('18', '83')\n",
      "104 (('18', '83'), ('124', '57')) option ('124', '57')\n",
      "43 (('83', '102'), ('57', '103')) option ('83', '102')\n",
      "43 (('83', '102'), ('57', '103')) option ('57', '103')\n",
      "99 (('115', '57'), ('23', '83')) option ('115', '57')\n",
      "99 (('115', '57'), ('23', '83')) option ('23', '83')\n",
      "135 (('83', '93'), ('57', '97')) option ('83', '93')\n",
      "135 (('83', '93'), ('57', '97')) option ('57', '97')\n",
      "23 (('81', '57'), ('69', '83')) option ('81', '57')\n",
      "23 (('81', '57'), ('69', '83')) option ('69', '83')\n",
      "115 (('83', '132'), ('57', '25')) option ('83', '132')\n",
      "115 (('83', '132'), ('57', '25')) option ('57', '25')\n",
      "110 (('85', '57'), ('18', '83')) option ('85', '57')\n",
      "110 (('85', '57'), ('18', '83')) option ('18', '83')\n",
      "52 (('83', '3'), ('57', '137')) option ('83', '3')\n",
      "52 (('83', '3'), ('57', '137')) option ('57', '137')\n",
      "3 (('68', '57'), ('106', '83')) option ('68', '57')\n",
      "3 (('68', '57'), ('106', '83')) option ('106', '83')\n",
      "15 (('35', '83'), ('53', '57')) option ('35', '83')\n",
      "15 (('35', '83'), ('53', '57')) option ('53', '57')\n",
      "106 (('41', '83'), ('85', '57')) option ('41', '83')\n",
      "106 (('41', '83'), ('85', '57')) option ('85', '57')\n",
      "60 (('113', '83'), ('24', '57')) option ('113', '83')\n",
      "60 (('113', '83'), ('24', '57')) option ('24', '57')\n",
      "93 (('12', '57'),) option ('12', '57')\n",
      "66 (('87', '83'), ('133', '57')) option ('87', '83')\n",
      "66 (('87', '83'), ('133', '57')) option ('133', '57')\n",
      "34 (('55', '83'), ('28', '57')) option ('55', '83')\n",
      "34 (('55', '83'), ('28', '57')) option ('28', '57')\n",
      "80 (('83', '41'), ('57', '85')) option ('83', '41')\n",
      "80 (('83', '41'), ('57', '85')) option ('57', '85')\n",
      "28 (('72', '57'), ('124', '83')) option ('72', '57')\n",
      "28 (('72', '57'), ('124', '83')) option ('124', '83')\n",
      "45 (('83', '57'), ('83', '83')) option ('83', '57')\n",
      "45 (('83', '57'), ('83', '83')) option ('83', '83')\n",
      "38 (('58', '57'), ('61', '83')) option ('58', '57')\n",
      "38 (('58', '57'), ('61', '83')) option ('61', '83')\n",
      "25 (('4', '83'), ('62', '57')) option ('4', '83')\n",
      "25 (('4', '83'), ('62', '57')) option ('62', '57')\n",
      "14 (('57', '124'), ('83', '138')) option ('57', '124')\n",
      "14 (('57', '124'), ('83', '138')) option ('83', '138')\n",
      "29 (('136', '83'), ('121', '57')) option ('136', '83')\n",
      "29 (('136', '83'), ('121', '57')) option ('121', '57')\n",
      "64 (('18', '83'), ('19', '57')) option ('18', '83')\n",
      "64 (('18', '83'), ('19', '57')) option ('19', '57')\n",
      "81 (('122', '57'), ('9', '83')) option ('122', '57')\n",
      "81 (('122', '57'), ('9', '83')) option ('9', '83')\n",
      "137 (('33', '83'), ('91', '57')) option ('33', '83')\n",
      "137 (('33', '83'), ('91', '57')) option ('91', '57')\n",
      "118 (('100', '57'), ('120', '83')) option ('100', '57')\n",
      "118 (('100', '57'), ('120', '83')) option ('120', '83')\n",
      "98 (('108', '57'), ('41', '83')) option ('108', '57')\n",
      "98 (('108', '57'), ('41', '83')) option ('41', '83')\n",
      "114 (('83', '72'), ('57', '45')) option ('83', '72')\n",
      "114 (('83', '72'), ('57', '45')) option ('57', '45')\n",
      "132 (('128', '57'), ('75', '83')) option ('128', '57')\n",
      "132 (('128', '57'), ('75', '83')) option ('75', '83')\n",
      "107 (('83', '134'), ('57', '72')) option ('83', '134')\n",
      "107 (('83', '134'), ('57', '72')) option ('57', '72')\n",
      "50 (('123', '83'), ('114', '57')) option ('123', '83')\n",
      "50 (('123', '83'), ('114', '57')) option ('114', '57')\n",
      "78 (('41', '83'), ('19', '57')) option ('41', '83')\n",
      "78 (('41', '83'), ('19', '57')) option ('19', '57')\n",
      "79 (('57', '118'), ('83', '77')) option ('57', '118')\n",
      "79 (('57', '118'), ('83', '77')) option ('83', '77')\n",
      "32 (('62', '57'), ('109', '83')) option ('62', '57')\n",
      "32 (('62', '57'), ('109', '83')) option ('109', '83')\n",
      "10 (('59', '83'), ('43', '57')) option ('59', '83')\n",
      "10 (('59', '83'), ('43', '57')) option ('43', '57')\n",
      "119 (('39', '57'), ('111', '83')) option ('39', '57')\n",
      "119 (('39', '57'), ('111', '83')) option ('111', '83')\n",
      "36 (('57', '134'), ('83', '41')) option ('57', '134')\n",
      "36 (('57', '134'), ('83', '41')) option ('83', '41')\n",
      "6 (('83', '2'), ('57', '138')) option ('83', '2')\n",
      "6 (('83', '2'), ('57', '138')) option ('57', '138')\n",
      "69 (('126', '83'), ('27', '57')) option ('126', '83')\n",
      "69 (('126', '83'), ('27', '57')) option ('27', '57')\n",
      "57 (('b',),) option ('b',)\n",
      "113 (('5', '83'), ('38', '57')) option ('5', '83')\n",
      "113 (('5', '83'), ('38', '57')) option ('38', '57')\n",
      "112 (('138', '83'), ('105', '57')) option ('138', '83')\n",
      "112 (('138', '83'), ('105', '57')) option ('105', '57')\n",
      "33 (('108', '83'), ('45', '57')) option ('108', '83')\n",
      "33 (('108', '83'), ('45', '57')) option ('45', '57')\n",
      "127 (('41', '57'), ('12', '83')) option ('41', '57')\n",
      "127 (('41', '57'), ('12', '83')) option ('12', '83')\n",
      "22 (('83', '34'), ('57', '119')) option ('83', '34')\n",
      "22 (('83', '34'), ('57', '119')) option ('57', '119')\n",
      "20 (('57', '127'), ('83', '80')) option ('57', '127')\n",
      "20 (('57', '127'), ('83', '80')) option ('83', '80')\n",
      "85 (('95', '57'), ('57', '83')) option ('95', '57')\n",
      "85 (('95', '57'), ('57', '83')) option ('57', '83')\n",
      "68 (('134', '57'), ('19', '83')) option ('134', '57')\n",
      "68 (('134', '57'), ('19', '83')) option ('19', '83')\n",
      "44 (('83', '63'), ('57', '10')) option ('83', '63')\n",
      "44 (('83', '63'), ('57', '10')) option ('57', '10')\n",
      "47 (('83', '95'), ('57', '57')) option ('83', '95')\n",
      "47 (('83', '95'), ('57', '57')) option ('57', '57')\n",
      "54 (('57', '57'), ('57', '83')) option ('57', '57')\n",
      "54 (('57', '57'), ('57', '83')) option ('57', '83')\n",
      "96 (('36', '57'), ('21', '83')) option ('36', '57')\n",
      "96 (('36', '57'), ('21', '83')) option ('21', '83')\n",
      "84 (('98', '57'), ('46', '83')) option ('98', '57')\n",
      "84 (('98', '57'), ('46', '83')) option ('46', '83')\n",
      "117 (('83', '16'), ('57', '65')) option ('83', '16')\n",
      "117 (('83', '16'), ('57', '65')) option ('57', '65')\n",
      "95 (('83',), ('57',)) option ('83',)\n",
      "95 (('83',), ('57',)) option ('57',)\n",
      "122 (('18', '83'), ('41', '57')) option ('18', '83')\n",
      "122 (('18', '83'), ('41', '57')) option ('41', '57')\n",
      "101 (('83', '41'), ('57', '72')) option ('83', '41')\n",
      "101 (('83', '41'), ('57', '72')) option ('57', '72')\n",
      "121 (('134', '57'), ('108', '83')) option ('134', '57')\n",
      "121 (('134', '57'), ('108', '83')) option ('108', '83')\n",
      "56 (('82', '83'), ('6', '57')) option ('82', '83')\n",
      "56 (('82', '83'), ('6', '57')) option ('6', '57')\n",
      "17 (('83', '88'), ('57', '93')) option ('83', '88')\n",
      "17 (('83', '88'), ('57', '93')) option ('57', '93')\n",
      "108 (('57', '95'), ('83', '83')) option ('57', '95')\n",
      "108 (('57', '95'), ('83', '83')) option ('83', '83')\n",
      "109 (('134', '83'), ('124', '57')) option ('134', '83')\n",
      "109 (('134', '83'), ('124', '57')) option ('124', '57')\n",
      "134 (('95', '83'), ('83', '57')) option ('95', '83')\n",
      "134 (('95', '83'), ('83', '57')) option ('83', '57')\n",
      "5 (('104', '83'), ('64', '57')) option ('104', '83')\n",
      "5 (('104', '83'), ('64', '57')) option ('64', '57')\n",
      "100 (('41', '83'), ('138', '57')) option ('41', '83')\n",
      "100 (('41', '83'), ('138', '57')) option ('138', '57')\n",
      "126 (('54', '83'), ('45', '57')) option ('54', '83')\n",
      "126 (('54', '83'), ('45', '57')) option ('45', '57')\n",
      "11 (('42', '31'), ('42', '11', '31')) option ('42', '31')\n",
      "11 (('42', '31'), ('42', '11', '31')) option ('42', '11', '31')\n",
      "13 (('57', '135'), ('83', '96')) option ('57', '135')\n",
      "13 (('57', '135'), ('83', '96')) option ('83', '96')\n",
      "31 (('83', '71'), ('57', '67')) option ('83', '71')\n",
      "31 (('83', '71'), ('57', '67')) option ('57', '67')\n",
      "102 (('19', '57'), ('72', '83')) option ('19', '57')\n",
      "102 (('19', '57'), ('72', '83')) option ('72', '83')\n",
      "outcomes after grammar defaultdict(<class 'set'>, {'a': {'83', '95'}, 'b': {'95', '57'}})\n",
      "0 messages done\n",
      "1000 messages done\n",
      "2000 messages done\n",
      "3000 messages done\n",
      "finished all messages, returning dict\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'97': {('12', '83'), ('138', '57')},\n",
       "             '131': {('20', '83'), ('74', '57')},\n",
       "             '7': {('57', '110'), ('83', '51')},\n",
       "             '48': {('17', '83'), ('56', '57')},\n",
       "             '2': {('83', '57')},\n",
       "             '40': {('57', '101'), ('83', '93')},\n",
       "             '16': {('12', '83'), ('47', '57')},\n",
       "             '42': {('15', '83'), ('66', '57')},\n",
       "             '62': {('57', '18'), ('83', '134')},\n",
       "             '55': {('124', '57'), ('45', '83')},\n",
       "             '1': {('57', '116'), ('83', '93')},\n",
       "             '63': {('57', '32'), ('83', '1')},\n",
       "             '83': {('a',)},\n",
       "             '72': {('57', '83'), ('83', '83')},\n",
       "             '18': {('57', '83'), ('83', '57')},\n",
       "             '67': {('90', '83'), ('99', '57')},\n",
       "             '91': {('57', '72'), ('83', '108')},\n",
       "             '8': {('15', '83'), ('42', '8'), ('66', '57')},\n",
       "             '116': {('57', '72'), ('83', '18')},\n",
       "             '41': {('57', '83')},\n",
       "             '130': {('57', '84'), ('83', '50')},\n",
       "             '26': {('57', '12'), ('83', '124')},\n",
       "             '103': {('134', '57'), ('45', '83')},\n",
       "             '39': {('57', '138'), ('83', '18')},\n",
       "             '46': {('57', '138'), ('83', '47')},\n",
       "             '129': {('57', '138'), ('83', '108')},\n",
       "             '58': {('108', '57'), ('72', '83')},\n",
       "             '138': {('57', '57'), ('83', '57')},\n",
       "             '49': {('26', '83'), ('58', '57')},\n",
       "             '133': {('57', '79'), ('83', '13')},\n",
       "             '125': {('57', '72'), ('83', '124')},\n",
       "             '123': {('105', '83'), ('134', '57')},\n",
       "             '128': {('2', '83'), ('45', '57')},\n",
       "             '24': {('57', '76'), ('83', '117')},\n",
       "             '86': {('57', '12'), ('83', '85')},\n",
       "             '76': {('107', '57'), ('123', '83')},\n",
       "             '70': {('57', '112'), ('83', '37')},\n",
       "             '51': {('57', '54'), ('83', '45')},\n",
       "             '37': {('47', '57'), ('72', '83')},\n",
       "             '9': {('57', '124'), ('83', '105')},\n",
       "             '61': {('57', '19'), ('83', '47')},\n",
       "             '75': {('105', '57'), ('108', '83')},\n",
       "             '120': {('57', '18'), ('83', '105')},\n",
       "             '124': {('57', '57'), ('83', '83')},\n",
       "             '4': {('12', '57'), ('41', '83')},\n",
       "             '0': {('8', '11')},\n",
       "             '27': {('83', '41')},\n",
       "             '89': {('57', '29'), ('83', '40')},\n",
       "             '111': {('18', '57'), ('54', '83')},\n",
       "             '12': {('57', '57')},\n",
       "             '53': {('57', '52'), ('83', '73')},\n",
       "             '90': {('57', '48'), ('83', '130')},\n",
       "             '59': {('125', '57'), ('55', '83')},\n",
       "             '21': {('19', '57'), ('45', '83')},\n",
       "             '30': {('57', '70'), ('83', '7')},\n",
       "             '88': {('2', '83'), ('41', '57')},\n",
       "             '71': {('44', '83'), ('60', '57')},\n",
       "             '74': {('14', '83'), ('98', '57')},\n",
       "             '87': {('131', '57'), ('30', '83')},\n",
       "             '73': {('49', '83'), ('94', '57')},\n",
       "             '82': {('57', '138'), ('83', '41')},\n",
       "             '35': {('57', '89'), ('83', '22')},\n",
       "             '136': {('57', '105'), ('83', '108')},\n",
       "             '94': {('57', '86'), ('83', '129')},\n",
       "             '65': {('57', '108'), ('83', '72')},\n",
       "             '105': {('95', '95')},\n",
       "             '77': {('57', '92'), ('83', '78')},\n",
       "             '19': {('83', '83')},\n",
       "             '92': {('95', '138')},\n",
       "             '104': {('124', '57'), ('18', '83')},\n",
       "             '43': {('57', '103'), ('83', '102')},\n",
       "             '99': {('115', '57'), ('23', '83')},\n",
       "             '135': {('57', '97'), ('83', '93')},\n",
       "             '23': {('69', '83'), ('81', '57')},\n",
       "             '115': {('57', '25'), ('83', '132')},\n",
       "             '110': {('18', '83'), ('85', '57')},\n",
       "             '52': {('57', '137'), ('83', '3')},\n",
       "             '3': {('106', '83'), ('68', '57')},\n",
       "             '15': {('35', '83'), ('53', '57')},\n",
       "             '106': {('41', '83'), ('85', '57')},\n",
       "             '60': {('113', '83'), ('24', '57')},\n",
       "             '93': {('12', '57')},\n",
       "             '66': {('133', '57'), ('87', '83')},\n",
       "             '34': {('28', '57'), ('55', '83')},\n",
       "             '80': {('57', '85'), ('83', '41')},\n",
       "             '28': {('124', '83'), ('72', '57')},\n",
       "             '45': {('83', '57'), ('83', '83')},\n",
       "             '38': {('58', '57'), ('61', '83')},\n",
       "             '25': {('4', '83'), ('62', '57')},\n",
       "             '14': {('57', '124'), ('83', '138')},\n",
       "             '29': {('121', '57'), ('136', '83')},\n",
       "             '64': {('18', '83'), ('19', '57')},\n",
       "             '81': {('122', '57'), ('9', '83')},\n",
       "             '137': {('33', '83'), ('91', '57')},\n",
       "             '118': {('100', '57'), ('120', '83')},\n",
       "             '98': {('108', '57'), ('41', '83')},\n",
       "             '114': {('57', '45'), ('83', '72')},\n",
       "             '132': {('128', '57'), ('75', '83')},\n",
       "             '107': {('57', '72'), ('83', '134')},\n",
       "             '50': {('114', '57'), ('123', '83')},\n",
       "             '78': {('19', '57'), ('41', '83')},\n",
       "             '79': {('57', '118'), ('83', '77')},\n",
       "             '32': {('109', '83'), ('62', '57')},\n",
       "             '10': {('43', '57'), ('59', '83')},\n",
       "             '119': {('111', '83'), ('39', '57')},\n",
       "             '36': {('57', '134'), ('83', '41')},\n",
       "             '6': {('57', '138'), ('83', '2')},\n",
       "             '69': {('126', '83'), ('27', '57')},\n",
       "             '57': {('b',)},\n",
       "             '113': {('38', '57'), ('5', '83')},\n",
       "             '112': {('105', '57'), ('138', '83')},\n",
       "             '33': {('108', '83'), ('45', '57')},\n",
       "             '127': {('12', '83'), ('41', '57')},\n",
       "             '22': {('57', '119'), ('83', '34')},\n",
       "             '20': {('57', '127'), ('83', '80')},\n",
       "             '85': {('57', '83'), ('95', '57')},\n",
       "             '68': {('134', '57'), ('19', '83')},\n",
       "             '44': {('57', '10'), ('83', '63')},\n",
       "             '47': {('57', '57'), ('83', '95')},\n",
       "             '54': {('57', '57'), ('57', '83')},\n",
       "             '96': {('21', '83'), ('36', '57')},\n",
       "             '84': {('46', '83'), ('98', '57')},\n",
       "             '117': {('57', '65'), ('83', '16')},\n",
       "             '95': {('a',), ('b',)},\n",
       "             '122': {('18', '83'), ('41', '57')},\n",
       "             '101': {('57', '72'), ('83', '41')},\n",
       "             '121': {('108', '83'), ('134', '57')},\n",
       "             '56': {('6', '57'), ('82', '83')},\n",
       "             '17': {('57', '93'), ('83', '88')},\n",
       "             '108': {('57', '95'), ('83', '83')},\n",
       "             '109': {('124', '57'), ('134', '83')},\n",
       "             '134': {('83', '57'), ('95', '83')},\n",
       "             '5': {('104', '83'), ('64', '57')},\n",
       "             '100': {('138', '57'), ('41', '83')},\n",
       "             '126': {('45', '57'), ('54', '83')},\n",
       "             '11': {('42', '31'), ('42', 'extra1')},\n",
       "             'extra1': {('11', '31')},\n",
       "             '13': {('57', '135'), ('83', '96')},\n",
       "             '31': {('57', '67'), ('83', '71')},\n",
       "             '102': {('19', '57'), ('72', '83')}})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://adventofcode.com/2020/day/19\n",
    "rules, messages = open('cfgloop.txt').read().split('\\n\\n')\n",
    "grammar = {}\n",
    "\n",
    "for rule in rules.split('\\n'):\n",
    "    num, makefrom = rule.split(': ')\n",
    "    makefrom = makefrom.replace('\"', '')\n",
    "    makefrom = tuple(makefrom.split(' | '))\n",
    "    makefrom = tuple(tuple(option.split()) for option in makefrom)\n",
    "    grammar[num] = makefrom\n",
    "    \n",
    "messages = messages.split('\\n')\n",
    "# messages = ['babbaaaabbbbbbabaaaaabbb']\n",
    "cfg = CFG(grammar, terminals = {'a', 'b'})\n",
    "res = cfg.solve(messages)\n",
    "sum('0' in v and k in messages for k,v in cfg.outcomes.items())\n",
    "cfg.grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C',\n",
       " 'Rn',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'B',\n",
       " 'P',\n",
       " 'Ti',\n",
       " 'Mg',\n",
       " 'Ar',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Mg',\n",
       " 'Ar',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Ca',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ti',\n",
       " 'Ti',\n",
       " 'B',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'F',\n",
       " 'Y',\n",
       " 'Ca',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'P',\n",
       " 'B',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'P',\n",
       " 'Ti',\n",
       " 'Rn',\n",
       " 'P',\n",
       " 'B',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Mg',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'P',\n",
       " 'Ti',\n",
       " 'B',\n",
       " 'P',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'B',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Ca',\n",
       " 'P',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'P',\n",
       " 'Mg',\n",
       " 'Y',\n",
       " 'Ca',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'P',\n",
       " 'Ti',\n",
       " 'Ti',\n",
       " 'Ti',\n",
       " 'B',\n",
       " 'P',\n",
       " 'B',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'P',\n",
       " 'Ti',\n",
       " 'B',\n",
       " 'P',\n",
       " 'B',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'B',\n",
       " 'P',\n",
       " 'B',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Ca',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'B',\n",
       " 'P',\n",
       " 'Rn',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Rn',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'B',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'P',\n",
       " 'B',\n",
       " 'P',\n",
       " 'Ti',\n",
       " 'Ti',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'P',\n",
       " 'Ti',\n",
       " 'B',\n",
       " 'Si',\n",
       " 'Al',\n",
       " 'Ar',\n",
       " 'P',\n",
       " 'B',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Mg',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Ca',\n",
       " 'F',\n",
       " 'Y',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Y',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Y',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'B',\n",
       " 'P',\n",
       " 'Mg',\n",
       " 'Ar',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'P',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ti',\n",
       " 'Rn',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Y',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'B',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Ti',\n",
       " 'Mg',\n",
       " 'Ar',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'P',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ti',\n",
       " 'Ti',\n",
       " 'Ti',\n",
       " 'Ti',\n",
       " 'B',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'F',\n",
       " 'Y',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'P',\n",
       " 'Ti',\n",
       " 'B',\n",
       " 'P',\n",
       " 'Ti',\n",
       " 'B',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Mg',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'F']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# https://adventofcode.com/2015/day/19\n",
    "rules, mol = open('cfg2.txt', 'r').read().split('\\n\\n')\n",
    "newrules = defaultdict(set)\n",
    "terminals = defaultdict(int)\n",
    "outcomes = defaultdict(set)\n",
    "counter = 1\n",
    "for line in rules.splitlines():\n",
    "    first, second = line.split(' => ')\n",
    "    molecules = tuple(re.findall('[A-Z][^A-Z]*', second))\n",
    "    if first not in terminals:\n",
    "        terminals[first] = str(counter)\n",
    "        counter += 1\n",
    "        \n",
    "    outcomes[''.join(molecules)] = {terminals[first]}\n",
    "    \n",
    "    for m in molecules:\n",
    "        if m not in terminals:\n",
    "            terminals[m] = str(counter)\n",
    "            counter += 1\n",
    "    molecules = tuple(terminals[m] for m in molecules)\n",
    "    newrules[terminals[first]].add(molecules)\n",
    "for k,v in terminals.items():\n",
    "    newrules[v].add(k)\n",
    "\n",
    "mollie = []\n",
    "prev = ''\n",
    "for ch in mol:\n",
    "    if ch.islower():\n",
    "        prev += ch\n",
    "    else:\n",
    "        if prev:\n",
    "            mollie.append(prev)\n",
    "        prev = ch\n",
    "    \n",
    "mollie.append(prev)\n",
    "mollie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'Rn', 'Ca', 'Ca', 'Ca', 'Si', 'Rn', 'B', 'P', 'Ti', 'Mg', 'Ar', 'Si', 'Rn', 'Si', 'Rn', 'Mg', 'Ar', 'Si', 'Rn', 'Ca', 'F', 'Ar', 'Ti', 'Ti', 'B', 'Si', 'Th', 'F', 'Y', 'Ca', 'F', 'Ar', 'Ca', 'Ca', 'Si', 'Th', 'Ca', 'P', 'B', 'Si', 'Th', 'Si', 'Th', 'Ca', 'Ca', 'P', 'Ti', 'Rn', 'P', 'B', 'Si', 'Th', 'Rn', 'F', 'Ar', 'Ar', 'Ca', 'Ca', 'Si', 'Th', 'Ca', 'Si', 'Th', 'Si', 'Rn', 'Mg', 'Ar', 'Ca', 'P', 'Ti', 'B', 'P', 'Rn', 'F', 'Ar', 'Si', 'Th', 'Ca', 'Si', 'Rn', 'F', 'Ar', 'B', 'Ca', 'Si', 'Rn', 'Ca', 'P', 'Rn', 'F', 'Ar', 'P', 'Mg', 'Y', 'Ca', 'F', 'Ar', 'Ca', 'P', 'Ti', 'Ti', 'Ti', 'B', 'P', 'B', 'Si', 'Th', 'Ca', 'P', 'Ti', 'B', 'P', 'B', 'Si', 'Rn', 'F', 'Ar', 'B', 'P', 'B', 'Si', 'Rn', 'Ca', 'F', 'Ar', 'B', 'P', 'Rn', 'Si', 'Rn', 'F', 'Ar', 'Rn', 'Si', 'Rn', 'B', 'F', 'Ar', 'Ca', 'F', 'Ar', 'Ca', 'Ca', 'Ca', 'Si', 'Th', 'Si', 'Th', 'Ca', 'Ca', 'P', 'B', 'P', 'Ti', 'Ti', 'Rn', 'F', 'Ar', 'Ca', 'P', 'Ti', 'B', 'Si', 'Al', 'Ar', 'P', 'B', 'Ca', 'Ca', 'Ca', 'Ca', 'Ca', 'Si', 'Rn', 'Mg', 'Ar', 'Ca', 'Si', 'Th', 'F', 'Ar', 'Th', 'Ca', 'Si', 'Th', 'Ca', 'Si', 'Rn', 'Ca', 'F', 'Y', 'Ca', 'Si', 'Rn', 'F', 'Y', 'F', 'Ar', 'F', 'Ar', 'Ca', 'Si', 'Rn', 'F', 'Y', 'F', 'Ar', 'Ca', 'Si', 'Rn', 'B', 'P', 'Mg', 'Ar', 'Si', 'Th', 'P', 'Rn', 'F', 'Ar', 'Ca', 'Si', 'Rn', 'F', 'Ar', 'Ti', 'Rn', 'Si', 'Rn', 'F', 'Y', 'F', 'Ar', 'Ca', 'Si', 'Rn', 'B', 'F', 'Ar', 'Ca', 'Si', 'Rn', 'Ti', 'Mg', 'Ar', 'Si', 'Th', 'Ca', 'Si', 'Th', 'Ca', 'F', 'Ar', 'P', 'Rn', 'F', 'Ar', 'Si', 'Rn', 'F', 'Ar', 'Ti', 'Ti', 'Ti', 'Ti', 'B', 'Ca', 'Ca', 'Si', 'Rn', 'Ca', 'Ca', 'F', 'Y', 'F', 'Ar', 'Si', 'Th', 'Ca', 'P', 'Ti', 'B', 'P', 'Ti', 'B', 'Ca', 'Si', 'Th', 'Si', 'Rn', 'Mg', 'Ar', 'Ca', 'F'] 295\n",
      "0 messages done\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class CYK():\n",
    "    def __init__(self, grammar, outcomes):\n",
    "        self.grammar = grammar\n",
    "        self.outcomes = outcomes\n",
    "            \n",
    "        self.finalgrammar = defaultdict(set)\n",
    "        for k,v in self.grammar.items():\n",
    "            for option in v:\n",
    "                self.finalgrammar[option].add(k)\n",
    "                \n",
    "    def pieces(self, test,l):\n",
    "        # gets all possibilities of len l out of a string\n",
    "        # assert isinstance(test, str)\n",
    "        return {''.join(test[i:i+l]) for i in range(len(test)-l+1) if ''.join(test[i:i+l]) not in self.outcomes}\n",
    "\n",
    "    def splitter(self,option):\n",
    "        # splits string into all options of two substrings\n",
    "        assert isinstance(option, str)\n",
    "        return {(option[:i], option[i:]) for i in range(1,len(option))}\n",
    "\n",
    "    def check_possible_option(self, option):\n",
    "        first = self.outcomes.get(option[0],set())\n",
    "        second = self.outcomes.get(option[1],set())\n",
    "        res = set()\n",
    "        for potential in product(first,second):\n",
    "            # print('            this is a potential', potential)\n",
    "            if potential in self.finalgrammar:\n",
    "                # print('             and found!')\n",
    "                res |= self.finalgrammar[potential]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def solve(self, messages):\n",
    "        # takes a list of messages and returns all possibilities for the substrings of m\n",
    "        # print(self.outcomes)\n",
    "        for num, m in enumerate(messages):\n",
    "            print(m, len(m))\n",
    "            if num % 100 == 0: print(num*10, 'messages done')\n",
    "            for i in range(1,len(m)+1):\n",
    "                print(i)\n",
    "                for j in self.pieces(m, i):\n",
    "                    # print('  ' + j)\n",
    "                    for k in self.splitter(j):\n",
    "                        # print('    ', k)\n",
    "                        res = self.check_possible_option(k)\n",
    "                        if res:\n",
    "                            # print('      yes')\n",
    "                            self.outcomes[j] |= res # this was a bug\n",
    "cyk = CYK(newrules, outcomes)\n",
    "cyk.solve([mollie])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = 'CRnCaCaCaSiRnBPTiMgArSiRnSiRnMgArSiRnCaFArTiTiBSiThFYCaFArCaCaSiThCaPBSiThSiThCaCaPTiRnPBSiThRnFArArCaCaSiThCaSiThSiRnMgArCaPTiBPRnFArSiThCaSiRnFArBCaSiRnCaPRnFArPMgYCaFArCaPTiTiTiBPBSiThCaPTiBPBSiRnFArBPBSiRnCaFArBPRnSiRnFArRnSiRnBFArCaFArCaCaCaSiThSiThCaCaPBPTiTiRnFArCaPTiBSiAlArPBCaCaCaCaCaSiRnMgArCaSiThFArThCaSiThCaSiRnCaFYCaSiRnFYFArFArCaSiRnFYFArCaSiRnBPMgArSiThPRnFArCaSiRnFArTiRnSiRnFYFArCaSiRnBFArCaSiRnTiMgArSiThCaSiThCaFArPRnFArSiRnFArTiTiTiTiBCaCaSiRnCaCaFYFArSiThCaPTiBPTiBCaSiThSiRnMgArCaF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"d:\\Programmeren\\adventofcode\\.aocenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Gebruiker\\AppData\\Local\\Temp\\ipykernel_29368\\672364784.py\", line -1, in <cell line: 7>\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Programmeren\\adventofcode\\.aocenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1993, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"d:\\Programmeren\\adventofcode\\.aocenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"d:\\Programmeren\\adventofcode\\.aocenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"d:\\Programmeren\\adventofcode\\.aocenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"d:\\Programmeren\\adventofcode\\.aocenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"d:\\Programmeren\\adventofcode\\.aocenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"d:\\Programmeren\\adventofcode\\.aocenv\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"d:\\Programmeren\\adventofcode\\.aocenv\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"d:\\Programmeren\\adventofcode\\.aocenv\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"d:\\Programmeren\\adventofcode\\.aocenv\\lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"d:\\Programmeren\\adventofcode\\.aocenv\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"d:\\Programmeren\\adventofcode\\.aocenv\\lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"d:\\Programmeren\\adventofcode\\.aocenv\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "all_molecules = []\n",
    "for line in rules.splitlines():\n",
    "    first, second = line.split(' => ')\n",
    "    all_molecules.append((first, second))\n",
    "all_molecules\n",
    "count = 0\n",
    "while (mol != 'e'):\n",
    "     for inp, out in all_molecules:\n",
    "          if out in mol:\n",
    "               count += mol.count(out)\n",
    "               mol = mol.replace(out, inp)\n",
    "               \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CRnXXXSiRnSiRnXFArMgYXFArXXXXXXXXXPRnXFArXXXXXXXXXXXSiRnXXFYXFArXXXXXXSiRnXFArTiRnPRnXXFArXXXXXXXXXXFArXXXXXXXFArThXXXSiRnXFYXFArXXXXXXXPRnXXXXXXXXXFArXXXSiRnXXFYFArXXXXXXXF'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chart[0]\n",
      "S0 gamma -> \\bullet S  [0, 0] [] dummy start state\n",
      "S1 S -> \\bullet NP VP  [0, 0] [] predictor\n",
      "S2 S -> \\bullet Aux NP VP  [0, 0] [] predictor\n",
      "S3 S -> \\bullet VP  [0, 0] [] predictor\n",
      "S4 NP -> \\bullet Det Nominal  [0, 0] [] predictor\n",
      "S5 NP -> \\bullet Proper-Noun  [0, 0] [] predictor\n",
      "S6 VP -> \\bullet Verb  [0, 0] [] predictor\n",
      "S7 VP -> \\bullet Verb NP  [0, 0] [] predictor\n",
      "\n",
      "Chart[1]\n",
      "S8 Verb -> book \\bullet [0, 1] [] scanner\n",
      "S9 VP -> Verb \\bullet [0, 1] [8] completer\n",
      "S10 VP -> Verb \\bullet NP  [0, 1] [8] completer\n",
      "S11 S -> VP \\bullet [0, 1] [9] completer\n",
      "S12 NP -> \\bullet Det Nominal  [1, 1] [] predictor\n",
      "S13 NP -> \\bullet Proper-Noun  [1, 1] [] predictor\n",
      "\n",
      "Chart[2]\n",
      "S14 Det -> that \\bullet [1, 2] [] scanner\n",
      "S15 NP -> Det \\bullet Nominal  [1, 2] [14] completer\n",
      "S16 Nominal -> \\bullet Noun  [2, 2] [] predictor\n",
      "S17 Nominal -> \\bullet Noun Nominal  [2, 2] [] predictor\n",
      "\n",
      "Chart[3]\n",
      "S18 Noun -> flight \\bullet [2, 3] [] scanner\n",
      "S19 Nominal -> Noun \\bullet [2, 3] [18] completer\n",
      "S20 Nominal -> Noun \\bullet Nominal  [2, 3] [18] completer\n",
      "S21 NP -> Det Nominal \\bullet [1, 3] [14, 19] completer\n",
      "S22 Nominal -> \\bullet Noun  [3, 3] [] predictor\n",
      "S23 Nominal -> \\bullet Noun Nominal  [3, 3] [] predictor\n",
      "S24 VP -> Verb NP \\bullet [0, 3] [8, 21] completer\n",
      "S25 Nominal -> Noun Nominal \\bullet [2, 3] [18, 22] completer\n",
      "S26 S -> VP \\bullet [0, 3] [24] completer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class State(object):\n",
    "    def __init__(self, label, rules, dot_idx, start_idx, end_idx, idx, made_from, producer):\n",
    "        self.label = label\n",
    "        self.rules = rules\n",
    "        self.dot_idx = dot_idx\n",
    "        self.start_idx = start_idx\n",
    "        self.end_idx = end_idx\n",
    "        self.idx = idx\n",
    "        self.made_from = made_from\n",
    "        self.producer = producer\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"Returns the tag after the dot\"\"\"\n",
    "        return self.rules[self.dot_idx]\n",
    "\n",
    "    def complete(self):\n",
    "        return len(self.rules) == self.dot_idx\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.label == other.label and\n",
    "                self.rules == other.rules and\n",
    "                self.dot_idx == other.dot_idx and\n",
    "                self.start_idx == other.start_idx and\n",
    "                self.end_idx == other.end_idx)\n",
    "\n",
    "    def __str__(self):\n",
    "        rule_string = ''\n",
    "        for i, rule in enumerate(self.rules):\n",
    "            if i == self.dot_idx:\n",
    "                rule_string += '\\\\bullet '\n",
    "            rule_string += rule + ' '\n",
    "        if self.dot_idx == len(self.rules):\n",
    "            rule_string += '\\\\bullet'\n",
    "        return 'S%d %s -> %s [%d, %d] %s %s' % (self.idx, self.label, rule_string, self.start_idx, \n",
    "                                                self.end_idx, self.made_from, self.producer)\n",
    "\n",
    "class Earley:\n",
    "    def __init__(self, words, grammar, terminals):\n",
    "        self.chart = [[] for _ in range(len(words) + 1)]\n",
    "        self.current_id = 0\n",
    "        self.words = words\n",
    "        self.grammar = grammar\n",
    "        self.terminals = terminals\n",
    "\n",
    "    def get_new_id(self):\n",
    "        self.current_id += 1\n",
    "        return self.current_id - 1\n",
    "\n",
    "    def is_terminal(self, tag):\n",
    "        return tag in self.terminals\n",
    "\n",
    "    def is_complete(self, state):\n",
    "        return len(state.rules) == state.dot_idx\n",
    "\n",
    "    def enqueue(self, state, chart_entry):\n",
    "        if state not in self.chart[chart_entry]:\n",
    "            self.chart[chart_entry].append(state)\n",
    "        else:\n",
    "            self.current_id -= 1\n",
    "\n",
    "    def predictor(self, state):\n",
    "        for production in self.grammar[state.next()]:\n",
    "            self.enqueue(State(state.next(), production, 0, state.end_idx, state.end_idx, self.get_new_id(), [], 'predictor'), state.end_idx)\n",
    "\n",
    "    def scanner(self, state):\n",
    "        if self.words[state.end_idx] in self.grammar[state.next()]:\n",
    "            self.enqueue(State(state.next(), [self.words[state.end_idx]], 1, state.end_idx, state.end_idx + 1, self.get_new_id(), [], 'scanner'), state.end_idx + 1)\n",
    "\n",
    "    def completer(self, state):\n",
    "        for s in self.chart[state.start_idx]:\n",
    "            if not s.complete() and s.next() == state.label and s.end_idx == state.start_idx and s.label != 'gamma':\n",
    "                self.enqueue(State(s.label, s.rules, s.dot_idx + 1, s.start_idx, state.end_idx, self.get_new_id(), s.made_from + [state.idx], 'completer'), state.end_idx)\n",
    "\n",
    "    def parse(self):\n",
    "        self.enqueue(State('gamma', ['S'], 0, 0, 0, self.get_new_id(), [], 'dummy start state'), 0)\n",
    "        \n",
    "        for i in range(len(self.words) + 1):\n",
    "            for state in self.chart[i]:\n",
    "                if not state.complete() and not self.is_terminal(state.next()):\n",
    "                    self.predictor(state)\n",
    "                elif i != len(self.words) and not state.complete() and self.is_terminal(state.next()):\n",
    "                    self.scanner(state)\n",
    "                else:\n",
    "                    self.completer(state)\n",
    "\n",
    "    def __str__(self):\n",
    "        res = ''\n",
    "        \n",
    "        for i, chart in enumerate(self.chart):\n",
    "            res += '\\nChart[%d]\\n' % i\n",
    "            for state in chart:\n",
    "                res += str(state) + '\\n'\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "def test():\n",
    "    grammar = {\n",
    "        'S':           [['NP', 'VP'], ['Aux', 'NP', 'VP'], ['VP']],\n",
    "        'NP':          [['Det', 'Nominal'], ['Proper-Noun']],\n",
    "        'Nominal':     [['Noun'], ['Noun', 'Nominal']],\n",
    "        'VP':          [['Verb'], ['Verb', 'NP']],\n",
    "        'Det':         ['that', 'this', 'a'],\n",
    "        'Noun':        ['book', 'flight', 'meal', 'money'],\n",
    "        'Verb':        ['book', 'include', 'prever'],\n",
    "        'Aux':         ['does'],\n",
    "        'Prep':        ['from', 'to', 'on'],\n",
    "        'Proper-Noun': ['Houston', 'TWA']\n",
    "    }\n",
    "    terminals = ['Det', 'Noun', 'Verb', 'Aux', 'Prep', 'Proper-Noun']\n",
    "\n",
    "    earley = Earley(['book', 'that', 'flight'], grammar, terminals)\n",
    "    earley.parse()\n",
    "    print(earley)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible = set()\n",
    "pnt = 0\n",
    "for pnt in range(len(mol)):\n",
    "    if mol[pnt].isupper():\n",
    "        right = pnt + 1\n",
    "        if pnt != len(mol) -1 and mol[pnt+1].islower():\n",
    "            right += 1\n",
    "        for option in newrules[mol[pnt:right]]:\n",
    "            antwoord = mol[:pnt] + ''.join(option) + mol[right:]\n",
    "            possible.add(antwoord)\n",
    "len(possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<D>\n",
      "<B>:= <D> |(0,-1)\n",
      "True\n",
      "{'<C>', '<A>'}\n",
      "<start>:= | <A> <B>(0,0)\n",
      "<start>:= | <A> <B>(0,0)\n",
      "<start>:= | <A> <B>(0,0)\n",
      "<A>:= | a <B> c(0,0)\n",
      "<A>:= | a <A>(0,0)\n",
      "<A>:= | a <B> c(0,0)\n",
      "<A>:= a | <B> c(0,1)\n",
      "<start>:= | <A> <B>(0,0)\n",
      "<A>:= | a <B> c(0,0)\n",
      "<A>:= | a <A>(0,0)\n",
      "a\n",
      "<A>:= a | <B> c(0,1)\n",
      "<A>:= a | <A>(0,1)\n",
      "<A>:= a | <B> c(0,1)\n",
      "<A>:= a | <A>(0,1)\n",
      "<B>:= | b <C>(1,1)\n",
      "<B>:= | <D>(1,1)\n",
      "<A>:= | a <B> c(1,1)\n",
      "<A>:= | a <A>(1,1)\n",
      "<D>:= | d(1,1)\n",
      "d chart[2]\n",
      "\n",
      "<D>:= d |(1,2)\n",
      "<D>:= d |(1,2)\n",
      "<B>:= <D> |(1,2)\n",
      "<A>:= a <B> | c(0,2)\n",
      "None chart[0]\n",
      "<start>:= | <A> <B>(0,0)\n",
      "<A>:= | a <B> c(0,0)\n",
      "<A>:= | a <A>(0,0) \n",
      "\n",
      "a chart[1]\n",
      "<A>:= a | <B> c(0,1)\n",
      "<A>:= a | <A>(0,1)\n",
      "<B>:= | b <C>(1,1)\n",
      "<B>:= | <D>(1,1)\n",
      "<A>:= | a <B> c(1,1)\n",
      "<A>:= | a <A>(1,1)\n",
      "<D>:= | d(1,1) \n",
      "\n",
      "d chart[2]\n",
      "<D>:= d |(1,2)\n",
      "<B>:= <D> |(1,2)\n",
      "<A>:= a <B> | c(0,2) \n",
      "\n",
      "c chart[3]\n",
      "<A>:= a <B> c |(0,3)\n",
      "<start>:= <A> | <B>(0,3)\n",
      "<B>:= | b <C>(3,3)\n",
      "<B>:= | <D>(3,3)\n",
      "<D>:= | d(3,3) \n",
      "\n",
      "d chart[4]\n",
      "<D>:= d |(3,4)\n",
      "<B>:= <D> |(3,4)\n",
      "<start>:= <A> <B> |(0,4) \n",
      "\n",
      "None chart[0]\n",
      "\n",
      "a chart[1]\n",
      "\n",
      "d chart[2]\n",
      "<D>:= d |(1,2)\n",
      "<B>:= <D> |(1,2)\n",
      "c chart[3]\n",
      "<A>:= a <B> c |(0,3)\n",
      "d chart[4]\n",
      "<D>:= d |(3,4)\n",
      "<B>:= <D> |(3,4)\n",
      "<start>:= <A> <B> |(0,4)\n",
      "<start>:= <A> <B> |(0,4)\n",
      "4 ['<start>:= <A> <B> |(0,4)']\n",
      "[['<A>', '<B>']]\n",
      "[['<B>:= <D> |(3,4)', 'n'], ['<A>:= a <B> c |(0,3)', 'n']]\n",
      "('<start>', [[(<__main__.State object at 0x0000020983793430>, 'n', [<__main__.Column object at 0x0000020983798880>, <__main__.Column object at 0x0000020981A6F5E0>, <__main__.Column object at 0x0000020983793FD0>, <__main__.Column object at 0x0000020983793D60>, <__main__.Column object at 0x0000020983793C10>]), (<__main__.State object at 0x00000209837936A0>, 'n', [<__main__.Column object at 0x0000020983798880>, <__main__.Column object at 0x0000020981A6F5E0>, <__main__.Column object at 0x0000020983793FD0>, <__main__.Column object at 0x0000020983793D60>, <__main__.Column object at 0x0000020983793C10>])]])\n",
      "<start>\n",
      "└─ <expr>\n",
      "    ├─ <expr>\n",
      "    │   ├─ <expr>\n",
      "    │   │   └─ <integer>\n",
      "    │   │       └─ <digits>\n",
      "    │   │           └─ <digit>\n",
      "    │   │               └─ '1'\n",
      "    │   ├─ '+'\n",
      "    │   └─ <expr>\n",
      "    │       └─ <integer>\n",
      "    │           └─ <digits>\n",
      "    │               └─ <digit>\n",
      "    │                   └─ '2'\n",
      "    ├─ '+'\n",
      "    └─ <expr>\n",
      "        └─ <integer>\n",
      "            └─ <digits>\n",
      "                └─ <digit>\n",
      "                    └─ '4'\n",
      "None\n",
      "<start>\n",
      "└─ <expr>\n",
      "    ├─ <expr>\n",
      "    │   ├─ <expr>\n",
      "    │   │   └─ <integer>\n",
      "    │   │       └─ <digits>\n",
      "    │   │           └─ <digit>\n",
      "    │   │               └─ '1'\n",
      "    │   ├─ '+'\n",
      "    │   └─ <expr>\n",
      "    │       └─ <integer>\n",
      "    │           └─ <digits>\n",
      "    │               └─ <digit>\n",
      "    │                   └─ '2'\n",
      "    ├─ '+'\n",
      "    └─ <expr>\n",
      "        └─ <integer>\n",
      "            └─ <digits>\n",
      "                └─ <digit>\n",
      "                    └─ '4'\n",
      "None\n",
      "<start>\n",
      "└─ <expr>\n",
      "    ├─ <expr>\n",
      "    │   ├─ <expr>\n",
      "    │   │   └─ <integer>\n",
      "    │   │       └─ <digits>\n",
      "    │   │           └─ <digit>\n",
      "    │   │               └─ '1'\n",
      "    │   ├─ '+'\n",
      "    │   └─ <expr>\n",
      "    │       └─ <integer>\n",
      "    │           └─ <digits>\n",
      "    │               └─ <digit>\n",
      "    │                   └─ '2'\n",
      "    ├─ '+'\n",
      "    └─ <expr>\n",
      "        └─ <integer>\n",
      "            └─ <digits>\n",
      "                └─ <digit>\n",
      "                    └─ '4'\n",
      "None\n",
      "<start>\n",
      "└─ <expr>\n",
      "    ├─ <expr>\n",
      "    │   └─ <integer>\n",
      "    │       └─ <digits>\n",
      "    │           └─ <digit>\n",
      "    │               └─ '1'\n",
      "    ├─ '+'\n",
      "    └─ <expr>\n",
      "        ├─ <expr>\n",
      "        │   └─ <integer>\n",
      "        │       └─ <digits>\n",
      "        │           └─ <digit>\n",
      "        │               └─ '2'\n",
      "        ├─ '+'\n",
      "        └─ <expr>\n",
      "            └─ <integer>\n",
      "                └─ <digits>\n",
      "                    └─ <digit>\n",
      "                        └─ '4'\n",
      "None\n",
      "recognized a\n",
      "Recursion error maximum recursion depth exceeded\n",
      "recognized a\n",
      "Recursion error maximum recursion depth exceeded\n",
      "a\n",
      "<start>\n",
      "└─ <query>\n",
      "    └─ <expr>\n",
      "        └─ 'a'\n",
      "None\n",
      "a\n",
      "<start>\n",
      "└─ <query>\n",
      "    └─ <expr>\n",
      "        └─ <expr>\n",
      "            └─ 'a'\n",
      "None\n",
      "a\n",
      "<start>\n",
      "└─ <query>\n",
      "    └─ <expr>\n",
      "        └─ 'a'\n",
      "None\n",
      "a\n",
      "<start>\n",
      "└─ <query>\n",
      "    └─ <expr>\n",
      "        └─ 'a'\n",
      "None\n",
      "a\n",
      "<start>\n",
      "└─ <query>\n",
      "    └─ <expr>\n",
      "        └─ <expr>\n",
      "            └─ <expr>\n",
      "                └─ 'a'\n",
      "None\n",
      "a\n",
      "<start>\n",
      "└─ <query>\n",
      "    └─ <expr>\n",
      "        └─ 'a'\n",
      "None\n",
      "a\n",
      "<start>\n",
      "└─ <query>\n",
      "    └─ <expr>\n",
      "        └─ <aexpr>\n",
      "            └─ <expr>\n",
      "                └─ 'a'\n",
      "None\n",
      "a\n",
      "<start>\n",
      "└─ <query>\n",
      "    └─ <expr>\n",
      "        └─ <aexpr>\n",
      "            └─ <expr>\n",
      "                └─ <aexpr>\n",
      "                    └─ <expr>\n",
      "                        └─ <aexpr>\n",
      "                            └─ <expr>\n",
      "                                └─ <aexpr>\n",
      "                                    └─ <expr>\n",
      "                                        └─ <aexpr>\n",
      "                                            └─ <expr>\n",
      "                                                └─ <aexpr>\n",
      "                                                    └─ <expr>\n",
      "                                                        └─ 'a'\n",
      "None\n",
      "a\n",
      "<start>\n",
      "└─ <query>\n",
      "    └─ <expr>\n",
      "        └─ <aexpr>\n",
      "            └─ <expr>\n",
      "                └─ 'a'\n",
      "None\n",
      "a\n",
      "<start>\n",
      "└─ <query>\n",
      "    └─ <expr>\n",
      "        └─ <aexpr>\n",
      "            └─ <expr>\n",
      "                └─ <aexpr>\n",
      "                    └─ <expr>\n",
      "                        └─ 'a'\n",
      "None\n",
      "<start>\n",
      "├─ <A>\n",
      "│   ├─ <A>\n",
      "│   │   ├─ <A>\n",
      "│   │   └─ 'a'\n",
      "│   └─ 'a'\n",
      "└─ 'a'\n",
      "None\n",
      "<start>\n",
      "└─ <A>\n",
      "    ├─ 'a'\n",
      "    └─ <A>\n",
      "        ├─ 'a'\n",
      "        └─ <A>\n",
      "            ├─ 'a'\n",
      "            └─ <A>\n",
      "None\n",
      "None chart[0]\n",
      "<start>:= | <A>(0,0)\n",
      "<A>:= | <A> a(0,0)\n",
      "<A>:= |(0,0)\n",
      "<start>:= <A> |(0,0)\n",
      "<A>:= <A> | a(0,0) \n",
      "\n",
      "a chart[1]\n",
      "<A>:= <A> a |(0,1)\n",
      "<start>:= <A> |(0,1)\n",
      "<A>:= <A> | a(0,1) \n",
      "\n",
      "a chart[2]\n",
      "<A>:= <A> a |(0,2)\n",
      "<start>:= <A> |(0,2)\n",
      "<A>:= <A> | a(0,2) \n",
      "\n",
      "a chart[3]\n",
      "<A>:= <A> a |(0,3)\n",
      "<start>:= <A> |(0,3)\n",
      "<A>:= <A> | a(0,3) \n",
      "\n",
      "a chart[4]\n",
      "<A>:= <A> a |(0,4)\n",
      "<start>:= <A> |(0,4)\n",
      "<A>:= <A> | a(0,4) \n",
      "\n",
      "a chart[5]\n",
      "<A>:= <A> a |(0,5)\n",
      "<start>:= <A> |(0,5)\n",
      "<A>:= <A> | a(0,5) \n",
      "\n",
      "a chart[6]\n",
      "<A>:= <A> a |(0,6)\n",
      "<start>:= <A> |(0,6)\n",
      "<A>:= <A> | a(0,6) \n",
      "\n",
      "None chart[0]\n",
      "<start>:= | <A>(0,0)\n",
      "<A>:= | a <A>(0,0)\n",
      "<A>:= |(0,0)\n",
      "<start>:= <A> |(0,0) \n",
      "\n",
      "a chart[1]\n",
      "<A>:= a | <A>(0,1)\n",
      "<A>:= | a <A>(1,1)\n",
      "<A>:= |(1,1)\n",
      "<A>:= a <A> |(0,1)\n",
      "<start>:= <A> |(0,1) \n",
      "\n",
      "a chart[2]\n",
      "<A>:= a | <A>(1,2)\n",
      "<A>:= | a <A>(2,2)\n",
      "<A>:= |(2,2)\n",
      "<A>:= a <A> |(1,2)\n",
      "<A>:= a <A> |(0,2)\n",
      "<start>:= <A> |(0,2) \n",
      "\n",
      "a chart[3]\n",
      "<A>:= a | <A>(2,3)\n",
      "<A>:= | a <A>(3,3)\n",
      "<A>:= |(3,3)\n",
      "<A>:= a <A> |(2,3)\n",
      "<A>:= a <A> |(1,3)\n",
      "<A>:= a <A> |(0,3)\n",
      "<start>:= <A> |(0,3) \n",
      "\n",
      "a chart[4]\n",
      "<A>:= a | <A>(3,4)\n",
      "<A>:= | a <A>(4,4)\n",
      "<A>:= |(4,4)\n",
      "<A>:= a <A> |(3,4)\n",
      "<A>:= a <A> |(2,4)\n",
      "<A>:= a <A> |(1,4)\n",
      "<A>:= a <A> |(0,4)\n",
      "<start>:= <A> |(0,4) \n",
      "\n",
      "a chart[5]\n",
      "<A>:= a | <A>(4,5)\n",
      "<A>:= | a <A>(5,5)\n",
      "<A>:= |(5,5)\n",
      "<A>:= a <A> |(4,5)\n",
      "<A>:= a <A> |(3,5)\n",
      "<A>:= a <A> |(2,5)\n",
      "<A>:= a <A> |(1,5)\n",
      "<A>:= a <A> |(0,5)\n",
      "<start>:= <A> |(0,5) \n",
      "\n",
      "a chart[6]\n",
      "<A>:= a | <A>(5,6)\n",
      "<A>:= | a <A>(6,6)\n",
      "<A>:= |(6,6)\n",
      "<A>:= a <A> |(5,6)\n",
      "<A>:= a <A> |(4,6)\n",
      "<A>:= a <A> |(3,6)\n",
      "<A>:= a <A> |(2,6)\n",
      "<A>:= a <A> |(1,6)\n",
      "<A>:= a <A> |(0,6)\n",
      "<start>:= <A> |(0,6) \n",
      "\n",
      "[('<D>:= d |(3,4)', '<B>:= | <D>(3,3)'), ('<B>:= <D> |(3,4)', '<start>:= <A> | <B>(0,3)'), ('<start>:= <A> <B> |(0,4)', 'None')]\n",
      "[('<A>:= a | <A>(5,6)', '<start>:= <A> |(0,-1)'), ('<A>:= | a <A>(6,6)', '<start>:= <A> |(0,-1)'), ('<A>:= |(6,6)', '<start>:= <A> |(0,-1)'), ('<A>:= a <A> |(5,6)', '<start>:= <A> |(0,-1)'), ('<start>:= <A> |(0,6)', 'None')]\n",
      "None chart[0]\n",
      "<start>:= | <A>(0,0)\n",
      "<A>:= | a <A>(0,0)\n",
      "<A>:= |(0,0)\n",
      "<start>:= <A> |(0,0) \n",
      "\n",
      "a chart[1]\n",
      "<A>:= a | <A>(0,1)\n",
      "<A>:= | a <A>(1,1)\n",
      "<A>:= |(1,1)\n",
      "<A>:= a <A> |(0,1)\n",
      "<start>:= <A> |(0,1) \n",
      "\n",
      "a chart[2]\n",
      "<A>:= a | <A>(1,2)\n",
      "<A>:= | a <A>(2,2)\n",
      "<A>:= |(2,2)\n",
      "<A>:= a <A> |(1,2)\n",
      "<start>:= <A> |(0,2) \n",
      "\n",
      "a chart[3]\n",
      "<A>:= a | <A>(2,3)\n",
      "<A>:= | a <A>(3,3)\n",
      "<A>:= |(3,3)\n",
      "<A>:= a <A> |(2,3)\n",
      "<start>:= <A> |(0,3) \n",
      "\n",
      "a chart[4]\n",
      "<A>:= a | <A>(3,4)\n",
      "<A>:= | a <A>(4,4)\n",
      "<A>:= |(4,4)\n",
      "<A>:= a <A> |(3,4)\n",
      "<start>:= <A> |(0,4) \n",
      "\n",
      "a chart[5]\n",
      "<A>:= a | <A>(4,5)\n",
      "<A>:= | a <A>(5,5)\n",
      "<A>:= |(5,5)\n",
      "<A>:= a <A> |(4,5)\n",
      "<start>:= <A> |(0,5) \n",
      "\n",
      "a chart[6]\n",
      "<A>:= a | <A>(5,6)\n",
      "<A>:= | a <A>(6,6)\n",
      "<A>:= |(6,6)\n",
      "<A>:= a <A> |(5,6)\n",
      "<start>:= <A> |(0,6) \n",
      "\n",
      "None chart[0]\n",
      "<start>:= | <A>(0,0)\n",
      "<A>:= | a b <A>(0,0)\n",
      "<A>:= |(0,0)\n",
      "<start>:= <A> |(0,0) \n",
      "\n",
      "a chart[1]\n",
      "<A>:= a | b <A>(0,1) \n",
      "\n",
      "b chart[2]\n",
      "<A>:= a b | <A>(0,2)\n",
      "<A>:= | a b <A>(2,2)\n",
      "<A>:= |(2,2)\n",
      "<A>:= a b <A> |(0,2)\n",
      "<start>:= <A> |(0,2) \n",
      "\n",
      "a chart[3]\n",
      "<A>:= a | b <A>(2,3) \n",
      "\n",
      "b chart[4]\n",
      "<A>:= a b | <A>(2,4)\n",
      "<A>:= | a b <A>(4,4)\n",
      "<A>:= |(4,4)\n",
      "<A>:= a b <A> |(2,4)\n",
      "<start>:= <A> |(0,4) \n",
      "\n",
      "a chart[5]\n",
      "<A>:= a | b <A>(4,5) \n",
      "\n",
      "b chart[6]\n",
      "<A>:= a b | <A>(4,6)\n",
      "<A>:= | a b <A>(6,6)\n",
      "<A>:= |(6,6)\n",
      "<A>:= a b <A> |(4,6)\n",
      "<start>:= <A> |(0,6) \n",
      "\n",
      "a chart[7]\n",
      "<A>:= a | b <A>(6,7) \n",
      "\n",
      "b chart[8]\n",
      "<A>:= a b | <A>(6,8)\n",
      "<A>:= | a b <A>(8,8)\n",
      "<A>:= |(8,8)\n",
      "<A>:= a b <A> |(6,8)\n",
      "<start>:= <A> |(0,8) \n",
      "\n",
      "a chart[9]\n",
      "<A>:= a | b <A>(8,9) \n",
      "\n",
      "b chart[10]\n",
      "<A>:= a b | <A>(8,10)\n",
      "<A>:= | a b <A>(10,10)\n",
      "<A>:= |(10,10)\n",
      "<A>:= a b <A> |(8,10)\n",
      "<start>:= <A> |(0,10) \n",
      "\n",
      "None chart[0]\n",
      "<start>:= | c <A>(0,0) \n",
      "\n",
      "c chart[1]\n",
      "<start>:= c | <A>(0,1)\n",
      "<A>:= | a b <A>(1,1)\n",
      "<A>:= |(1,1)\n",
      "<start>:= c <A> |(0,1) \n",
      "\n",
      "a chart[2]\n",
      "<A>:= a | b <A>(1,2) \n",
      "\n",
      "b chart[3]\n",
      "<A>:= a b | <A>(1,3)\n",
      "<A>:= | a b <A>(3,3)\n",
      "<A>:= |(3,3)\n",
      "<A>:= a b <A> |(1,3)\n",
      "<start>:= c <A> |(0,3) \n",
      "\n",
      "a chart[4]\n",
      "<A>:= a | b <A>(3,4) \n",
      "\n",
      "b chart[5]\n",
      "<A>:= a b | <A>(3,5)\n",
      "<A>:= | a b <A>(5,5)\n",
      "<A>:= |(5,5)\n",
      "<A>:= a b <A> |(3,5)\n",
      "<start>:= c <A> |(0,5) \n",
      "\n",
      "a chart[6]\n",
      "<A>:= a | b <A>(5,6) \n",
      "\n",
      "b chart[7]\n",
      "<A>:= a b | <A>(5,7)\n",
      "<A>:= | a b <A>(7,7)\n",
      "<A>:= |(7,7)\n",
      "<A>:= a b <A> |(5,7)\n",
      "<start>:= c <A> |(0,7) \n",
      "\n",
      "a chart[8]\n",
      "<A>:= a | b <A>(7,8) \n",
      "\n",
      "b chart[9]\n",
      "<A>:= a b | <A>(7,9)\n",
      "<A>:= | a b <A>(9,9)\n",
      "<A>:= |(9,9)\n",
      "<A>:= a b <A> |(7,9)\n",
      "<start>:= c <A> |(0,9) \n",
      "\n",
      "a chart[10]\n",
      "<A>:= a | b <A>(9,10) \n",
      "\n",
      "b chart[11]\n",
      "<A>:= a b | <A>(9,11)\n",
      "<A>:= | a b <A>(11,11)\n",
      "<A>:= |(11,11)\n",
      "<A>:= a b <A> |(9,11)\n",
      "<start>:= c <A> |(0,11) \n",
      "\n",
      "None chart[0]\n",
      "<start>:= | <A> c(0,0)\n",
      "<A>:= | a b <A>(0,0)\n",
      "<A>:= |(0,0)\n",
      "<start>:= <A> | c(0,0) \n",
      "\n",
      "a chart[1]\n",
      "<A>:= a | b <A>(0,1) \n",
      "\n",
      "b chart[2]\n",
      "<A>:= a b | <A>(0,2)\n",
      "<A>:= | a b <A>(2,2)\n",
      "<A>:= |(2,2)\n",
      "<A>:= a b <A> |(0,2)\n",
      "<start>:= <A> | c(0,2) \n",
      "\n",
      "a chart[3]\n",
      "<A>:= a | b <A>(2,3) \n",
      "\n",
      "b chart[4]\n",
      "<A>:= a b | <A>(2,4)\n",
      "<A>:= | a b <A>(4,4)\n",
      "<A>:= |(4,4)\n",
      "<A>:= a b <A> |(2,4)\n",
      "<A>:= a b <A> |(0,4)\n",
      "<start>:= <A> | c(0,4) \n",
      "\n",
      "a chart[5]\n",
      "<A>:= a | b <A>(4,5) \n",
      "\n",
      "b chart[6]\n",
      "<A>:= a b | <A>(4,6)\n",
      "<A>:= | a b <A>(6,6)\n",
      "<A>:= |(6,6)\n",
      "<A>:= a b <A> |(4,6)\n",
      "<A>:= a b <A> |(0,6)\n",
      "<start>:= <A> | c(0,6) \n",
      "\n",
      "a chart[7]\n",
      "<A>:= a | b <A>(6,7) \n",
      "\n",
      "b chart[8]\n",
      "<A>:= a b | <A>(6,8)\n",
      "<A>:= | a b <A>(8,8)\n",
      "<A>:= |(8,8)\n",
      "<A>:= a b <A> |(6,8)\n",
      "<A>:= a b <A> |(0,8)\n",
      "<start>:= <A> | c(0,8) \n",
      "\n",
      "c chart[9]\n",
      "<start>:= <A> c |(0,9) \n",
      "\n",
      "None chart[0]\n",
      "<start>:= | <A>(0,0)\n",
      "<A>:= | a b <B>(0,0)\n",
      "<A>:= |(0,0)\n",
      "<start>:= <A> |(0,0) \n",
      "\n",
      "a chart[1]\n",
      "<A>:= a | b <B>(0,1) \n",
      "\n",
      "b chart[2]\n",
      "<A>:= a b | <B>(0,2)\n",
      "<B>:= | <A>(2,2)\n",
      "<A>:= a b <B> |(0,2)\n",
      "<A>:= | a b <B>(2,2)\n",
      "<A>:= |(2,2)\n",
      "<B>:= <A> |(2,2)\n",
      "<start>:= <A> |(0,2) \n",
      "\n",
      "a chart[3]\n",
      "<A>:= a | b <B>(2,3) \n",
      "\n",
      "b chart[4]\n",
      "<A>:= a b | <B>(2,4)\n",
      "<B>:= | <A>(4,4)\n",
      "<A>:= a b <B> |(2,4)\n",
      "<A>:= | a b <B>(4,4)\n",
      "<A>:= |(4,4)\n",
      "<B>:= <A> |(4,4)\n",
      "<start>:= <A> |(0,4) \n",
      "\n",
      "a chart[5]\n",
      "<A>:= a | b <B>(4,5) \n",
      "\n",
      "b chart[6]\n",
      "<A>:= a b | <B>(4,6)\n",
      "<B>:= | <A>(6,6)\n",
      "<A>:= a b <B> |(4,6)\n",
      "<A>:= | a b <B>(6,6)\n",
      "<A>:= |(6,6)\n",
      "<B>:= <A> |(6,6)\n",
      "<start>:= <A> |(0,6) \n",
      "\n",
      "a chart[7]\n",
      "<A>:= a | b <B>(6,7) \n",
      "\n",
      "b chart[8]\n",
      "<A>:= a b | <B>(6,8)\n",
      "<B>:= | <A>(8,8)\n",
      "<A>:= a b <B> |(6,8)\n",
      "<A>:= | a b <B>(8,8)\n",
      "<A>:= |(8,8)\n",
      "<B>:= <A> |(8,8)\n",
      "<start>:= <A> |(0,8) \n",
      "\n",
      "None chart[0]\n",
      "<start>:= | <A>(0,0)\n",
      "<A>:= | a <B>(0,0)\n",
      "<A>:= |(0,0)\n",
      "<start>:= <A> |(0,0) \n",
      "\n",
      "a chart[1]\n",
      "<A>:= a | <B>(0,1)\n",
      "<B>:= | b <A>(1,1) \n",
      "\n",
      "b chart[2]\n",
      "<B>:= b | <A>(1,2)\n",
      "<A>:= | a <B>(2,2)\n",
      "<A>:= |(2,2)\n",
      "<B>:= b <A> |(1,2)\n",
      "<start>:= <A> |(0,2) \n",
      "\n",
      "a chart[3]\n",
      "<A>:= a | <B>(2,3)\n",
      "<B>:= | b <A>(3,3) \n",
      "\n",
      "b chart[4]\n",
      "<B>:= b | <A>(3,4)\n",
      "<A>:= | a <B>(4,4)\n",
      "<A>:= |(4,4)\n",
      "<B>:= b <A> |(3,4)\n",
      "<start>:= <A> |(0,4) \n",
      "\n",
      "a chart[5]\n",
      "<A>:= a | <B>(4,5)\n",
      "<B>:= | b <A>(5,5) \n",
      "\n",
      "b chart[6]\n",
      "<B>:= b | <A>(5,6)\n",
      "<A>:= | a <B>(6,6)\n",
      "<A>:= |(6,6)\n",
      "<B>:= b <A> |(5,6)\n",
      "<start>:= <A> |(0,6) \n",
      "\n",
      "a chart[7]\n",
      "<A>:= a | <B>(6,7)\n",
      "<B>:= | b <A>(7,7) \n",
      "\n",
      "b chart[8]\n",
      "<B>:= b | <A>(7,8)\n",
      "<A>:= | a <B>(8,8)\n",
      "<A>:= |(8,8)\n",
      "<B>:= b <A> |(7,8)\n",
      "<start>:= <A> |(0,8) \n",
      "\n",
      "None chart[0]\n",
      "<start>:= | <A>(0,0)\n",
      "<A>:= | a <A>(0,0)\n",
      "<A>:= | a(0,0) \n",
      "\n",
      "a chart[1]\n",
      "<A>:= a | <A>(0,1)\n",
      "<A>:= a |(0,1)\n",
      "<A>:= | a <A>(1,1)\n",
      "<A>:= | a(1,1)\n",
      "<start>:= <A> |(0,1) \n",
      "\n",
      "a chart[2]\n",
      "<A>:= a | <A>(1,2)\n",
      "<A>:= a |(1,2)\n",
      "<A>:= | a <A>(2,2)\n",
      "<A>:= | a(2,2)\n",
      "<start>:= <A> |(0,2) \n",
      "\n",
      "a chart[3]\n",
      "<A>:= a | <A>(2,3)\n",
      "<A>:= a |(2,3)\n",
      "<A>:= | a <A>(3,3)\n",
      "<A>:= | a(3,3)\n",
      "<start>:= <A> |(0,3) \n",
      "\n",
      "a chart[4]\n",
      "<A>:= a | <A>(3,4)\n",
      "<A>:= a |(3,4)\n",
      "<A>:= | a <A>(4,4)\n",
      "<A>:= | a(4,4)\n",
      "<start>:= <A> |(0,4) \n",
      "\n",
      "a chart[5]\n",
      "<A>:= a | <A>(4,5)\n",
      "<A>:= a |(4,5)\n",
      "<A>:= | a <A>(5,5)\n",
      "<A>:= | a(5,5)\n",
      "<start>:= <A> |(0,5) \n",
      "\n",
      "a chart[6]\n",
      "<A>:= a | <A>(5,6)\n",
      "<A>:= a |(5,6)\n",
      "<A>:= | a <A>(6,6)\n",
      "<A>:= | a(6,6)\n",
      "<start>:= <A> |(0,6) \n",
      "\n",
      "a chart[7]\n",
      "<A>:= a | <A>(6,7)\n",
      "<A>:= a |(6,7)\n",
      "<A>:= | a <A>(7,7)\n",
      "<A>:= | a(7,7)\n",
      "<start>:= <A> |(0,7) \n",
      "\n",
      "a chart[8]\n",
      "<A>:= a | <A>(7,8)\n",
      "<A>:= a |(7,8)\n",
      "<A>:= | a <A>(8,8)\n",
      "<A>:= | a(8,8)\n",
      "<start>:= <A> |(0,8) \n",
      "\n",
      "None chart[0]\n",
      "<start>:= | <A>(0,0)\n",
      "<A>:= | <A> a(0,0)\n",
      "<A>:= |(0,0)\n",
      "<start>:= <A> |(0,0)\n",
      "<A>:= <A> | a(0,0) \n",
      "\n",
      "a chart[1]\n",
      "<A>:= <A> a |(0,1)\n",
      "<start>:= <A> |(0,1)\n",
      "<A>:= <A> | a(0,1) \n",
      "\n",
      "a chart[2]\n",
      "<A>:= <A> a |(0,2)\n",
      "<start>:= <A> |(0,2)\n",
      "<A>:= <A> | a(0,2) \n",
      "\n",
      "a chart[3]\n",
      "<A>:= <A> a |(0,3)\n",
      "<start>:= <A> |(0,3)\n",
      "<A>:= <A> | a(0,3) \n",
      "\n",
      "a chart[4]\n",
      "<A>:= <A> a |(0,4)\n",
      "<start>:= <A> |(0,4)\n",
      "<A>:= <A> | a(0,4) \n",
      "\n",
      "a chart[5]\n",
      "<A>:= <A> a |(0,5)\n",
      "<start>:= <A> |(0,5)\n",
      "<A>:= <A> | a(0,5) \n",
      "\n",
      "a chart[6]\n",
      "<A>:= <A> a |(0,6)\n",
      "<start>:= <A> |(0,6)\n",
      "<A>:= <A> | a(0,6) \n",
      "\n",
      "None chart[0]\n",
      "<A>:= |(0,0)\n",
      "<start>:= <A> |(0,0)\n",
      "<A>:= a <A> |(0,1)\n",
      "<start>:= <A> |(0,1)\n",
      "<start>:= <A> |(0,2)\n",
      "<start>:= <A> |(0,3)\n",
      "<start>:= <A> |(0,4)\n",
      "<start>:= <A> |(0,5)\n",
      "<start>:= <A> |(0,6) \n",
      "\n",
      "a chart[1]\n",
      "<A>:= |(1,1)\n",
      "<A>:= a <A> |(1,2) \n",
      "\n",
      "a chart[2]\n",
      "<A>:= |(2,2)\n",
      "<A>:= a <A> |(2,3) \n",
      "\n",
      "a chart[3]\n",
      "<A>:= |(3,3)\n",
      "<A>:= a <A> |(3,4) \n",
      "\n",
      "a chart[4]\n",
      "<A>:= |(4,4)\n",
      "<A>:= a <A> |(4,5) \n",
      "\n",
      "a chart[5]\n",
      "<A>:= |(5,5)\n",
      "<A>:= a <A> |(5,6) \n",
      "\n",
      "a chart[6]\n",
      "<A>:= |(6,6) \n",
      "\n",
      "'aa'\n",
      "'aa'\n",
      "'bbbbbbb'\n",
      "'bbbbbbb'\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# published: true\n",
    "# title: Earley Parser\n",
    "# layout: post\n",
    "# comments: true\n",
    "# tags: parsing, context-free\n",
    "# categories: post\n",
    "# ---\n",
    "# TLDR; This tutorial is a complete implementation of Earley Parser in Python\n",
    "# with Leo's optimizations. The Python interpreter is embedded so that you can\n",
    "# work through the implementation steps.\n",
    "# \n",
    "# The *Earley* parsing algorithm was invented by Jay Earley [^earley1970an] in 1970. It\n",
    "# can be used to parse strings that conform to a context-free grammar. The\n",
    "# algorithm uses a chart for parsing -- that is, it is implemented as a dynamic\n",
    "# program relying on solving simpler sub-problems.\n",
    "# \n",
    "# Earley parsers are very appealing for a practitioner because they can use any\n",
    "# context-free grammar for parsing a string, and from the parse forest generated,\n",
    "# one can recover all (even an infinite number) of parse trees that correspond to\n",
    "# the given grammar. Unfortunately, this style of parsing pays for generality by\n",
    "# being slightly expensive. It takes $$O(n^3)$$ time to parse in the worst case.\n",
    "# However, if the grammar is unambiguous, it can parse in $$O(n^2)$$ time, and\n",
    "# all [LR(k)](https://en.wikipedia.org/wiki/LR_parser) grammars in linear time[^leo1991a] -- $$ O(n) $$.\n",
    "# \n",
    "# **This implementation of Earley parser correctly handles the epsilon case as\n",
    "# given by Aycock et al.[^aycock2002practical]** Further, **the `LeoParser` class\n",
    "# incorporates Leo's optimizations[^leo1991a]**.\n",
    "# \n",
    "# Another detailed explanation of Earley parsing is by\n",
    "# [Loup Vaillant](https://loup-vaillant.fr/tutorials/earley-parsing/).\n",
    "# Further, a fast industrial strength Earley parser implementation is\n",
    "# [Marpa](https://jeffreykegler.github.io/Marpa-web-site/).\n",
    "# \n",
    "# This post is written as runnable Python source. You can download the\n",
    "# notebook directly [here](https://github.com/rahulgopinath/rahulgopinath.github.io/blob/master/notebooks/2021-02-06-earley-parsing.py),\n",
    "# It the file is downloaded as `earleyparser.py`, it can be imported into your\n",
    "# projects using `import earleyparser`.\n",
    "#\n",
    "# ## Synopsis\n",
    "#\n",
    "# ```python\n",
    "# import earleyparser as P\n",
    "# my_grammar = {'<start>': [['1', '<A>'],\n",
    "#                           ['2']\n",
    "#                          ],\n",
    "#               '<A>'    : [['a']]}\n",
    "# my_parser = P.EarleyParser(my_grammar)\n",
    "# for tree in my_parser.parse_on(text='1a', start_symbol='<start>'):\n",
    "#     print(P.format_parsetree(tree))\n",
    "# ```\n",
    "# \n",
    "# ## Definitons\n",
    "# \n",
    "# For this post, we use the following terms:\n",
    "# \n",
    "# * The _alphabet_ is the set all of symbols in the input language. For example,\n",
    "#   in this post, we use all ASCII characters as alphabet.\n",
    "# * A _terminal_ is a single alphabet symbol. Note that this is slightly different\n",
    "#   from usual definitions (done here for ease of parsing). (Usually a terminal is\n",
    "#   a contiguous sequence of symbols from the alphabet. However, both kinds of\n",
    "#   grammars have a one to one correspondence, and can be converted easily.)\n",
    "# \n",
    "#   For example, `x` is a terminal symbol.\n",
    "# \n",
    "# * A _nonterminal_ is a symbol outside the alphabet whose expansion is _defined_\n",
    "#   in the grammar using _rules_ for expansion.\n",
    "# \n",
    "#   For example, `<term>` is a nonterminal in the below grammar.\n",
    "# \n",
    "# * A _rule_ is a finite sequence of _terms_ (two types of terms: terminals and\n",
    "#   nonterminals) that describe an expansion of a given terminal.\n",
    "# \n",
    "#   For example, `[<term>+<expr>]` is one of the expansion rules of the nonterminal `<expr>`.\n",
    "# \n",
    "# * A _definition_ is a set of _rules_ that describe the expansion of a given nonterminal.\n",
    "# \n",
    "#   For example, `[[<digit>,<digits>],[<digit>]]` is the definition of the nonterminal `<digits>`\n",
    "# \n",
    "# * A _context-free grammar_ is  composed of a set of nonterminals and \n",
    "#   corresponding definitions that define the structure of the nonterminal.\n",
    "# \n",
    "#   The grammar given below is an example context-free grammar.\n",
    "# \n",
    "# * A terminal _derives_ a string if the string contains only the symbols in the\n",
    "#   terminal. A nonterminal derives a string if the corresponding definition\n",
    "#   derives the string. A definition derives the  string if one of the rules in\n",
    "#   the definition derives the string. A rule derives a string if the sequence\n",
    "#   of terms that make up the rule can derive the string, deriving one substring \n",
    "#   after another contiguously (also called parsing).\n",
    "# \n",
    "# * A *derivation tree* is an ordered tree that describes how an input string is\n",
    "#   derived by the given start symbol. Also called a *parse tree*.\n",
    "# * A derivation tree can be collapsed into its string equivalent. Such a string\n",
    "#   can be parsed again by the nonterminal at the root node of the derivation\n",
    "#   tree such that at least one of the resulting derivation trees would be the\n",
    "#   same as the one we started with.\n",
    "# \n",
    "# As before, we use the [fuzzingbook](https://www.fuzzingbook.org) grammar style.\n",
    "# Here is an example grammar for arithmetic expressions, starting at `<start>`.\n",
    "# A terminal symbol has exactly one character\n",
    "# (Note that we disallow empty string (`''`) as a terminal symbol).\n",
    "# Secondly, as per traditional implementations,\n",
    "# there can only be one expansion rule for the `<start>` symbol. We work around\n",
    "# this restriction by simply constructing as many charts as there are expansion\n",
    "# rules, and returning all parse trees.\n",
    "\n",
    "grammar = {\n",
    "    '<start>': [['<expr>']],\n",
    "    '<expr>': [\n",
    "        ['<term>', '+', '<expr>'],\n",
    "        ['<term>', '-', '<expr>'],\n",
    "        ['<term>']],\n",
    "    '<term>': [\n",
    "        ['<fact>', '*', '<term>'],\n",
    "        ['<fact>', '/', '<term>'],\n",
    "        ['<fact>']],\n",
    "    '<fact>': [\n",
    "        ['<digits>'],\n",
    "        ['(','<expr>',')']],\n",
    "    '<digits>': [\n",
    "        ['<digit>','<digits>'],\n",
    "        ['<digit>']],\n",
    "    '<digit>': [[\"%s\" % str(i)] for i in range(10)],\n",
    "}\n",
    "START = '<start>'\n",
    "\n",
    "# Here is another grammar that targets the same language. Unlike the first\n",
    "# grammar, this grammar produces ambiguous parse results.\n",
    "\n",
    "a_grammar = {\n",
    "    '<start>': [['<expr>']],\n",
    "    '<expr>': [\n",
    "        ['<expr>', '+', '<expr>'],\n",
    "        ['<expr>', '-', '<expr>'],\n",
    "        ['<expr>', '*', '<expr>'],\n",
    "        ['<expr>', '/', '<expr>'],\n",
    "        ['(', '<expr>', ')'],\n",
    "        ['<integer>']],\n",
    "    '<integer>': [\n",
    "        ['<digits>']],\n",
    "    '<digits>': [\n",
    "        ['<digit>','<digits>'],\n",
    "        ['<digit>']],\n",
    "    '<digit>': [[\"%s\" % str(i)] for i in range(10)],\n",
    "}\n",
    "\n",
    "# ## Summary\n",
    "# \n",
    "# An Earley parser executes the following steps for parsing:\n",
    "# \n",
    "# Use `<start>` as the entry into parsing. At this point, we want to parse the\n",
    "# given string by the nonterminal `<start>`. The _definition_ of `<start>`\n",
    "# contains the possible expansion rule that can match the given string. Each\n",
    "# expansion rule can be thought of as a *parsing path*, with contiguous\n",
    "# substrings of the given input string matched by the particular terms in the\n",
    "# rule.\n",
    "# \n",
    "# * When given a nonterminal to match the string, the essential idea is to\n",
    "#   get the rules in the definition, and add them to the current set of\n",
    "#   parsing paths to try with the given string. Within the parsing path, we have\n",
    "#   a parsed index which denotes the progress of parsing that particular path\n",
    "#   (i.e the point till which the string until now has been recognized by that\n",
    "#   path, and any parents of this path). When a rule is newly added, this parsed\n",
    "#   index is set to zero.\n",
    "# \n",
    "# * We next look at our set of possible parsing paths, and check if any of these\n",
    "#   paths start with a nonterminal. If one is found, then for that parsing path to\n",
    "#   be completed with the given string, that nonterminal has to be recognized\n",
    "#   first. So, we add the expansion rules corresponding to that nonterminal to the\n",
    "#   list of possible parsing paths. We do this recursively.\n",
    "# \n",
    "# * Now, examine the current letter in the input. Then select all parsing paths\n",
    "#   that have that particular letter at the parsed index. These expressions can\n",
    "#   now advance one step to the next index. We add such parsing paths to the\n",
    "#   set of parsing paths to try for the next character.\n",
    "# \n",
    "# * While doing this, any parsing paths have finished parsing, fetch its\n",
    "#   corresponding nonterminal and advance all parsing paths that have that\n",
    "#   nonterminal at the parsing index.\n",
    "# \n",
    "# * Continue recursively until the parsing path corresponding to `<start>` has\n",
    "#   finished.\n",
    "# \n",
    "# \n",
    "# The chart parser depends on a chart (a table) for parsing. The columns\n",
    "# correspond to the characters in the input string. Each column represents a set\n",
    "# of *states*, and corresponds to the legal rules to follow from that point on.\n",
    "# \n",
    "# Say we start with the following grammar:\n",
    "\n",
    "sample_grammar = {\n",
    "    '<start>': [['<A>','<B>']],\n",
    "    '<A>': [['a', '<B>', 'c'], ['a', '<A>']],\n",
    "    '<B>': [['b', '<C>'], ['<D>']],\n",
    "    '<C>': [['c']],\n",
    "    '<D>': [['d']]\n",
    "}\n",
    "\n",
    "# Earley parser produces a table of possible parse paths at each letter index of\n",
    "# the table. Given an input `adcd`, we seed the column `0`  with:\n",
    "# \n",
    "# ```\n",
    "#    <start>: | <A> <B>\n",
    "# ```\n",
    "# \n",
    "# where the `|` represents the parsing index (also called the dot). This indicates\n",
    "# that we are at the starting, and the next step is to identify `<A>`. After this\n",
    "# rule is processed, the column would contain two more states\n",
    "# \n",
    "# ```\n",
    "#    <A>: | a <B> <c>\n",
    "#    <A>: | a <A>\n",
    "# ```\n",
    "# which represents two parsing paths to complete `<A>`.\n",
    "# \n",
    "# After processing of column `0` (which corresponds to input character `a`), we\n",
    "# would find the following in column `1` (which corresponds to the input character `b`)\n",
    "# \n",
    "# ```\n",
    "#    <A>: a | <B> c\n",
    "#    <A>: a | <A>\n",
    "#    <B>: | b <C>\n",
    "#    <B>: | <D>\n",
    "#    <A>: | a <B> c\n",
    "#    <A>: | a <A>\n",
    "#    <D>: | d\n",
    "# ```\n",
    "# \n",
    "# Similarly, the next column (column `2` corresponding to `d`) would contain the following.\n",
    "# \n",
    "# ```\n",
    "#    <D>: | d\n",
    "#    <B>: <D> |\n",
    "#    <A>: a <B> | c\n",
    "# ```\n",
    "# \n",
    "# Next, column `3` corresponding to `c` would contain:\n",
    "# ```\n",
    "#    <A>: a <B> c |\n",
    "#    <start>: <A> | <B>\n",
    "#    <B>: | <b> <C>\n",
    "#    <B>: | <D>\n",
    "#    <D>: | d\n",
    "# ```\n",
    "# \n",
    "# Finally, column `4` (`d`) would contain this at the end of processing.\n",
    "# ```\n",
    "#    <D>: d |\n",
    "#    <B>: <D> |\n",
    "#    <start>: <A> <B> |\n",
    "# ```\n",
    "# \n",
    "# This is how the table or the chart -- from where the parsing gets its name: chart parsing -- gets filled.\n",
    "# \n",
    "# ## The Column Data Structure\n",
    "# \n",
    "# The column contains a set of states. Each column corresponds\n",
    "# to a character (or a token if tokens are used).\n",
    "# Note that the states in a column corresponds to the parsing expression that will\n",
    "# occur once that character has been read. That is, the first column will\n",
    "# correspond to the parsing expression when no characters have been read.\n",
    "# \n",
    "# The column allows for adding states, and checks to prevent duplication of\n",
    "# states. Why do we need to prevent duplication? The problem is left recursion.\n",
    "# We need to detect and curtail left recursion, which is indicated by non-unique\n",
    "# states.\n",
    "\n",
    "class Column:\n",
    "    def __init__(self, index, letter):\n",
    "        self.index, self.letter = index, letter\n",
    "        self.states, self._unique = [], {}\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"%s chart[%d]\\n%s\" % (self.letter, self.index, \"\\n\".join(\n",
    "            str(state) for state in self.states if state.finished()))\n",
    "\n",
    "    def to_repr(self):\n",
    "        return \"%s chart[%d]\\n%s\" % (self.letter, self.index, \"\\n\".join(\n",
    "            str(state) for state in self.states))\n",
    "\n",
    "    def add(self, state):\n",
    "        if state in self._unique:\n",
    "            return self._unique[state]\n",
    "        self._unique[state] = state\n",
    "        self.states.append(state)\n",
    "        state.e_col = self\n",
    "        return self._unique[state]\n",
    "\n",
    "# ## The State Data Structure\n",
    "# \n",
    "# A state represents a parsing path (which corresponds to the nonterminal, and the\n",
    "# expansion rule that is being followed) with the current parsed index. \n",
    "# Each state contains the following:\n",
    "# \n",
    "# * name: The nonterminal that this rule represents.\n",
    "# * expr: The rule that is being followed\n",
    "# * dot:  The point till which parsing has happened in the rule.\n",
    "# * s_col: The starting point for this rule.\n",
    "# * e_col: The ending point for this rule.\n",
    "\n",
    "class State:\n",
    "    def __init__(self, name, expr, dot, s_col, e_col=None):\n",
    "        self.name, self.expr, self.dot = name, expr, dot\n",
    "        self.s_col, self.e_col = s_col, e_col\n",
    "\n",
    "    def finished(self):\n",
    "        return self.dot >= len(self.expr)\n",
    "\n",
    "    def at_dot(self):\n",
    "        return self.expr[self.dot] if self.dot < len(self.expr) else None\n",
    "\n",
    "    def __str__(self):\n",
    "        def idx(var):\n",
    "            return var.index if var else -1\n",
    "\n",
    "        return self.name + ':= ' + ' '.join([\n",
    "            str(p)\n",
    "            for p in [*self.expr[:self.dot], '|', *self.expr[self.dot:]]\n",
    "        ]) + \"(%d,%d)\" % (idx(self.s_col), idx(self.e_col))\n",
    "\n",
    "    def copy(self):\n",
    "        return State(self.name, self.expr, self.dot, self.s_col, self.e_col)\n",
    "\n",
    "    def _t(self):\n",
    "        return (self.name, self.expr, self.dot, self.s_col.index)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self._t())\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self._t() == other._t()\n",
    "\n",
    "    def advance(self):\n",
    "        return State(self.name, self.expr, self.dot + 1, self.s_col)\n",
    "\n",
    "# The convenience methods `finished()`, `advance()` and `at_dot()` should be\n",
    "# self explanatory. For example,\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    nt_name = '<B>'\n",
    "    nt_expr = tuple(sample_grammar[nt_name][1])\n",
    "    col_0 = Column(0, None)\n",
    "    a_state = State(nt_name, tuple(nt_expr), 0, col_0)\n",
    "    print(a_state.at_dot())\n",
    "\n",
    "# That is, the next symbol to be parsed is `<D>`, and if we advance it,\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    b_state = a_state.advance()\n",
    "    print(b_state)\n",
    "    print(b_state.finished())\n",
    "\n",
    "# ## The Basic Parser Interface\n",
    "# \n",
    "# We start with a bare minimum interface for a parser. It should allow one\n",
    "# to parse a given text using a given nonterminal (which should be present in\n",
    "# the grammar).\n",
    "\n",
    "class Parser:\n",
    "    def recognize_on(self, text, start_symbol):\n",
    "        raise NotImplemented()\n",
    "\n",
    "    def parse_on(self, text, start_symbol):\n",
    "        raise NotImplemented()\n",
    "\n",
    "# We now initialize the Earley parser, which is a parser.\n",
    "\n",
    "class EarleyParser(Parser):\n",
    "    def __init__(self, grammar, log = False, parse_exceptions = True, **kwargs):\n",
    "        self._grammar = grammar\n",
    "        self.epsilon = nullable(grammar)\n",
    "        self.log = log\n",
    "        self.parse_exceptions = parse_exceptions\n",
    "\n",
    "# ### Nonterminals Deriving Empty Strings\n",
    "# \n",
    "# Earley parser handles *nullable* nonterminals separately. A nullable\n",
    "# nonterminal is a nonterminal that can derive an empty string. That is\n",
    "# at least one of the expansion rules must derive an empty string. An\n",
    "# expansion rule derives an empty string if *all* of the tokens can\n",
    "# derive the empty string. This means no terminal symbols (assuming we\n",
    "# do not have zero width terminal symbols), and all nonterminal symbols\n",
    "# can derive empty string.\n",
    "# \n",
    "# In this implementation, we first initialize the list of first level\n",
    "# nullable nonterminals that contain an empty expansion. That is, they\n",
    "# directly derive the empty string.\n",
    "# Next, we remove any expansion rule that contains a token as these\n",
    "# expansion rules will not result in empty strings. Next, we start with\n",
    "# our current list of nullable nonterminals, take one at a time, and\n",
    "# remove them from the current expansion rules. If any expansion rule\n",
    "# becomes empty, the corresponding nonterminal is added to the nullable\n",
    "# nonterminal list. This continues until all nullable nonterminals\n",
    "# are processed.\n",
    "\n",
    "def is_nt(k):\n",
    "    return (k[0], k[-1]) == ('<', '>')\n",
    "\n",
    "def rem_terminals(g):\n",
    "    g_cur = {}\n",
    "    for k in g:\n",
    "        alts = []\n",
    "        for alt in g[k]:\n",
    "            ts = [t for t in alt if not is_nt(t)]\n",
    "            if not ts:\n",
    "                alts.append(alt)\n",
    "        if alts:\n",
    "            g_cur[k] = alts\n",
    "    return g_cur\n",
    "\n",
    "def nullable(g):\n",
    "    nullable_keys = {k for k in g if [] in g[k]}\n",
    "\n",
    "    unprocessed  = list(nullable_keys)\n",
    "\n",
    "    g_cur = rem_terminals(g)\n",
    "    while unprocessed:\n",
    "        nxt, *unprocessed = unprocessed\n",
    "        g_nxt = {}\n",
    "        for k in g_cur:\n",
    "            g_alts = []\n",
    "            for alt in g_cur[k]:\n",
    "                alt_ = [t for t in alt if t != nxt]\n",
    "                if not alt_:\n",
    "                    nullable_keys.add(k)\n",
    "                    unprocessed.append(k)\n",
    "                    break\n",
    "                else:\n",
    "                    g_alts.append(alt_)\n",
    "            if g_alts:\n",
    "                g_nxt[k] = g_alts\n",
    "        g_cur = g_nxt\n",
    "\n",
    "    return nullable_keys\n",
    "\n",
    "# An example\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    nullable_grammar = {\n",
    "        '<start>': [['<A>', '<B>']],\n",
    "        '<A>': [['a'], [], ['<C>']],\n",
    "        '<B>': [['b']],\n",
    "        '<C>': [['<A>'], ['<B>']]\n",
    "    }\n",
    "\n",
    "# Checking\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(nullable(nullable_grammar))\n",
    "\n",
    "# ## The Chart Parser\n",
    "# \n",
    "# Earley parser is a chart parser. That is, it relies on a table of solutions\n",
    "# to smaller problems. This table is called a chart (hence the name of such parsers -- chart parsers).\n",
    "#\n",
    "# ### The Chart Construction\n",
    "# \n",
    "# Here, we begin the chart construction by \n",
    "# seeding the chart with columns representing the tokens or characters.\n",
    "# Consider our example grammar again. The starting point is,\n",
    "# ```\n",
    "#    <start>: | <A> <B>\n",
    "# ```\n",
    "# We add this state to the `chart[0]` to start the parse. Note that the term\n",
    "# after dot is `<A>`, which will need to be recursively inserted to the column.\n",
    "# We will see how to do that later.\n",
    "# \n",
    "# *Note:* In traditional Earley parsing, the starting nonterminal always have\n",
    "# a single expansion rule. However, in many cases, you want to parse a fragment\n",
    "# and this rule makes it cumbersome to use Earley parsing. Hence, we have\n",
    "# opted to allow any nonterminal to be used as the starting nonterminal\n",
    "# irrespective of whether it has a single rule or not.\n",
    "# Interestingly, this does not have an impact on the parsing itself, but in\n",
    "# the extraction of results.\n",
    "# In essence, we seed *all* expansion rules into of the current start symbol\n",
    "# to the chart at `column 0`. We will take care of that difference while\n",
    "# building parse trees.\n",
    "\n",
    "class EarleyParser(EarleyParser):\n",
    "    def chart_parse(self, tokens, start, alts):\n",
    "        chart = [self.create_column(i, tok) for i, tok in enumerate([None, *tokens])]\n",
    "        for alt in alts:\n",
    "            chart[0].add(self.create_state(start, tuple(alt), 0, chart[0]))\n",
    "        return self.fill_chart(chart)\n",
    "\n",
    "    def create_column(self, i, tok): return Column(i, tok)\n",
    "\n",
    "    def create_state(self, sym, alt, num, col): return State(sym, alt, num, col)\n",
    "\n",
    "# We seed our initial state in the example\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ep = EarleyParser(sample_grammar)\n",
    "    ep.fill_chart = lambda s: s\n",
    "\n",
    "    v = ep.chart_parse(list('a'), START, sample_grammar[START])\n",
    "    print(v[0].states[0])\n",
    "\n",
    "# Then, we complete the chart. The idea here is to process one character or one\n",
    "# element at a time. At each character, we examine the current parse paths\n",
    "# (states) and continue forward any parse path that successfully parses the\n",
    "# letter. We process any state that is present in the current column in the\n",
    "# following fashion.\n",
    "# \n",
    "# There are three main methods we use: `predict()`, `scan()`, and `complete()`\n",
    "# \n",
    "# \n",
    "# #### Predict\n",
    "# \n",
    "# If in the current state, the term after the dot is a nonterminal, `predict()` is called. It\n",
    "# adds the expansion of the nonterminal to the current column.\n",
    "# \n",
    "# If the term is nullable, then we simply advance the current state, and\n",
    "# add that to the current column. This fix to the original Earley parsing\n",
    "# was suggested by Aycock et al.[^aycock2002practical].\n",
    "\n",
    "class EarleyParser(EarleyParser):\n",
    "    def predict(self, col, sym, state):\n",
    "        for alt in self._grammar[sym]:\n",
    "            col.add(self.create_state(sym, tuple(alt), 0, col))\n",
    "        if sym in self.epsilon:\n",
    "            col.add(state.advance())\n",
    "\n",
    "# If we look our example, we have seeded the first column with `| <A> <B>`. Now,\n",
    "# `fill_chart()` will find that the next term is `<A>` and call `predict()`\n",
    "# which will then add the expansions of `<A>`.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ep = EarleyParser(sample_grammar)\n",
    "    ep.fill_chart = lambda s: s\n",
    "\n",
    "    chart = ep.chart_parse(list('a'), START, sample_grammar[START])\n",
    "\n",
    "    for s in chart[0].states:\n",
    "        print(s)\n",
    "\n",
    "# Next, we apply predict.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ep.predict(chart[0], '<A>', s)\n",
    "    for s in chart[0].states:\n",
    "        print(s)\n",
    "\n",
    "# As you can see, the two rules of `<A>` has been added to\n",
    "# the current column.\n",
    "\n",
    "# #### Scan\n",
    "# \n",
    "# The `scan()` method is called if the next symbol in the current state is a terminal symbol. If the\n",
    "# state matches the next term, moves the dot one position, and adds the new\n",
    "# state to the column.\n",
    "# \n",
    "# For example, consider this state.\n",
    "# ```\n",
    "#    <B>: | b c\n",
    "# ```\n",
    "# If we scan the next column's letter, and that letter is `b`, then it matches the\n",
    "# next symbol. So, we can advance the state by one symbol, and add it to the next\n",
    "# column.\n",
    "# ```\n",
    "#    <B>: b | c\n",
    "# ```\n",
    " \n",
    "class EarleyParser(EarleyParser):\n",
    "    def scan(self, col, state, letter):\n",
    "        if letter == col.letter:\n",
    "            col.add(state.advance())\n",
    "\n",
    "# Here is our continuing example.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ep = EarleyParser(sample_grammar)\n",
    "    ep.fill_chart = lambda s: s\n",
    "\n",
    "    chart = ep.chart_parse(list('a'), START, sample_grammar[START])\n",
    "    ep.predict(chart[0], '<A>', s)\n",
    "\n",
    "    new_state = chart[0].states[1]\n",
    "    print(new_state)\n",
    "\n",
    "    ep.scan(chart[1], new_state, 'a')\n",
    "    for s in chart[1].states:\n",
    "        print(s)\n",
    "\n",
    "# As you can see, the `state[1]` in `chart[0]` that was waiting for `a` has\n",
    "# advanced one letter after consuming `a`, and has been added to `chart[1]`.\n",
    "\n",
    "# #### Complete\n",
    "# \n",
    "# The `complete()` method is called if a particular state has finished the rule\n",
    "# during execution. It first extracts the start column of the finished state, then\n",
    "# for all states in the start column that is not finished, find the states that\n",
    "# were parsing this current state (that is, we can go back to continue to parse\n",
    "# those rules now). Next, shift them by one position, and add them to the current\n",
    "# column.\n",
    "# \n",
    "# For example, say the state we have is:\n",
    "# ```\n",
    "#    <A>: a | <B> c\n",
    "#    <B>: b c |\n",
    "# ```\n",
    "# The state `<B> b c |` is complete, and we need to advance any state that\n",
    "# has `<B>` at the dot to one index forward, which is `<A>: a <B> | c`\n",
    "# \n",
    "# How do we determine the parent states? During predict, we added the predicted\n",
    "# child states to the same column as that of the inspected state. So, the states\n",
    "# will be found in the starting column of the current state, with the same symbol\n",
    "# at_dot as that of the name of the completed state.\n",
    "# \n",
    "# We advance all such parents (producing new states) and add the new states to the\n",
    "# current column.\n",
    "\n",
    "class EarleyParser(EarleyParser):\n",
    "    def complete(self, col, state):\n",
    "        parent_states = [st for st in state.s_col.states\n",
    "                 if st.at_dot() == state.name]\n",
    "        for st in parent_states:\n",
    "            col.add(st.advance())\n",
    "\n",
    "# Here is our example. We start parsing `ad`. So, we have three columns.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ep = EarleyParser(sample_grammar)\n",
    "    ep.fill_chart = lambda s: s\n",
    "\n",
    "    chart = ep.chart_parse(list('ad'), START, sample_grammar[START])\n",
    "    ep.predict(chart[0], '<A>', s)\n",
    "    for s in chart[0].states:\n",
    "        print(s)\n",
    "\n",
    "# Next, we populate column 1 which corresponds to letter `a`.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(chart[1].letter)\n",
    "    for state in chart[0].states:\n",
    "        if state.at_dot() not in sample_grammar:\n",
    "            ep.scan(chart[1], state, 'a')\n",
    "    for s in chart[1].states:\n",
    "        print(s)\n",
    "\n",
    "# You can see that the two states are waiting on `<A>` and `<B>`\n",
    "# respectively at `at_dot()`.\n",
    "# Hence, we run predict again to add the corresponding rules of `<A>` and `<B>`\n",
    "# to the current column.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for state in chart[1].states:\n",
    "        if state.at_dot() in sample_grammar:\n",
    "            ep.predict(chart[1], state.at_dot(), state)\n",
    "    for s in chart[1].states:\n",
    "        print(s)\n",
    "\n",
    "# As you can see, we have a list of states that are waiting\n",
    "# for `b`, `a` and `d`.\n",
    "\n",
    "# Our next letter is:\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(chart[2])\n",
    "\n",
    "# We scan to populate `column 2`.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for state in chart[1].states:\n",
    "        if state.at_dot() not in sample_grammar:\n",
    "            ep.scan(chart[2], state, state.at_dot())\n",
    "\n",
    "    for s in chart[2].states:\n",
    "        print(s)\n",
    "\n",
    "# As we expected, only `<D>` could advance to the next column (`chart[2]`)\n",
    "# after reading `d`\n",
    "\n",
    "# Finally, we use complete, so that we can advance the parents of the `<D>` state above.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for state in chart[2].states:\n",
    "        if state.finished():\n",
    "            ep.complete(chart[2], state)\n",
    "\n",
    "    for s in chart[2].states:\n",
    "        print(s)\n",
    "\n",
    "# As you can see, that led to `<B>` being complete, and since `<B>` is\n",
    "# complete, `<A>` also becomes complete.\n",
    "\n",
    "# ### Filling The Chart\n",
    "# \n",
    "# In the below algorithm, whenever the `at_dot()` is at a nonterminal\n",
    "# symbol, the expansion rules of that nonterminal are added to the current\n",
    "# rule (`predict()`) since each rule represents one valid parsing path. If on the\n",
    "# other hand, `at_dot()` indicates processing finished for that nonterminal, we\n",
    "# lookup the parent symbols and advance their parsing state (`complete()`). If we\n",
    "# find that we are at a terminal symbol, we simply check if the current state can\n",
    "# advance to parsing the next character (`scan()`). \n",
    "\n",
    "class EarleyParser(EarleyParser):\n",
    "    def fill_chart(self, chart):\n",
    "        for i, col in enumerate(chart):\n",
    "            for state in col.states:\n",
    "                if state.finished():\n",
    "                    self.complete(col, state)\n",
    "                else:\n",
    "                    sym = state.at_dot()\n",
    "                    if sym in self._grammar:\n",
    "                        self.predict(col, sym, state)\n",
    "                    else:\n",
    "                        if i + 1 >= len(chart):\n",
    "                            continue\n",
    "                        self.scan(chart[i + 1], state, sym)\n",
    "            if self.log: print(col.to_repr(), '\\n')\n",
    "        return chart\n",
    "\n",
    "# We can now recognize the given string as part of the language represented by the grammar.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ep = EarleyParser(sample_grammar, log=True)\n",
    "    columns = ep.chart_parse('adcd', START, sample_grammar[START])\n",
    "    for c in columns: print(c)\n",
    "\n",
    "# The chart above only shows completed entries. The parenthesized expression\n",
    "# indicates the column just before the first character was recognized, and the\n",
    "# ending column.\n",
    "\n",
    "# Notice how the `<start>` nonterminal shows the dot at the end. That is, fully parsed.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    last_col = columns[-1]\n",
    "    for s in last_col.states:\n",
    "        if s.name == '<start>':\n",
    "            print(s)\n",
    "\n",
    "# ## Derivation trees\n",
    "# \n",
    "# We use the following procedures to translate the parse forest to individual\n",
    "# trees.\n",
    "\n",
    "# ### parse_prefix\n",
    "\n",
    "class EarleyParser(EarleyParser):\n",
    "    def parse_prefix(self, text, start_symbol):\n",
    "        alts = [tuple(alt) for alt in self._grammar[start_symbol]]\n",
    "        self.table = self.chart_parse(text, start_symbol, alts)\n",
    "        for col in reversed(self.table):\n",
    "            states = [st for st in col.states\n",
    "                if st.name == start_symbol and st.expr in alts and st.s_col.index == 0\n",
    "            ]\n",
    "            if states:\n",
    "                return col.index, states\n",
    "        return -1, []\n",
    "\n",
    "# Here is an example of using it.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ep = EarleyParser(sample_grammar)\n",
    "    cursor, last_states = ep.parse_prefix('adcd', START)\n",
    "    print(cursor, [str(s) for s in last_states])\n",
    "\n",
    "# ### parse_on\n",
    "# \n",
    "# Our `parse_on()` method is slightly different from usual Earley implementations\n",
    "# in that we accept any nonterminal symbol, not just nonterminal symbols with a\n",
    "# single expansion rule. We accomplish this by computing a different chart for\n",
    "# each expansion.\n",
    "\n",
    "class EarleyParser(EarleyParser):\n",
    "    def parse_on(self, text, start_symbol):\n",
    "        starts = self.recognize_on(text, start_symbol)\n",
    "        forest = self.parse_forest(self.table, starts)\n",
    "        for tree in self.extract_trees(forest):\n",
    "            yield tree\n",
    "\n",
    "    def recognize_on(self, text, start_symbol):\n",
    "        cursor, states = self.parse_prefix(text, start_symbol)\n",
    "        starts = [s for s in states if s.finished()]\n",
    "\n",
    "        if self.parse_exceptions:\n",
    "            if cursor < len(text) or not starts:\n",
    "                raise SyntaxError(\"at \" + repr(text[cursor:]))\n",
    "        return starts\n",
    "\n",
    "# ### parse_paths\n",
    "# \n",
    "# \n",
    "# The parse_paths() method tries to unify the given expression in `named_expr` with\n",
    "# the parsed string. For that, it extracts the last symbol in `named_expr` and\n",
    "# checks if it is a terminal symbol. If it is, then it checks the chart at `til` to\n",
    "# see if the letter corresponding to the position matches the terminal symbol.\n",
    "# If it does, extend our start index by the length of the symbol.\n",
    "# \n",
    "# If the symbol was a nonterminal symbol, then we retrieve the parsed states\n",
    "# at the current end column index (`til`) that correspond to the nonterminal\n",
    "# symbol, and collect the start index. These are the end column indexes for\n",
    "# the remaining expression.\n",
    "# \n",
    "# Given our list of start indexes, we obtain the parse paths from the remaining\n",
    "# expression. If we can obtain any, then we return the parse paths. If not, we\n",
    "# return an empty list.\n",
    "\n",
    "class EarleyParser(EarleyParser):\n",
    "    def parse_paths(self, named_expr, chart, frm, til):\n",
    "        def paths(state, start, k, e):\n",
    "            if not e:\n",
    "                return [[(state, k)]] if start == frm else []\n",
    "            else:\n",
    "                return [[(state, k)] + r\n",
    "                        for r in self.parse_paths(e, chart, frm, start)]\n",
    "\n",
    "        *expr, var = named_expr\n",
    "        starts = None\n",
    "        if var not in self._grammar:\n",
    "            starts = ([(var, til - len(var),\n",
    "                        't')] if til > 0 and chart[til].letter == var else [])\n",
    "        else:\n",
    "            starts = [(s, s.s_col.index, 'n') for s in chart[til].states\n",
    "                      if s.finished() and s.name == var]\n",
    "\n",
    "        return [p for s, start, k in starts for p in paths(s, start, k, expr)]\n",
    "\n",
    "# Example\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(sample_grammar[START])\n",
    "    ep = EarleyParser(sample_grammar)\n",
    "    completed_start = last_states[0]\n",
    "    paths = ep.parse_paths(completed_start.expr, columns, 0, 4)\n",
    "    for path in paths:\n",
    "        print([list(str(s_) for s_ in s) for s in path])\n",
    "\n",
    "# That is, the parse path for `<start>` given the input `adcd` included\n",
    "# recognizing the expression `<A><B>`. This was recognized by the two states:\n",
    "# `<A>` from input(0) to input(2) which further involved recognizing the rule\n",
    "# `a<B>c`, and the next state `<B>` from input(3) which involved recognizing the\n",
    "# rule `<D>`.\n",
    "# \n",
    "# ### parse_forest\n",
    "# \n",
    "# The `parse_forest()` method takes the states which represents completed\n",
    "# parses, and determines the possible ways that its expressions corresponded to\n",
    "# the parsed expression. As we noted, it is here that we take care of multiple\n",
    "# expansion rules for start symbol. (The `_parse_forest()` accepts a single\n",
    "# state, and is the main driver that corresponds to traditional implementation,)\n",
    "# For example, say we are parsing `1+2+3`, and the\n",
    "# state has `[<expr>,+,<expr>]` in `expr`. It could have been parsed as either\n",
    "# `[{<expr>:1+2},+,{<expr>:3}]` or `[{<expr>:1},+,{<expr>:2+3}]`.\n",
    "\n",
    "class EarleyParser(EarleyParser):\n",
    "    def forest(self, s, kind, chart):\n",
    "        return self.parse_forest(chart, [s]) if kind == 'n' else (s, [])\n",
    "\n",
    "    def _parse_forest(self, chart, state):\n",
    "        pathexprs = self.parse_paths(state.expr, chart, state.s_col.index,\n",
    "                                     state.e_col.index) if state.expr else []\n",
    "        return (state.name, [[(v, k, chart) for v, k in reversed(pathexpr)]\n",
    "                            for pathexpr in pathexprs])\n",
    "\n",
    "    def parse_forest(self, chart, states):\n",
    "        names = list({s.name for s in states})\n",
    "        assert len(names) == 1\n",
    "        forest = [self._parse_forest(chart, state) for state in states]\n",
    "        return (names[0], [e for name, expr in forest for e in expr])\n",
    "\n",
    "# Example\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ep = EarleyParser(sample_grammar)\n",
    "    result = ep.parse_forest(columns, last_states)\n",
    "    print(result)\n",
    "\n",
    "# ### extract_trees\n",
    "# \n",
    "# We show how to extract a single tree first, and then generalize it to\n",
    "# all trees.\n",
    "\n",
    "class EarleyParser(EarleyParser):\n",
    "    def extract_a_tree(self, forest_node):\n",
    "        name, paths = forest_node\n",
    "        if not paths:\n",
    "            return (name, [])\n",
    "        return (name, [self.extract_a_tree(self.forest(*p)) for p in paths[0]])\n",
    "\n",
    "    def extract_trees(self, forest):\n",
    "        yield self.extract_a_tree(forest)\n",
    "\n",
    "# We need a way to display parse trees.\n",
    "\n",
    "\n",
    "class O:\n",
    "    def __init__(self, **keys): self.__dict__.update(keys)\n",
    "\n",
    "OPTIONS   = O(V='│', H='─', L='└', J = '├')\n",
    "\n",
    "def format_node(node):\n",
    "    key = node[0]\n",
    "    if key and (key[0], key[-1]) ==  ('<', '>'): return key\n",
    "    return repr(key)\n",
    "\n",
    "def get_children(node):\n",
    "    return node[1]\n",
    "\n",
    "def display_tree(node, format_node=format_node, get_children=get_children,\n",
    "                 options=OPTIONS):\n",
    "    print(format_node(node))\n",
    "    for line in format_tree(node, format_node, get_children, options):\n",
    "        print(line)\n",
    "\n",
    "def format_tree(node, format_node, get_children, options, prefix=''):\n",
    "    children = get_children(node)\n",
    "    if not children: return\n",
    "    *children, last_child = children\n",
    "    for child in children:\n",
    "        next_prefix = prefix + options.V + '   '\n",
    "        yield from format_child(child, next_prefix, format_node, get_children,\n",
    "                                options, prefix, False)\n",
    "    last_prefix = prefix + '    '\n",
    "    yield from format_child(last_child, last_prefix, format_node, get_children,\n",
    "                            options, prefix, True)\n",
    "\n",
    "def format_child(child, next_prefix, format_node, get_children, options, \n",
    "                 prefix, last):\n",
    "    sep = (options.L if last else options.J)\n",
    "    yield prefix + sep + options.H + ' ' + format_node(child)\n",
    "    yield from format_tree(child, format_node, get_children, options, next_prefix)\n",
    "\n",
    "format_parsetree = display_tree\n",
    "\n",
    "# Displaying the tree\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tree=('<start>', [('<expr>', [('<expr>', [('<expr>', [('<integer>', [('<digits>', [('<digit>', [('1', [])])])])]), ('+', []), ('<expr>', [('<integer>', [('<digits>', [('<digit>', [('2', [])])])])])]), ('+', []), ('<expr>', [('<integer>', [('<digits>', [('<digit>', [('4', [])])])])])])])\n",
    "    print(format_parsetree(tree))\n",
    "\n",
    "# Example\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mystring = '1+2+4'\n",
    "    parser = EarleyParser(a_grammar)\n",
    "    for tree in parser.parse_on(mystring, START):\n",
    "        print(format_parsetree(tree))\n",
    "\n",
    "# ## Ambiguous Parsing\n",
    "# \n",
    "# Ambiguous grammars can produce multiple derivation trees for some given string.\n",
    "# In the above example, the `a_grammar` can parse `1+2+4` in as either `[1+2]+4` or `1+[2+4]`.\n",
    "# \n",
    "# That is, we need to extract all derivation trees.\n",
    "# We enhance our `extract_trees()` as below.\n",
    "# \n",
    "\n",
    "import itertools as I\n",
    "\n",
    "class EarleyParser(EarleyParser):\n",
    "    def extract_trees(self, forest_node):\n",
    "        name, paths = forest_node\n",
    "        if not paths:\n",
    "            yield (name, [])\n",
    "        results = []\n",
    "        for path in paths:\n",
    "            ptrees = [self.extract_trees(self.forest(*p)) for p in path]\n",
    "            for p in I.product(*ptrees):\n",
    "                yield (name, p)\n",
    "# ### Example\n",
    "# \n",
    "# Using the same example,\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mystring = '1+2+4'\n",
    "    parser = EarleyParser(a_grammar)\n",
    "    for tree in parser.parse_on(mystring, START):\n",
    "        print(format_parsetree(tree))\n",
    "\n",
    "# ## Almost Infinite Parse Trees\n",
    "# \n",
    "# There is a problem with our `extract_trees()` method. The issue is that it is\n",
    "# too eager. The parse forest can have an infinite number of trees, and at this\n",
    "# time we effectively try to extract all at the same time. So, in case of\n",
    "# such grammars our `extract_trees()` will fail. Here are two example grammars.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    directly_self_referring = {\n",
    "        '<start>': [['<query>']],\n",
    "        '<query>': [['<expr>']],\n",
    "        \"<expr>\": [[\"<expr>\"], ['a']],\n",
    "    }\n",
    "\n",
    "    indirectly_self_referring = {\n",
    "        '<start>': [['<query>']],\n",
    "        '<query>': [['<expr>']],\n",
    "        '<expr>': [['<aexpr>'], ['a']],\n",
    "        '<aexpr>': [['<expr>']],\n",
    "    }\n",
    "\n",
    "# An example run.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mystring = 'a'\n",
    "    for grammar in [directly_self_referring, indirectly_self_referring]:\n",
    "        ep = EarleyParser(grammar)\n",
    "        forest = ep.parse_on(mystring, START)\n",
    "        print('recognized', mystring)\n",
    "        try:\n",
    "            for tree in forest:\n",
    "                print(tree)\n",
    "        except RecursionError as e:\n",
    "             print(\"Recursion error\",e)\n",
    "\n",
    "\n",
    "# The problem is that, our implementation of `extract_trees()` is eager.\n",
    "# That is, it attempts to extract all inner parse trees before it can construct\n",
    "# the outer parse tree. When there is a self reference, this results in recursion.\n",
    "# Here is a simple extractor that avoids this problem. The idea here is that we\n",
    "# randomly and lazily choose a node to expand, which avoids the infinite\n",
    "# recursion.\n",
    "\n",
    "import random\n",
    "\n",
    "class SimpleExtractor:\n",
    "    def __init__(self, parser, text, start_symbol):\n",
    "        self.parser = parser\n",
    "        cursor, states = parser.parse_prefix(text, start_symbol)\n",
    "        starts = [s for s in states if s.finished()]\n",
    "        if cursor < len(text) or not starts:\n",
    "            raise SyntaxError(\"at \" + repr(cursor))\n",
    "        self.my_forest = parser.parse_forest(parser.table, starts)\n",
    "\n",
    "    def extract_a_node(self, forest_node):\n",
    "        name, paths = forest_node\n",
    "        if not paths:\n",
    "            return ((name, 0, 1), []), (name, [])\n",
    "        cur_path, i, l = self.choose_path(paths)\n",
    "        child_nodes = []\n",
    "        pos_nodes = []\n",
    "        for s, kind, chart in cur_path:\n",
    "            f = self.parser.forest(s, kind, chart)\n",
    "            postree, ntree = self.extract_a_node(f)\n",
    "            child_nodes.append(ntree)\n",
    "            pos_nodes.append(postree)\n",
    "\n",
    "        return ((name, i, l), pos_nodes), (name, child_nodes)\n",
    "\n",
    "    def choose_path(self, arr):\n",
    "        l = len(arr)\n",
    "        i = random.randrange(l)\n",
    "        return arr[i], i, l\n",
    "\n",
    "    def extract_a_tree(self):\n",
    "        pos_tree, parse_tree = self.extract_a_node(self.my_forest)\n",
    "        return parse_tree\n",
    "\n",
    "# At this point, we also need a simple way to collapse the derivation tree to the original string\n",
    "\n",
    "def tree_to_str(tree):\n",
    "    expanded = []\n",
    "    to_expand = [tree]\n",
    "    while to_expand:\n",
    "        (key, children, *rest), *to_expand = to_expand\n",
    "        if is_nt(key):\n",
    "            to_expand = list(children) + list(to_expand)\n",
    "        else:\n",
    "            assert not children\n",
    "            expanded.append(key)\n",
    "    return ''.join(expanded)\n",
    "# \n",
    "if __name__ == '__main__':\n",
    "    de = SimpleExtractor(EarleyParser(directly_self_referring), mystring, START)\n",
    "\n",
    "# \n",
    "if __name__ == '__main__':\n",
    "    for i in range(5):\n",
    "        tree = de.extract_a_tree()\n",
    "        print(tree_to_str(tree))\n",
    "        print(format_parsetree(tree))\n",
    "\n",
    "# indirect reference\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ie = SimpleExtractor(EarleyParser(indirectly_self_referring), mystring, START)\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for i in range(5):\n",
    "        tree = ie.extract_a_tree()\n",
    "        print(tree_to_str(tree))\n",
    "        print(format_parsetree(tree))\n",
    "\n",
    "# However, `SimpleExtractor` has a problem. The issue is that since we rely on\n",
    "# randomness for exploration, it gives no guarantees on the uniqueness of the\n",
    "# returned trees. Hence, we need a way to keep track of the explored paths.\n",
    "# our next class `EnahncedExtractor` can do that. In `EnhancedExtractor`,\n",
    "# different exploration paths form a tree of nodes.\n",
    "# \n",
    "# First we define a data-structure to keep track of explorations. \n",
    "# * `_chosen` contains the current choice\n",
    "# * `next` holds the next choice done using `_chosen`\n",
    "# * `total` holds he total number of choices for this node.\n",
    "\n",
    "class ChoiceNode:\n",
    "    def __init__(self, parent, total):\n",
    "        self._p, self._chosen = parent, 0\n",
    "        self._total, self.next = total, None\n",
    "\n",
    "    def chosen(self):\n",
    "        assert not self.finished()\n",
    "        return self._chosen\n",
    "\n",
    "    def __str__(self):\n",
    "        return '%d(%s/%s %s)' % (self._i, str(self._chosen),\n",
    "                                 str(self._total), str(self.next))\n",
    "    def __repr__(self):\n",
    "        return repr((self._i, self._chosen, self._total))\n",
    "\n",
    "    def increment(self):\n",
    "        # as soon as we increment, next becomes invalid\n",
    "        self.next = None\n",
    "        self._chosen += 1\n",
    "        if self.finished():\n",
    "            if self._p is None:\n",
    "                return None\n",
    "            return self._p.increment()\n",
    "        return self\n",
    "\n",
    "    def finished(self):\n",
    "        return self._chosen >= self._total\n",
    "\n",
    "# Initialization of the data-structure in the constructor.\n",
    "\n",
    "class EnhancedExtractor(SimpleExtractor):\n",
    "    def __init__(self, parser, text, start_symbol):\n",
    "        super().__init__(parser, text, start_symbol)\n",
    "        self.choices = choices = ChoiceNode(None, 1)\n",
    "\n",
    "# Given an array and a choice node, `choose_path()` returns the element\n",
    "# in array corresponding to the next choice node if it exists, or produces\n",
    "# a new choice nodes, and returns that element.\n",
    "\n",
    "class EnhancedExtractor(EnhancedExtractor):\n",
    "    def choose_path(self, arr, choices):\n",
    "        arr_len = len(arr)\n",
    "        if choices.next is not None:\n",
    "            if choices.next.finished():\n",
    "                return None, None, None, choices.next\n",
    "        else:\n",
    "            choices.next = ChoiceNode(choices, arr_len)\n",
    "        next_choice = choices.next.chosen()\n",
    "        choices = choices.next\n",
    "        return arr[next_choice], next_choice, arr_len, choices\n",
    "\n",
    "# While extracting, we have a choice. Should we allow infinite forests,\n",
    "# or should we have a finite number of trees with no direct recursion?\n",
    "# A direct recursion is when there exists a parent node with the same\n",
    "# nonterminal that parsed the same span. We choose here not to extract\n",
    "# such trees. They can be added back after parsing.\n",
    "# \n",
    "# This is a recursive procedure that inspects a node, extracts the path\n",
    "# required to complete that node. A single path (corresponding to a nonterminal)\n",
    "# may again be composed of a sequence of smaller paths. Such paths are again\n",
    "# extracted using another call to extract_a_node() recursively.\n",
    "# \n",
    "# What happens when we hit on one of the node recursions we want to avoid?\n",
    "# In that case, we return the current choice node, which bubbles up to\n",
    "# `extract_a_tree()`. That procedure increments the last choice, which in\n",
    "# turn increments up the parents until we reach a choice node that still has\n",
    "# options to explore.\n",
    "# \n",
    "# What if we hit the end of choices for a particular choice node\n",
    "# (i.e, we have exhausted paths that can be taken from a node)? In this case also,\n",
    "# we return the current choice node, which bubbles up to `extract_a_tree()`.\n",
    "# That procedure increments the last choice, which bubbles up to the next choice\n",
    "# that has some unexplored paths.\n",
    "\n",
    "class EnhancedExtractor(EnhancedExtractor):\n",
    "    def extract_a_node(self, forest_node, seen, choices):\n",
    "        name, paths = forest_node\n",
    "        if not paths:\n",
    "            return (name, []), choices\n",
    "\n",
    "        cur_path, _i, _l, new_choices = self.choose_path(paths, choices)\n",
    "        if cur_path is None:\n",
    "            return None, new_choices\n",
    "        child_nodes = []\n",
    "        for s, kind, chart in cur_path:\n",
    "            if kind == 't':\n",
    "                child_nodes.append((s, []))\n",
    "                continue\n",
    "            nid = (s.name, s.s_col.index, s.e_col.index)\n",
    "            if nid in seen:\n",
    "                return None, new_choices\n",
    "            f = self.parser.forest(s, kind, chart)\n",
    "            ntree, newer_choices = self.extract_a_node(f, seen | {nid}, new_choices)\n",
    "            if ntree is None:\n",
    "                return None, newer_choices\n",
    "            child_nodes.append(ntree)\n",
    "            new_choices = newer_choices\n",
    "        return (name, child_nodes), new_choices\n",
    "\n",
    "# The `extract_a_tree()` is a depth first extractor of a single tree. It tries to\n",
    "# extract a tree, and if the extraction returns None, it means that a particular\n",
    "# choice was exhausted, or we hit on a recursion. In that case, we increment the\n",
    "# choice, and explore a new path.\n",
    "\n",
    "class EnhancedExtractor(EnhancedExtractor):\n",
    "    def extract_a_tree(self):\n",
    "        while not self.choices.finished():\n",
    "            parse_tree, choices = self.extract_a_node(self.my_forest, set(), self.choices)\n",
    "            choices.increment()\n",
    "            if parse_tree is not None:\n",
    "                return parse_tree\n",
    "        return None\n",
    "\n",
    "# Note that the `EnhancedExtractor` only extracts nodes that are not directly\n",
    "# recursive. That is, if it finds a node with a nonterminal that covers the same\n",
    "# span as that of a parent node with the same nonterminal, it skips the node.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ee = EnhancedExtractor(EarleyParser(indirectly_self_referring), mystring, START)\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        t = ee.extract_a_tree()\n",
    "        if t is None: break\n",
    "        s = tree_to_str(t)\n",
    "        assert s == mystring\n",
    "\n",
    "# ## Leo Optimizations\n",
    "# \n",
    "# One of the problems with the original Earley parser is that while it can parse\n",
    "# strings using arbitrary Context Free Grammars, its performance on\n",
    "# right-recursive grammars is quadratic. That is, it takes $$O(n^2)$$ runtime and\n",
    "# space for parsing with right-recursive grammars. For example, consider the\n",
    "# parsing of the following string by two different grammars `LR_GRAMMAR` and\n",
    "# `RR_GRAMMAR`.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    LR_GRAMMAR = {\n",
    "        '<start>': [['<A>']],\n",
    "        '<A>': [['<A>', 'a'], []],\n",
    "    }\n",
    "    lr_tree = ('<start>', (('<A>', (('<A>', (('<A>', []), ('a', []))), ('a', []))), ('a', [])))\n",
    "    print(format_parsetree(lr_tree))\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    RR_GRAMMAR = {\n",
    "        '<start>': [['<A>']],\n",
    "        '<A>': [['a', '<A>'], []],\n",
    "    }\n",
    "    rr_tree = ('<start>', (('<A>', (('a', []), ('<A>', (('a', []), ('<A>', (('a', []), ('<A>', []))))))),))\n",
    "    print(format_parsetree(rr_tree))\n",
    "\n",
    "# Here is our input string\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mystring = 'aaaaaa'\n",
    "\n",
    "# To see the problem, we need to enable logging. Here is the logged version of parsing with the `LR_GRAMMAR`\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = EarleyParser(LR_GRAMMAR, log=True).parse_on(mystring, START)\n",
    "    for _ in result: pass # consume the generator so that we can see the logs\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = EarleyParser(RR_GRAMMAR, log=True).parse_on(mystring, START)\n",
    "    for _ in result: pass\n",
    "\n",
    "# As can be seen from the parsing log for each letter, the number of states with\n",
    "# representation `<A>: a <A> | (i, j)` increases at each stage, and these are\n",
    "# simply a left over from the previous letter. They do not contribute anything\n",
    "# more to the parse other than to simply complete these entries. However, they\n",
    "# take up space, and require resources for inspection, contributing a factor of $$n$$ in analysis.\n",
    "# \n",
    "# Joop Leo[^leo1991a] found that this inefficiency can be avoided by detecting\n",
    "# right recursion. The idea is that before starting the completion step, check\n",
    "# whether the current item has a deterministic reduction path. If such a path\n",
    "# exists, add a copy of the topmost element of the deterministic reduction path\n",
    "# to the current column, and return. If not, perform the original completion step.\n",
    "\n",
    "\n",
    "# **Definition:** An item is said to be on the deterministic reduction path above\n",
    "# $$[A \\rightarrow \\gamma.,i]$$ if it is $$[B \\rightarrow \\alpha A.,k]$$ with\n",
    "# $$[B \\rightarrow \\alpha.A,k]$$ being the only item in $$I_i$$ with the\n",
    "# dot in front of $$A$$, or if it is on the deterministic reduction path above\n",
    "# $$[B \\rightarrow \\alpha A.,k]$$. An item on such a path is called topmost one\n",
    "# if there is no item on the deterministic reduction path above it[^leo1991a].\n",
    "# \n",
    "# Finding a deterministic reduction path is as follows:\n",
    "# \n",
    "# Given a complete state, represented by `<A> : seq_1 | (s, e)` where `s` is the\n",
    "# starting column for this rule, and `e` the current column, there is a\n",
    "# deterministic reduction path above it if two constraints are satisfied.\n",
    "# \n",
    "# 1. There exist a single item in the form `<B> : seq_2 | <A> (k, s)` in column `s`.\n",
    "# 2. That should be the single item in s with dot in front of `<A>1\n",
    "# \n",
    "# The resulting item is of the form `<B> : seq_2 <A> | (k, e)`, which is simply\n",
    "# item from (1) advanced, and is considered above `<A>:.. (s, e)` in the\n",
    "# deterministic reduction path. The `seq_1` and `seq_2` are arbitrary symbol sequences.\n",
    "# \n",
    "# This forms the following chain of links, with `<A>:.. (s_1, e)` being the child\n",
    "# of `<B>:.. (s_2, e)` etc.\n",
    "# \n",
    "# Here is one way to visualize the chain:\n",
    "# \n",
    "# ```\n",
    "# <C> : seq_3 <B> | (s_3, e)  \n",
    "#              |  constraints satisfied by <C> : seq_3 | <B> (s_3, s_2)\n",
    "#             <B> : seq_2 <A> | (s_2, e)  \n",
    "#                          | constraints satisfied by <B> : seq_2 | <A> (s_2, s_1)\n",
    "#                         <A> : seq_1 | (s_1, e)\n",
    "# ```\n",
    "# \n",
    "# Essentially, what we want to do is to identify potential deterministic right\n",
    "# recursion candidates, perform completion on them, and *throw away* the result.\n",
    "# We do this until we reach the top. See Grune et al.[^grune2008parsing] for further information.\n",
    "# \n",
    "# Note that the completions are in the same column (e), with each candidates with constraints satisfied in further and further earlier columns (as shown below):\n",
    "# \n",
    "# ```\n",
    "# <C> : seq_3 | <B> (s_3, s_2)  -->              <C> : seq_3 <B> | (s_3, e)\n",
    "#                |\n",
    "#               <B> : seq_2 | <A> (s_2, s_1) --> <B> : seq_2 <A> | (s_2, e)  \n",
    "#                              |\n",
    "#                             <A> : seq_1 |                        (s_1, e)\n",
    "# ```\n",
    "# Following this chain, the topmost item is the item `<C>:.. (s_3, e)` that does\n",
    "# not have a parent. The topmost item needs to be saved is called a transitive\n",
    "# item by Leo, and it is associated with the non-terminal symbol that started the\n",
    "# lookup. The transitive item needs to be added to each column we inspect.\n",
    "# \n",
    "# Here is the skeleton for the parser `LeoParser`.\n",
    "# \n",
    "# We first save our original complete\n",
    "\n",
    "class EarleyParser(EarleyParser):\n",
    "    def earley_complete(self, col, state):\n",
    "        parent_states = [st for st in state.s_col.states\n",
    "                 if st.at_dot() == state.name]\n",
    "        for st in parent_states:\n",
    "            col.add(st.advance())\n",
    "\n",
    "# \n",
    "class LeoParser(EarleyParser):\n",
    "    def complete(self, col, state):\n",
    "        return self.leo_complete(col, state)\n",
    "\n",
    "    def leo_complete(self, col, state):\n",
    "        detred = self.deterministic_reduction(state)\n",
    "        if detred:\n",
    "            col.add(detred.copy())\n",
    "        else:\n",
    "            self.earley_complete(col, state)\n",
    "\n",
    "    def deterministic_reduction(self, state):\n",
    "        raise NotImplemented()\n",
    "\n",
    "# First, we update our `Column` class with the ability to add transitive items.\n",
    "# Note that, while Leo asks the transitive to be added to the set $$I_k$$ there is\n",
    "# no actual requirement for the transitive states to be added to the states list.\n",
    "# The transitive items are only intended for memoization and not for the\n",
    "# `fill_chart()` method. Hence, we track them separately.\n",
    "\n",
    "class Column(Column):\n",
    "    def __init__(self, index, letter):\n",
    "        self.index, self.letter = index, letter\n",
    "        self.states, self._unique, self.transitives = [], {}, {}\n",
    "\n",
    "    def add_transitive(self, key, state):\n",
    "        assert key not in self.transitives\n",
    "        self.transitives[key] = state\n",
    "        return self.transitives[key]\n",
    "\n",
    "# Remember the picture we drew of the deterministic path?\n",
    "# \n",
    "# ```\n",
    "#     <C> : seq_3 <B> | (s_3, e)\n",
    "#                  |  constraints satisfied by <C> : seq_3 | <B> (s_3, s_2)\n",
    "#                 <B> : seq_2 <A> | (s_2, e)\n",
    "#                              | constraints satisfied by <B> : seq_2 | <A> (s_2, s_1)\n",
    "#                             <A> : seq_1 | (s_1, e)\n",
    "# ```\n",
    "# \n",
    "# We define a function `uniq_postdot()` that given the item `<A> := seq_1 | (s_1, e)`,\n",
    "# returns a `<B> : seq_2 | <A> (s_2, s_1)` that satisfies the constraints\n",
    "# mentioned in the above picture.\n",
    "\n",
    "class LeoParser(LeoParser):\n",
    "    def uniq_postdot(self, st_A):\n",
    "        col_s1 = st_A.s_col\n",
    "        parent_states = [\n",
    "            s for s in col_s1.states if s.expr and s.at_dot() == st_A.name\n",
    "        ]\n",
    "        if len(parent_states) > 1:\n",
    "            return None\n",
    "        matching_st_B = [s for s in parent_states if s.dot == len(s.expr) - 1]\n",
    "        return matching_st_B[0] if matching_st_B else None\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lp = LeoParser(RR_GRAMMAR)\n",
    "    print([(str(s), str(lp.uniq_postdot(s))) for s in columns[-1].states])\n",
    "\n",
    "# We next define the function `get_top()` that is the core of deterministic\n",
    "# reduction which gets the topmost state above the current state `(A)`.\n",
    "\n",
    "class LeoParser(LeoParser):\n",
    "    def get_top(self, state_A):\n",
    "        st_B_inc = self.uniq_postdot(state_A)\n",
    "        if not st_B_inc:\n",
    "            return None\n",
    "\n",
    "        t_name = st_B_inc.name\n",
    "        if t_name in st_B_inc.e_col.transitives:\n",
    "            return st_B_inc.e_col.transitives[t_name]\n",
    "\n",
    "        st_B = st_B_inc.advance()\n",
    "\n",
    "        top = self.get_top(st_B) or st_B\n",
    "        return st_B_inc.e_col.add_transitive(t_name, top)\n",
    "\n",
    "# Once we have the machinery in place, `deterministic_reduction()` itself is\n",
    "# simply a wrapper to call `get_top()`\n",
    "\n",
    "class LeoParser(LeoParser):\n",
    "    def deterministic_reduction(self, state):\n",
    "        return self.get_top(state)\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lp = LeoParser(RR_GRAMMAR)\n",
    "    columns = lp.chart_parse(mystring, START, RR_GRAMMAR[START])\n",
    "    print([(str(s), str(lp.get_top(s))) for s in columns[-1].states])\n",
    "\n",
    "# Now, both LR and RR grammars should work within  $$O(n)$$ bounds.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = LeoParser(RR_GRAMMAR, log=True).parse_on(mystring, START)\n",
    "    for _ in result: pass\n",
    "\n",
    "# Examples\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    RR_GRAMMAR2 = {\n",
    "        '<start>': [['<A>']],\n",
    "        '<A>': [['a','b', '<A>'], []],\n",
    "    }\n",
    "    mystring2 = 'ababababab'\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = LeoParser(RR_GRAMMAR2, log=True).parse_on(mystring2, START)\n",
    "    for _ in result: pass\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    RR_GRAMMAR3 = {\n",
    "        '<start>': [['c', '<A>']],\n",
    "        '<A>': [['a', 'b', '<A>'], []],\n",
    "    }\n",
    "    mystring3 = 'cababababab'\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = LeoParser(RR_GRAMMAR3, log=True).parse_on(mystring3, START)\n",
    "    for _ in result: pass\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    RR_GRAMMAR4 = {\n",
    "        '<start>': [['<A>', 'c']],\n",
    "        '<A>': [['a', 'b', '<A>'], []],\n",
    "    }\n",
    "    mystring4 = 'ababababc'\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = LeoParser(RR_GRAMMAR4, log=True).parse_on(mystring4, START)\n",
    "    for _ in result: pass\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    RR_GRAMMAR5 = {\n",
    "        '<start>': [['<A>']],\n",
    "        '<A>': [['a', 'b', '<B>'], []],\n",
    "        '<B>': [['<A>']],\n",
    "    }\n",
    "    mystring5 = 'abababab'\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = LeoParser(RR_GRAMMAR5, log=True).parse_on(mystring5, START)\n",
    "    for _ in result: pass\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    RR_GRAMMAR6 = {\n",
    "        '<start>': [['<A>']],\n",
    "        '<A>': [['a', '<B>'], []],\n",
    "        '<B>': [['b', '<A>']],\n",
    "    }\n",
    "    mystring6 = 'abababab'\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = LeoParser(RR_GRAMMAR6, log=True).parse_on(mystring6, START)\n",
    "    for _ in result: pass\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    RR_GRAMMAR7 = {\n",
    "        '<start>': [['<A>']],\n",
    "        '<A>': [['a', '<A>'], ['a']],\n",
    "    }\n",
    "    mystring7 = 'aaaaaaaa'\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = LeoParser(RR_GRAMMAR7, log=True).parse_on(mystring7, START)\n",
    "    for _ in result: pass\n",
    "\n",
    "# We verify that our parser works correctly on `LR_GRAMMAR` too.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = LeoParser(LR_GRAMMAR, log=True).parse_on(mystring, START)\n",
    "    for _ in result: pass\n",
    "\n",
    "\n",
    "# We have fixed the complexity bounds. However, because we are saving only the topmost item of a right recursion, we need to fix our parser to be aware of our fix while extracting parse trees.\n",
    "# \n",
    "# We first change the definition of `add_transitive()` so that results of deterministic reduction can be identified later.\n",
    "\n",
    "class Column(Column):\n",
    "    def add_transitive(self, key, state):\n",
    "        assert key not in self.transitives\n",
    "        self.transitives[key] = self.create_tstate(state)\n",
    "        return self.transitives[key]\n",
    "\n",
    "    def create_tstate(self, state):\n",
    "        return TState(state.name, state.expr, state.dot, state.s_col, state.e_col)\n",
    "\n",
    "\n",
    "# We also need a `back()` method to create the constraints.\n",
    "\n",
    "class State(State):\n",
    "    def back(self):\n",
    "        return TState(self.name, self.expr, self.dot - 1, self.s_col, self.e_col)\n",
    "\n",
    "# We update `copy()` to make `TState` items instead.\n",
    "\n",
    "class TState(State):\n",
    "    def copy(self):\n",
    "        return TState(self.name, self.expr, self.dot, self.s_col, self.e_col)\n",
    "\n",
    "# We now modify the `LeoParser` to keep track of the chain of constrains that we mentioned earlier.\n",
    "\n",
    "class LeoParser(LeoParser):\n",
    "    def __init__(self, grammar, **kwargs):\n",
    "        super().__init__(grammar, **kwargs)\n",
    "        self._postdots = {}\n",
    "\n",
    "# Next, we update the `uniq_postdot()` so that it tracks the chain of links.\n",
    "\n",
    "class LeoParser(LeoParser):\n",
    "    def uniq_postdot(self, st_A):\n",
    "        col_s1 = st_A.s_col\n",
    "        parent_states = [\n",
    "            s for s in col_s1.states if s.expr and s.at_dot() == st_A.name\n",
    "        ]\n",
    "        if len(parent_states) > 1:\n",
    "            return None\n",
    "        matching_st_B = [s for s in parent_states if s.dot == len(s.expr) - 1]\n",
    "        if matching_st_B:\n",
    "            self._postdots[matching_st_B[0]._t()] = st_A\n",
    "            return matching_st_B[0]\n",
    "        return None\n",
    "\n",
    "# We next define a method `expand_tstate()` that, when given a `TState`, generates\n",
    "# all the intermediate links that we threw away earlier for a given end column.\n",
    "\n",
    "class LeoParser(LeoParser):\n",
    "    def expand_tstate(self, state, e):\n",
    "        if state._t() not in self._postdots:\n",
    "            return\n",
    "        c_C = self._postdots[state._t()]\n",
    "        e.add(c_C.advance())\n",
    "        self.expand_tstate(c_C.back(), e)\n",
    "\n",
    "# We define a `rearrange()` method to generate a reversed table where each column contains states that start at that column.\n",
    "\n",
    "class LeoParser(LeoParser):\n",
    "    def rearrange(self, table):\n",
    "        f_table = [self.create_column(c.index, c.letter) for c in table]\n",
    "        for col in table:\n",
    "            for s in col.states:\n",
    "                f_table[s.s_col.index].states.append(s)\n",
    "        return f_table\n",
    "\n",
    "# Here is the rearranged table.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ep = LeoParser(RR_GRAMMAR)\n",
    "    columns = ep.chart_parse(mystring, START, RR_GRAMMAR[START])\n",
    "    r_table = ep.rearrange(columns)\n",
    "    for col in r_table:\n",
    "        print(col, \"\\n\")\n",
    "\n",
    "# We save the result of rearrange before going into `parse_forest()`.\n",
    "\n",
    "class LeoParser(LeoParser):\n",
    "    def parse_on(self, text, start_symbol):\n",
    "        starts = self.recognize_on(text, start_symbol)\n",
    "        self.r_table = self.rearrange(self.table)\n",
    "        forest = self.parse_forest(self.table, starts)\n",
    "        for tree in self.extract_trees(forest):\n",
    "            yield tree\n",
    "\n",
    "# Finally, during `parse_forest()`, we first check to see if it is a transitive\n",
    "# state, and if it is, expand it to the original sequence of states using\n",
    "# `traverse_constraints()`.\n",
    "\n",
    "class LeoParser(LeoParser):\n",
    "    def parse_forest(self, chart, states):\n",
    "        for state in states:\n",
    "            if isinstance(state, TState):\n",
    "                self.expand_tstate(state.back(), state.e_col)\n",
    "\n",
    "        return super().parse_forest(chart, states)\n",
    "\n",
    "# This completes our implementation of `LeoParser `.\n",
    "\n",
    "# ### Parse Examples\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = LeoParser(RR_GRAMMAR).parse_on(mystring, START)\n",
    "    for tree in result:\n",
    "        assert mystring == tree_to_str(tree)\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = LeoParser(RR_GRAMMAR2).parse_on(mystring2, START)\n",
    "    for tree in result:\n",
    "        assert mystring2 == tree_to_str(tree)\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = LeoParser(RR_GRAMMAR3).parse_on(mystring3, START)\n",
    "    for tree in result:\n",
    "        assert mystring3 == tree_to_str(tree)\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = LeoParser(RR_GRAMMAR4).parse_on(mystring4, START)\n",
    "    for tree in result:\n",
    "        assert mystring4 == tree_to_str(tree)\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = LeoParser(RR_GRAMMAR5).parse_on(mystring5, START)\n",
    "    for tree in result:\n",
    "        assert mystring5 == tree_to_str(tree)\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = LeoParser(RR_GRAMMAR6).parse_on(mystring6, START)\n",
    "    for tree in result:\n",
    "        assert mystring6 == tree_to_str(tree)\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = LeoParser(RR_GRAMMAR7).parse_on(mystring7, START)\n",
    "    for tree in result:\n",
    "        assert mystring7 == tree_to_str(tree)\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = LeoParser(LR_GRAMMAR).parse_on(mystring, START)\n",
    "    for tree in result:\n",
    "        assert mystring == tree_to_str(tree)\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    RR_GRAMMAR8 = {\n",
    "       '<start>': [['<A>']],\n",
    "       '<A>': [['a', '<A>'], ['a']]\n",
    "    }\n",
    "    mystring8 = 'aa'\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    RR_GRAMMAR9 = {\n",
    "       '<start>': [['<A>']],\n",
    "       '<A>': [['<B>', '<A>'], ['<B>']],\n",
    "       '<B>': [['b']]\n",
    "    }\n",
    "    mystring9 = 'bbbbbbb'\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = LeoParser(RR_GRAMMAR8).parse_on(mystring8, START)\n",
    "    for tree in result:\n",
    "        print(repr(tree_to_str(tree)))\n",
    "        assert mystring8 == tree_to_str(tree)\n",
    "\n",
    "# \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = LeoParser(RR_GRAMMAR9).parse_on(mystring9, START)\n",
    "    for tree in result:\n",
    "        print(repr(tree_to_str(tree)))\n",
    "        assert mystring9 == tree_to_str(tree)\n",
    "\n",
    "# Now this is still somewhat slow. Why is that? Note that recognition is\n",
    "# $$O(n^2)$$ and actual parsing is $$O(n^3)$$. That is, using `parse_prefix()` to\n",
    "# check whether a text can be parsed by a given grammar will be much faster than\n",
    "# extracting a parse tree. A second issue is that we are building this over\n",
    "# Python implemented on top of WASM. Python on its own is fairly slow. On our\n",
    "# experiments, [translating the earley parser to Java line by line](https://github.com/vrthra/EarleyJava)\n",
    "# resulted in an improvement over 300 times.\n",
    "\n",
    "# The runnable Python source for this post is available [here](https://github.com/rahulgopinath/rahulgopinath.github.io/blob/master/notebooks/2021-02-06-earley-parsing.py).\n",
    "# \n",
    "# [^earley1970an]: Earley, Jay. \"An efficient context-free parsing algorithm.\" Communications of the ACM 13.2 (1970): 94-102.\n",
    "# \n",
    "# [^leo1991a]: Leo, Joop MIM. \"A general context-free parsing algorithm running in linear time on every LR (k) grammar without using lookahead.\" Theoretical computer science 82.1 (1991): 165-176.\n",
    "# \n",
    "# [^aycock2002practical]: Aycock, John, and R. Nigel Horspool. \"Practical earley parsing.\" The Computer Journal 45.6 (2002): 620-630.\n",
    "# \n",
    "# [^grune2008parsing]: Grune, Dick, and Ceriel JH Jacobs. \"Introduction to Parsing.\" Parsing Techniques. Springer, New York, NY, 2008. 61-102."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "at 'XX' (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32md:\\Programmeren\\adventofcode\\.aocenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3398\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Input \u001b[0;32mIn [135]\u001b[0m in \u001b[0;35m<cell line: 9>\u001b[0m\n    for tree in my_parser.parse_on(text='aXX', start_symbol='e'):\n",
      "  Input \u001b[0;32mIn [111]\u001b[0m in \u001b[0;35mparse_on\u001b[0m\n    starts = self.recognize_on(text, start_symbol)\n",
      "\u001b[1;36m  Input \u001b[1;32mIn [111]\u001b[1;36m in \u001b[1;35mrecognize_on\u001b[1;36m\u001b[0m\n\u001b[1;33m    raise SyntaxError(\"at \" + repr(text[cursor:]))\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m<string>\u001b[1;36m\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m at 'XX'\n"
     ]
    }
   ],
   "source": [
    "my_grammar = {'Ca': [['Cp', '<A>'],['2']],\n",
    "              'A'    : [['a']],\n",
    "              'C'    : [['XX']],\n",
    "              'e'    : [['A','C'],['C']]\n",
    "              \n",
    "              \n",
    "              }\n",
    "my_parser = EarleyParser(my_grammar)\n",
    "for tree in my_parser.parse_on(text='aXX', start_symbol='e'):\n",
    "    print(format_parsetree(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class StateDict(dict):\n",
    "    def __repr__(self):\n",
    "        return self.get('test')\n",
    "j = StateDict(test='hi')\n",
    "j.get('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenv\\lib\\site-packages\\IPython\\core\\formatters.py:707\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    700\u001b[0m stream \u001b[39m=\u001b[39m StringIO()\n\u001b[0;32m    701\u001b[0m printer \u001b[39m=\u001b[39m pretty\u001b[39m.\u001b[39mRepresentationPrinter(stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[0;32m    702\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnewline,\n\u001b[0;32m    703\u001b[0m     max_seq_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_seq_length,\n\u001b[0;32m    704\u001b[0m     singleton_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msingleton_printers,\n\u001b[0;32m    705\u001b[0m     type_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype_printers,\n\u001b[0;32m    706\u001b[0m     deferred_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeferred_printers)\n\u001b[1;32m--> 707\u001b[0m printer\u001b[39m.\u001b[39;49mpretty(obj)\n\u001b[0;32m    708\u001b[0m printer\u001b[39m.\u001b[39mflush()\n\u001b[0;32m    709\u001b[0m \u001b[39mreturn\u001b[39;00m stream\u001b[39m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenv\\lib\\site-packages\\IPython\\lib\\pretty.py:410\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    407\u001b[0m                         \u001b[39mreturn\u001b[39;00m meth(obj, \u001b[39mself\u001b[39m, cycle)\n\u001b[0;32m    408\u001b[0m                 \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mobject\u001b[39m \\\n\u001b[0;32m    409\u001b[0m                         \u001b[39mand\u001b[39;00m callable(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39m__repr__\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[1;32m--> 410\u001b[0m                     \u001b[39mreturn\u001b[39;00m _repr_pprint(obj, \u001b[39mself\u001b[39;49m, cycle)\n\u001b[0;32m    412\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_pprint(obj, \u001b[39mself\u001b[39m, cycle)\n\u001b[0;32m    413\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenv\\lib\\site-packages\\IPython\\lib\\pretty.py:778\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[39m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[39m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mrepr\u001b[39;49m(obj)\n\u001b[0;32m    779\u001b[0m lines \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39msplitlines()\n\u001b[0;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m p\u001b[39m.\u001b[39mgroup():\n",
      "\u001b[1;32md:\\Programmeren\\aocutils\\06_context_free_grammar.ipynb Cell 23\u001b[0m in \u001b[0;36mStateDict.__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programmeren/aocutils/06_context_free_grammar.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__repr__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programmeren/aocutils/06_context_free_grammar.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     pos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mposition\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Programmeren/aocutils/06_context_free_grammar.ipynb#X35sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39msymbol\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mrule\u001b[39m\u001b[39m'\u001b[39m)[:pos]\u001b[39m}\u001b[39;00m\u001b[39m • \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mrule\u001b[39m\u001b[39m'\u001b[39m)[pos:]\u001b[39m}\u001b[39;00m\u001b[39m   (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mstartidx\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programmeren/aocutils/06_context_free_grammar.ipynb#X35sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import UserDict\n",
    "class StateDict(UserDict):\n",
    "    def __repr__(self):\n",
    "        pos = self.get('position')\n",
    "        output = f\"{self.get('symbol')}:{self.get('rule')[:pos]} • {self.get('rule')[pos:]}   ({self.get('startidx')})\"\n",
    "        return output\n",
    "test = StateDict({'symbol':'hi'})\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from collections import UserDict\n",
    "class StateDict(UserDict):\n",
    "    def __repr__(self):\n",
    "        pos = self.get('position')\n",
    "        output = f\"symbol {self.get('symbol'):<4}: {str(self.get('rule')[:pos]):<10} • {str(self.get('rule')[pos:]):<20} {'idx('}{self.get('startidx')}) {'Done' if self.get('completed') else ''})\"\n",
    "        return output\n",
    "grammar = defaultdict(set) # needs to be a set of TUPLES, be careful with only 1 item to make it a tuple\n",
    "grammar |= {'term': {('num', '+', 'term'), ('num',)},\n",
    "           'num': {(0,),(1,),(2,)},\n",
    "           }\n",
    "message = ((1), ('+'), (2))\n",
    "start = 'term'\n",
    "\n",
    "\n",
    "grammar = {'0': (('4', '1', '5'),),\n",
    " '1': (('2', '3'), ('3', '2')),\n",
    " '2': (('4', '4'), ('5', '5')),\n",
    " '3': (('4', '5'), ('5', '4')),\n",
    " '4': (('a',),),\n",
    " '5': (('b',),)}\n",
    "\n",
    "messages = ['ababbb', 'bababa', 'abbbab', 'aaabbb', 'aaaabbb']\n",
    "message = messages[0]\n",
    "start = '0'\n",
    "\n",
    "cols = [[] for _ in range(len(message)+1)]\n",
    "\n",
    "def genstate(symbol, rule, idx):\n",
    "    return StateDict({'symbol': symbol,\n",
    "            'rule': rule,\n",
    "            'startidx': idx,\n",
    "            'position': 0,\n",
    "            'steps': len(rule),\n",
    "            'completed': False})\n",
    "            # 'steps': len(rule)}\n",
    "\n",
    "def predict(column, colidx, symbol):\n",
    "    seen = {symbol} # otherwise you can have infinite loop when recursively adding\n",
    "    toadd = {symbol}\n",
    "    while toadd:\n",
    "        cur = toadd.pop()\n",
    "        \n",
    "        for rule in grammar.get(cur, []):\n",
    "            column.append(genstate(cur, rule, colidx))\n",
    "            if (recursivesymbol := column[-1]['rule'][0]) not in seen:\n",
    "                toadd.add(recursivesymbol)\n",
    "\n",
    "def scan(column, parsedchar):\n",
    "    # we are scanning the states in a column to check if we can advance\n",
    "    advancedstates = []\n",
    "    for state in column:\n",
    "        if not state['completed']:\n",
    "            # print(state, parsedchar, state['rule'][0])\n",
    "            if state['rule'][state['position']] == parsedchar:\n",
    "                state['position'] += 1\n",
    "                if state['position'] == state['steps']:\n",
    "                    state['completed'] = True\n",
    "                advancedstates.append(state)\n",
    "    return advancedstates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have completion 1\n",
      "1\n",
      "[symbol 4   : ('a',)     • ()                   idx(0) Done),\n",
      " symbol 0   : ('4',)     • ('1', '5')           idx(0) ),\n",
      " symbol 1   : ()         • ('2', '3')           idx(1) ),\n",
      " symbol 1   : ()         • ('3', '2')           idx(1) ),\n",
      " symbol 2   : ()         • ('4', '4')           idx(1) ),\n",
      " symbol 2   : ()         • ('5', '5')           idx(1) ),\n",
      " symbol 4   : ()         • ('a',)               idx(1) ),\n",
      " symbol 3   : ()         • ('4', '5')           idx(1) ),\n",
      " symbol 3   : ()         • ('5', '4')           idx(1) ),\n",
      " symbol 5   : ()         • ('b',)               idx(1) ),\n",
      " symbol 4   : ()         • ('a',)               idx(1) )]\n",
      "we have completion 2\n",
      "2\n",
      "[symbol 5   : ('b',)     • ()                   idx(1) Done),\n",
      " symbol 3   : ('5',)     • ('4',)               idx(1) ),\n",
      " symbol 4   : ()         • ('a',)               idx(2) ),\n",
      " symbol 2   : ('5',)     • ('5',)               idx(1) ),\n",
      " symbol 5   : ()         • ('b',)               idx(2) )]\n",
      "we have completion 1\n",
      "we have completion 0\n",
      "3\n",
      "[symbol 4   : ('a',)     • ()                   idx(2) Done),\n",
      " symbol 3   : ('5', '4') • ()                   idx(1) Done)]\n",
      "4\n",
      "[]\n",
      "5\n",
      "[]\n",
      "6\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict(cols[0], 0, start)\n",
    "\n",
    "for colidx in range(1, len(message)+1): # we just populated the 0th col, now the first character has colidx 1\n",
    "    advancedstates = scan(cols[colidx-1], message[colidx-1])\n",
    "    \n",
    "    # check if any of the states are completed, if yes do scan again (loop untill nothing is completed)\n",
    "    while advancedstates:\n",
    "        advancedstate = advancedstates.pop()\n",
    "        cols[colidx].append(advancedstate)\n",
    "        if advancedstate['completed']:\n",
    "            # do scan again, looking to advance other states based on the symbol of the completed rule\n",
    "            toadd = scan(cols[colidx-1], advancedstate['symbol'])\n",
    "            print('we have completion', len(toadd))\n",
    "            for newadvancedstate in toadd:\n",
    "                advancedstates.append(newadvancedstate)\n",
    "        else:\n",
    "            # predict new states based on the next expected symbol in the rule\n",
    "            predict(cols[colidx], colidx, advancedstate['rule'][advancedstate['position']])\n",
    "    print(colidx)\n",
    "    pprint(cols[colidx])\n",
    "\n",
    "for state in cols[colidx]:\n",
    "    if state['completed'] and state['startidx'] == 0:\n",
    "        print('valid')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"('4',)\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(('4',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (('4', '1', '5'),) option ('4', '1', '5')\n",
      "1 (('2', '3'), ('3', '2')) option ('2', '3')\n",
      "1 (('2', '3'), ('3', '2')) option ('3', '2')\n",
      "2 (('4', '4'), ('5', '5')) option ('4', '4')\n",
      "2 (('4', '4'), ('5', '5')) option ('5', '5')\n",
      "3 (('4', '5'), ('5', '4')) option ('4', '5')\n",
      "3 (('4', '5'), ('5', '4')) option ('5', '4')\n",
      "4 (('a',),) option ('a',)\n",
      "5 (('b',),) option ('b',)\n",
      "outcomes after grammar defaultdict(<class 'set'>, {'a': {'4'}, 'b': {'5'}})\n",
      "0 messages done\n",
      "1\n",
      "2\n",
      "  ab\n",
      "     ('a', 'b')\n",
      "            this is a potential ('4', '5')\n",
      "             and found!\n",
      "      yes\n",
      "  bb\n",
      "     ('b', 'b')\n",
      "            this is a potential ('5', '5')\n",
      "             and found!\n",
      "      yes\n",
      "  ba\n",
      "     ('b', 'a')\n",
      "            this is a potential ('5', '4')\n",
      "             and found!\n",
      "      yes\n",
      "3\n",
      "  bab\n",
      "     ('ba', 'b')\n",
      "            this is a potential ('3', '5')\n",
      "     ('b', 'ab')\n",
      "            this is a potential ('5', '3')\n",
      "  aba\n",
      "     ('ab', 'a')\n",
      "            this is a potential ('3', '4')\n",
      "     ('a', 'ba')\n",
      "            this is a potential ('4', '3')\n",
      "  bbb\n",
      "     ('bb', 'b')\n",
      "            this is a potential ('2', '5')\n",
      "     ('b', 'bb')\n",
      "            this is a potential ('5', '2')\n",
      "  abb\n",
      "     ('ab', 'b')\n",
      "            this is a potential ('3', '5')\n",
      "     ('a', 'bb')\n",
      "            this is a potential ('4', '2')\n",
      "4\n",
      "  abab\n",
      "     ('a', 'bab')\n",
      "     ('aba', 'b')\n",
      "     ('ab', 'ab')\n",
      "            this is a potential ('3', '3')\n",
      "  abbb\n",
      "     ('ab', 'bb')\n",
      "            this is a potential ('3', '2')\n",
      "             and found!\n",
      "      yes\n",
      "     ('a', 'bbb')\n",
      "     ('abb', 'b')\n",
      "  babb\n",
      "     ('bab', 'b')\n",
      "     ('b', 'abb')\n",
      "     ('ba', 'bb')\n",
      "            this is a potential ('3', '2')\n",
      "             and found!\n",
      "      yes\n",
      "5\n",
      "  ababb\n",
      "     ('ab', 'abb')\n",
      "     ('abab', 'b')\n",
      "     ('aba', 'bb')\n",
      "     ('a', 'babb')\n",
      "            this is a potential ('4', '1')\n",
      "  babbb\n",
      "     ('ba', 'bbb')\n",
      "     ('bab', 'bb')\n",
      "     ('babb', 'b')\n",
      "            this is a potential ('1', '5')\n",
      "             and found!\n",
      "      yes\n",
      "     ('b', 'abbb')\n",
      "            this is a potential ('5', '1')\n",
      "6\n",
      "  ababbb\n",
      "     ('ab', 'abbb')\n",
      "            this is a potential ('3', '1')\n",
      "     ('aba', 'bbb')\n",
      "     ('a', 'babbb')\n",
      "            this is a potential ('4', 'extra1')\n",
      "             and found!\n",
      "      yes\n",
      "     ('ababb', 'b')\n",
      "     ('abab', 'bb')\n",
      "1\n",
      "2\n",
      "3\n",
      "  bab\n",
      "     ('ba', 'b')\n",
      "            this is a potential ('3', '5')\n",
      "     ('b', 'ab')\n",
      "            this is a potential ('5', '3')\n",
      "  aba\n",
      "     ('ab', 'a')\n",
      "            this is a potential ('3', '4')\n",
      "     ('a', 'ba')\n",
      "            this is a potential ('4', '3')\n",
      "4\n",
      "  baba\n",
      "     ('bab', 'a')\n",
      "     ('ba', 'ba')\n",
      "            this is a potential ('3', '3')\n",
      "     ('b', 'aba')\n",
      "  abab\n",
      "     ('a', 'bab')\n",
      "     ('aba', 'b')\n",
      "     ('ab', 'ab')\n",
      "            this is a potential ('3', '3')\n",
      "5\n",
      "  babab\n",
      "     ('b', 'abab')\n",
      "     ('bab', 'ab')\n",
      "     ('ba', 'bab')\n",
      "     ('baba', 'b')\n",
      "  ababa\n",
      "     ('ab', 'aba')\n",
      "     ('a', 'baba')\n",
      "     ('abab', 'a')\n",
      "     ('aba', 'ba')\n",
      "6\n",
      "  bababa\n",
      "     ('baba', 'ba')\n",
      "     ('ba', 'baba')\n",
      "     ('b', 'ababa')\n",
      "     ('babab', 'a')\n",
      "     ('bab', 'aba')\n",
      "1\n",
      "2\n",
      "3\n",
      "  bba\n",
      "     ('bb', 'a')\n",
      "            this is a potential ('2', '4')\n",
      "     ('b', 'ba')\n",
      "            this is a potential ('5', '3')\n",
      "  bab\n",
      "     ('ba', 'b')\n",
      "            this is a potential ('3', '5')\n",
      "     ('b', 'ab')\n",
      "            this is a potential ('5', '3')\n",
      "  bbb\n",
      "     ('bb', 'b')\n",
      "            this is a potential ('2', '5')\n",
      "     ('b', 'bb')\n",
      "            this is a potential ('5', '2')\n",
      "  abb\n",
      "     ('ab', 'b')\n",
      "            this is a potential ('3', '5')\n",
      "     ('a', 'bb')\n",
      "            this is a potential ('4', '2')\n",
      "4\n",
      "  bbba\n",
      "     ('bb', 'ba')\n",
      "            this is a potential ('2', '3')\n",
      "             and found!\n",
      "      yes\n",
      "     ('bbb', 'a')\n",
      "     ('b', 'bba')\n",
      "  bbab\n",
      "     ('b', 'bab')\n",
      "     ('bba', 'b')\n",
      "     ('bb', 'ab')\n",
      "            this is a potential ('2', '3')\n",
      "             and found!\n",
      "      yes\n",
      "5\n",
      "  abbba\n",
      "     ('abbb', 'a')\n",
      "            this is a potential ('1', '4')\n",
      "     ('ab', 'bba')\n",
      "     ('abb', 'ba')\n",
      "     ('a', 'bbba')\n",
      "            this is a potential ('4', '1')\n",
      "  bbbab\n",
      "     ('bbb', 'ab')\n",
      "     ('bb', 'bab')\n",
      "     ('b', 'bbab')\n",
      "            this is a potential ('5', '1')\n",
      "     ('bbba', 'b')\n",
      "            this is a potential ('1', '5')\n",
      "             and found!\n",
      "      yes\n",
      "6\n",
      "  abbbab\n",
      "     ('abb', 'bab')\n",
      "     ('a', 'bbbab')\n",
      "            this is a potential ('4', 'extra1')\n",
      "             and found!\n",
      "      yes\n",
      "     ('abbb', 'ab')\n",
      "            this is a potential ('1', '3')\n",
      "     ('ab', 'bbab')\n",
      "            this is a potential ('3', '1')\n",
      "     ('abbba', 'b')\n",
      "1\n",
      "2\n",
      "  aa\n",
      "     ('a', 'a')\n",
      "            this is a potential ('4', '4')\n",
      "             and found!\n",
      "      yes\n",
      "3\n",
      "  aab\n",
      "     ('aa', 'b')\n",
      "            this is a potential ('2', '5')\n",
      "     ('a', 'ab')\n",
      "            this is a potential ('4', '3')\n",
      "  aaa\n",
      "     ('a', 'aa')\n",
      "            this is a potential ('4', '2')\n",
      "     ('aa', 'a')\n",
      "            this is a potential ('2', '4')\n",
      "  bbb\n",
      "     ('bb', 'b')\n",
      "            this is a potential ('2', '5')\n",
      "     ('b', 'bb')\n",
      "            this is a potential ('5', '2')\n",
      "  abb\n",
      "     ('ab', 'b')\n",
      "            this is a potential ('3', '5')\n",
      "     ('a', 'bb')\n",
      "            this is a potential ('4', '2')\n",
      "4\n",
      "  aabb\n",
      "     ('aa', 'bb')\n",
      "            this is a potential ('2', '2')\n",
      "     ('aab', 'b')\n",
      "     ('a', 'abb')\n",
      "  aaab\n",
      "     ('aa', 'ab')\n",
      "            this is a potential ('2', '3')\n",
      "             and found!\n",
      "      yes\n",
      "     ('aaa', 'b')\n",
      "     ('a', 'aab')\n",
      "5\n",
      "  aaabb\n",
      "     ('aa', 'abb')\n",
      "     ('aaab', 'b')\n",
      "            this is a potential ('1', '5')\n",
      "             and found!\n",
      "      yes\n",
      "     ('a', 'aabb')\n",
      "     ('aaa', 'bb')\n",
      "  aabbb\n",
      "     ('a', 'abbb')\n",
      "            this is a potential ('4', '1')\n",
      "     ('aa', 'bbb')\n",
      "     ('aab', 'bb')\n",
      "     ('aabb', 'b')\n",
      "6\n",
      "  aaabbb\n",
      "     ('aaab', 'bb')\n",
      "            this is a potential ('1', '2')\n",
      "     ('aa', 'abbb')\n",
      "            this is a potential ('2', '1')\n",
      "     ('aaa', 'bbb')\n",
      "     ('aaabb', 'b')\n",
      "            this is a potential ('extra1', '5')\n",
      "     ('a', 'aabbb')\n",
      "1\n",
      "2\n",
      "3\n",
      "  aab\n",
      "     ('aa', 'b')\n",
      "            this is a potential ('2', '5')\n",
      "     ('a', 'ab')\n",
      "            this is a potential ('4', '3')\n",
      "  aaa\n",
      "     ('a', 'aa')\n",
      "            this is a potential ('4', '2')\n",
      "     ('aa', 'a')\n",
      "            this is a potential ('2', '4')\n",
      "  bbb\n",
      "     ('bb', 'b')\n",
      "            this is a potential ('2', '5')\n",
      "     ('b', 'bb')\n",
      "            this is a potential ('5', '2')\n",
      "  abb\n",
      "     ('ab', 'b')\n",
      "            this is a potential ('3', '5')\n",
      "     ('a', 'bb')\n",
      "            this is a potential ('4', '2')\n",
      "4\n",
      "  aabb\n",
      "     ('aa', 'bb')\n",
      "            this is a potential ('2', '2')\n",
      "     ('aab', 'b')\n",
      "     ('a', 'abb')\n",
      "  aaaa\n",
      "     ('aa', 'aa')\n",
      "            this is a potential ('2', '2')\n",
      "     ('a', 'aaa')\n",
      "     ('aaa', 'a')\n",
      "5\n",
      "  aabbb\n",
      "     ('a', 'abbb')\n",
      "            this is a potential ('4', '1')\n",
      "     ('aa', 'bbb')\n",
      "     ('aab', 'bb')\n",
      "     ('aabb', 'b')\n",
      "  aaaab\n",
      "     ('a', 'aaab')\n",
      "            this is a potential ('4', '1')\n",
      "     ('aa', 'aab')\n",
      "     ('aaaa', 'b')\n",
      "     ('aaa', 'ab')\n",
      "6\n",
      "  aaaabb\n",
      "     ('aa', 'aabb')\n",
      "     ('a', 'aaabb')\n",
      "            this is a potential ('4', 'extra1')\n",
      "             and found!\n",
      "      yes\n",
      "     ('aaaa', 'bb')\n",
      "     ('aaaab', 'b')\n",
      "     ('aaa', 'abb')\n",
      "  aaabbb\n",
      "     ('aaab', 'bb')\n",
      "            this is a potential ('1', '2')\n",
      "     ('aa', 'abbb')\n",
      "            this is a potential ('2', '1')\n",
      "     ('aaa', 'bbb')\n",
      "     ('aaabb', 'b')\n",
      "            this is a potential ('extra1', '5')\n",
      "     ('a', 'aabbb')\n",
      "7\n",
      "  aaaabbb\n",
      "     ('a', 'aaabbb')\n",
      "     ('aaaabb', 'b')\n",
      "            this is a potential ('0', '5')\n",
      "     ('aaa', 'abbb')\n",
      "     ('aaaab', 'bb')\n",
      "     ('aa', 'aabbb')\n",
      "     ('aaaa', 'bbb')\n",
      "finished all messages, returning dict\n"
     ]
    }
   ],
   "source": [
    "grammar = {'0': (('4', '1', '5'),),\n",
    " '1': (('2', '3'), ('3', '2')),\n",
    " '2': (('4', '4'), ('5', '5')),\n",
    " '3': (('4', '5'), ('5', '4')),\n",
    " '4': (('a',),),\n",
    " '5': (('b',),)}\n",
    "\n",
    "messages = ['ababbb', 'bababa', 'abbbab', 'aaabbb', 'aaaabbb']\n",
    "cfg = CFG(grammar, terminals = {'a', 'b'})\n",
    "out = cfg.solve(messages)\n",
    "assert sum([1 for m in messages if (m in out) and ('0' in out[m])]) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(('num', '+', 'term')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('.aocenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a292fecb04ead1807198b22395dbb599f43710a25b8e4823a30fedd04cdfd0f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
