{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datascience\n",
    "from nbdev import *\n",
    "from nbdev.showdoc import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advent of Code Utils\n",
    "\n",
    "> A collection of somewhat handy functions to make your AoC puzzle life solving a bit easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from collections.abc import Iterable\n",
    "from collections import namedtuple, deque\n",
    "import contextlib\n",
    "from functools import reduce\n",
    "import hashlib\n",
    "import heapq\n",
    "import logging\n",
    "from math import sqrt, gcd\n",
    "from pathlib import Path\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data science helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-bd3c0ba8cb98>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-13-bd3c0ba8cb98>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    elif str(path).endswith(\"tgz\"):\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "def untar_data(path, save_dir = None):\n",
    "    # will untar a file to save dir or the directory of path\n",
    "    if isinstance(path,Path):\n",
    "        if str(path).endswith(\"tgz\"):\n",
    "            tar = tarfile.open(fname, \"r:gz\")\n",
    "        else:\n",
    "            tar = open(path)\n",
    "        tar.extractall(save_dir) if save_dir else tar.extractall(path.parent)\n",
    "        tar.close()\n",
    "    else:\n",
    "        print('argument should be Path instance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "@contextlib.contextmanager\n",
    "def timeit(description=None):\n",
    "    # usage: with timeit('description') do what you like\n",
    "    # will output the time taken in seconds\n",
    "    tstart = time.time()\n",
    "    yield\n",
    "    elapsed = (time.time() - tstart)/60\n",
    "    logging.info(f'{description}, time: {elapsed}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def load(filename):\n",
    "    f = open(filename,\"rb\")\n",
    "    return pickle.load(f)\n",
    "    \n",
    "def save(data, filename):\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def nan_inspect(df):\n",
    "    # will return some sort or correlation matrix\n",
    "    # this helps to quickly see where the na values are and if they are shared with multiple columns\n",
    "    print(df.isnull().sum(axis=1).value_counts(sort=False))\n",
    "    df_len = len(df)\n",
    "    df = df.isna().copy()\n",
    "    df = df.loc[:, (df != 0).any(axis=0)]\n",
    "    df = df.loc[(df!=0).any(1)]\n",
    "    df_nan_dict = {c : [len(df.loc[df[c] & df[c2]]) for c2 in df.columns] for c in df.columns}\n",
    "    df_nan = pd.DataFrame.from_dict(df_nan_dict)\n",
    "    df_nan.set_index(df.columns, inplace=True)\n",
    "    df_nan.insert(0, 'total', df_nan.max(axis=0))\n",
    "    df_nan.sort_values('total', inplace=True, ascending=False)\n",
    "    df_nan = pd.concat([df_nan['total'] , df_nan.iloc[:,1:][list(df_nan.index)]],axis=1)\n",
    "    return (df_nan/df_len).round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
