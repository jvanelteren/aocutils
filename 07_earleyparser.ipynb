{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp cfg\n",
    "from nbdev import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earley Parser\n",
    "\n",
    "> Parses it earley style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from collections import defaultdict\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chart[0]\n",
      "S0 gamma -> \\bullet S  [0, 0] [] dummy start state\n",
      "S1 S -> \\bullet NP VP  [0, 0] [] predictor\n",
      "S2 S -> \\bullet Aux NP VP  [0, 0] [] predictor\n",
      "S3 S -> \\bullet VP  [0, 0] [] predictor\n",
      "S4 NP -> \\bullet Det Nominal  [0, 0] [] predictor\n",
      "S5 NP -> \\bullet Proper-Noun  [0, 0] [] predictor\n",
      "S6 VP -> \\bullet Verb  [0, 0] [] predictor\n",
      "S7 VP -> \\bullet Verb NP  [0, 0] [] predictor\n",
      "\n",
      "Chart[1]\n",
      "S8 Verb -> book \\bullet [0, 1] [] scanner\n",
      "S9 VP -> Verb \\bullet [0, 1] [8] completer\n",
      "S10 VP -> Verb \\bullet NP  [0, 1] [8] completer\n",
      "S11 S -> VP \\bullet [0, 1] [9] completer\n",
      "S12 NP -> \\bullet Det Nominal  [1, 1] [] predictor\n",
      "S13 NP -> \\bullet Proper-Noun  [1, 1] [] predictor\n",
      "\n",
      "Chart[2]\n",
      "S14 Det -> that \\bullet [1, 2] [] scanner\n",
      "S15 NP -> Det \\bullet Nominal  [1, 2] [14] completer\n",
      "S16 Nominal -> \\bullet Noun  [2, 2] [] predictor\n",
      "S17 Nominal -> \\bullet Noun Nominal  [2, 2] [] predictor\n",
      "\n",
      "Chart[3]\n",
      "S18 Noun -> flight \\bullet [2, 3] [] scanner\n",
      "S19 Nominal -> Noun \\bullet [2, 3] [18] completer\n",
      "S20 Nominal -> Noun \\bullet Nominal  [2, 3] [18] completer\n",
      "S21 NP -> Det Nominal \\bullet [1, 3] [14, 19] completer\n",
      "S22 Nominal -> \\bullet Noun  [3, 3] [] predictor\n",
      "S23 Nominal -> \\bullet Noun Nominal  [3, 3] [] predictor\n",
      "S24 VP -> Verb NP \\bullet [0, 3] [8, 21] completer\n",
      "S25 Nominal -> Noun Nominal \\bullet [2, 3] [18, 22] completer\n",
      "S26 S -> VP \\bullet [0, 3] [24] completer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class State(object):\n",
    "    def __init__(self, label, rules, dot_idx, start_idx, end_idx, idx, made_from, producer):\n",
    "        self.label = label\n",
    "        self.rules = rules\n",
    "        self.dot_idx = dot_idx\n",
    "        self.start_idx = start_idx\n",
    "        self.end_idx = end_idx\n",
    "        self.idx = idx\n",
    "        self.made_from = made_from\n",
    "        self.producer = producer\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"Returns the tag after the dot\"\"\"\n",
    "        return self.rules[self.dot_idx]\n",
    "\n",
    "    def complete(self):\n",
    "        return len(self.rules) == self.dot_idx\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.label == other.label and\n",
    "                self.rules == other.rules and\n",
    "                self.dot_idx == other.dot_idx and\n",
    "                self.start_idx == other.start_idx and\n",
    "                self.end_idx == other.end_idx)\n",
    "\n",
    "    def __str__(self):\n",
    "        rule_string = ''\n",
    "        for i, rule in enumerate(self.rules):\n",
    "            if i == self.dot_idx:\n",
    "                rule_string += '\\\\bullet '\n",
    "            rule_string += rule + ' '\n",
    "        if self.dot_idx == len(self.rules):\n",
    "            rule_string += '\\\\bullet'\n",
    "        return 'S%d %s -> %s [%d, %d] %s %s' % (self.idx, self.label, rule_string, self.start_idx, \n",
    "                                                self.end_idx, self.made_from, self.producer)\n",
    "\n",
    "class Earley:\n",
    "    def __init__(self, words, grammar, terminals):\n",
    "        self.chart = [[] for _ in range(len(words) + 1)]\n",
    "        self.current_id = 0\n",
    "        self.words = words\n",
    "        self.grammar = grammar\n",
    "        self.terminals = terminals\n",
    "\n",
    "    def get_new_id(self):\n",
    "        self.current_id += 1\n",
    "        return self.current_id - 1\n",
    "\n",
    "    def is_terminal(self, tag):\n",
    "        return tag in self.terminals\n",
    "\n",
    "    def is_complete(self, state):\n",
    "        return len(state.rules) == state.dot_idx\n",
    "\n",
    "    def enqueue(self, state, chart_entry):\n",
    "        if state not in self.chart[chart_entry]:\n",
    "            self.chart[chart_entry].append(state)\n",
    "        else:\n",
    "            self.current_id -= 1\n",
    "\n",
    "    def predictor(self, state):\n",
    "        for production in self.grammar[state.next()]:\n",
    "            self.enqueue(State(state.next(), production, 0, state.end_idx, state.end_idx, self.get_new_id(), [], 'predictor'), state.end_idx)\n",
    "\n",
    "    def scanner(self, state):\n",
    "        if self.words[state.end_idx] in self.grammar[state.next()]:\n",
    "            self.enqueue(State(state.next(), [self.words[state.end_idx]], 1, state.end_idx, state.end_idx + 1, self.get_new_id(), [], 'scanner'), state.end_idx + 1)\n",
    "\n",
    "    def completer(self, state):\n",
    "        for s in self.chart[state.start_idx]:\n",
    "            if not s.complete() and s.next() == state.label and s.end_idx == state.start_idx and s.label != 'gamma':\n",
    "                self.enqueue(State(s.label, s.rules, s.dot_idx + 1, s.start_idx, state.end_idx, self.get_new_id(), s.made_from + [state.idx], 'completer'), state.end_idx)\n",
    "\n",
    "    def parse(self):\n",
    "        self.enqueue(State('gamma', ['S'], 0, 0, 0, self.get_new_id(), [], 'dummy start state'), 0)\n",
    "        \n",
    "        for i in range(len(self.words) + 1):\n",
    "            for state in self.chart[i]:\n",
    "                if not state.complete() and not self.is_terminal(state.next()):\n",
    "                    self.predictor(state)\n",
    "                elif i != len(self.words) and not state.complete() and self.is_terminal(state.next()):\n",
    "                    self.scanner(state)\n",
    "                else:\n",
    "                    self.completer(state)\n",
    "\n",
    "    def __str__(self):\n",
    "        res = ''\n",
    "        \n",
    "        for i, chart in enumerate(self.chart):\n",
    "            res += '\\nChart[%d]\\n' % i\n",
    "            for state in chart:\n",
    "                res += str(state) + '\\n'\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "def test():\n",
    "    grammar = {\n",
    "        'S':           [['NP', 'VP'], ['Aux', 'NP', 'VP'], ['VP']],\n",
    "        'NP':          [['Det', 'Nominal'], ['Proper-Noun']],\n",
    "        'Nominal':     [['Noun'], ['Noun', 'Nominal']],\n",
    "        'VP':          [['Verb'], ['Verb', 'NP']],\n",
    "        'Det':         ['that', 'this', 'a'],\n",
    "        'Noun':        ['book', 'flight', 'meal', 'money'],\n",
    "        'Verb':        ['book', 'include', 'prever'],\n",
    "        'Aux':         ['does'],\n",
    "        'Prep':        ['from', 'to', 'on'],\n",
    "        'Proper-Noun': ['Houston', 'TWA']\n",
    "    }\n",
    "    terminals = ['Det', 'Noun', 'Verb', 'Aux', 'Prep', 'Proper-Noun']\n",
    "\n",
    "    earley = Earley(['book', 'that', 'flight'], grammar, terminals)\n",
    "    earley.parse()\n",
    "    print(earley)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from collections import UserDict\n",
    "class StateDict(UserDict):\n",
    "    def __repr__(self):\n",
    "        pos = self.get('position')\n",
    "        output = f\"symbol {self.get('symbol'):<4}: {str(self.get('rule')[:pos]):<15} â€¢ {str(self.get('rule')[pos:]):<30} {'idx('}{self.get('startidx')}) {'Done' if self.get('completed') else ''})\"\n",
    "        return output\n",
    "    def __hash__(self):\n",
    "        return hash(''.join([str(v) for k,v in self.data.items()]))\n",
    "\n",
    "def genstate(symbol, rule, idx):\n",
    "    return StateDict({'symbol': symbol,\n",
    "            'rule': rule,\n",
    "            'startidx': idx,\n",
    "            'position': 0,\n",
    "            'steps': len(rule),\n",
    "            'completed': False})\n",
    "            # 'steps': len(rule)}\n",
    "\n",
    "def predict(column, colidx, symbol):\n",
    "    seen = {symbol} # otherwise you can have infinite loop when recursively adding\n",
    "    toadd = {symbol}\n",
    "    while toadd:\n",
    "        cur = toadd.pop()\n",
    "        \n",
    "        for rule in grammar.get(cur, []):\n",
    "            newstate = genstate(cur, rule, colidx)\n",
    "            column.add(newstate)\n",
    "            if (recursivesymbol := newstate['rule'][0]) not in seen:\n",
    "                toadd.add(recursivesymbol)\n",
    "\n",
    "def scan(column, parsedchar):\n",
    "    # we are scanning the states in a column to check if we can advance\n",
    "    advancedstates = []\n",
    "    for state in column:\n",
    "        if not state['completed']:\n",
    "            # print(state, parsedchar, state['rule'][0])\n",
    "            if state['rule'][state['position']] == parsedchar:\n",
    "                state = state.copy() # nasty bug, make sure to copy the state, otherwise you change the old state inplace and have the possibility to advance multiple positions during 1 character!\n",
    "                state['position'] += 1\n",
    "                if state['position'] == state['steps']:\n",
    "                    state['completed'] = True\n",
    "                advancedstates.append(state)\n",
    "    return advancedstates\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# pprint(cols[0])\n",
    "def parse(grammar, message, start):\n",
    "    cols = [set() for _ in range(len(message)+1)]\n",
    "    predict(cols[0], 0, start)\n",
    "    for colidx in range(1, len(message)+1): # we just populated the 0th col, now the first character has colidx 1\n",
    "        # print(colidx, message[colidx-1])\n",
    "        advancedstates = scan(cols[colidx-1], message[colidx-1])\n",
    "        # print('characted:', message[colidx-1], ':we have advanced on', [s['symbol'] for s in advancedstates])\n",
    "        \n",
    "        # check if any of the states are completed, if yes do scan again (loop untill nothing is completed)\n",
    "        while advancedstates:\n",
    "            advancedstate = advancedstates.pop()\n",
    "            cols[colidx].add(advancedstate)\n",
    "            if advancedstate['completed']:\n",
    "                # print('we have completion', advancedstate['symbol'])\n",
    "                # do scan again, looking to advance other states based on the symbol of the completed rule\n",
    "                toadd = scan(cols[advancedstate['startidx']], advancedstate['symbol'])\n",
    "                for newadvancedstate in toadd:\n",
    "                    advancedstates.append(newadvancedstate)\n",
    "            else:\n",
    "                # predict new states based on the next expected symbol in the rule\n",
    "                predict(cols[colidx], colidx, advancedstate['rule'][advancedstate['position']])\n",
    "        # pprint(cols[colidx])\n",
    "\n",
    "    for state in cols[colidx]:\n",
    "        if state['completed'] and state['startidx'] == 0 and state['symbol'] == start:\n",
    "            return True #('valid')\n",
    "    else:\n",
    "        return False\n",
    "# messages = ['ababbb', 'bababa', 'abbbab', 'aaabbb', 'aaaabbb']\n",
    "# message = messages[2]\n",
    "m = 'babbaaaabbbbbbabaaaaabbb'\n",
    "# message = 'babbaaaa'\n",
    "# message = 'aaaabb'\n",
    "# # message = 'aab'\n",
    "# start = '60'\n",
    "# # start = '16'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://adventofcode.com/2020/day/19\n",
    "rules, messages = open('cfgloop.txt').read().split('\\n\\n')\n",
    "grammar = {}\n",
    "\n",
    "for rule in rules.split('\\n'):\n",
    "    num, makefrom = rule.split(': ')\n",
    "    makefrom = makefrom.replace('\"', '')\n",
    "    makefrom = tuple(makefrom.split(' | '))\n",
    "    makefrom = tuple(tuple(option.split()) for option in makefrom)\n",
    "    grammar[num] = makefrom\n",
    "    \n",
    "messages = messages.split('\\n')\n",
    "s = '0'\n",
    "ans = 0\n",
    "for m in messages:\n",
    "    ans += parse(grammar, m,s)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C',\n",
       " 'Rn',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'B',\n",
       " 'P',\n",
       " 'Ti',\n",
       " 'Mg',\n",
       " 'Ar',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Mg',\n",
       " 'Ar',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Ca',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ti',\n",
       " 'Ti',\n",
       " 'B',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'F',\n",
       " 'Y',\n",
       " 'Ca',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'P',\n",
       " 'B',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'P',\n",
       " 'Ti',\n",
       " 'Rn',\n",
       " 'P',\n",
       " 'B',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Mg',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'P',\n",
       " 'Ti',\n",
       " 'B',\n",
       " 'P',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'B',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Ca',\n",
       " 'P',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'P',\n",
       " 'Mg',\n",
       " 'Y',\n",
       " 'Ca',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'P',\n",
       " 'Ti',\n",
       " 'Ti',\n",
       " 'Ti',\n",
       " 'B',\n",
       " 'P',\n",
       " 'B',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'P',\n",
       " 'Ti',\n",
       " 'B',\n",
       " 'P',\n",
       " 'B',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'B',\n",
       " 'P',\n",
       " 'B',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Ca',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'B',\n",
       " 'P',\n",
       " 'Rn',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Rn',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'B',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'P',\n",
       " 'B',\n",
       " 'P',\n",
       " 'Ti',\n",
       " 'Ti',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'P',\n",
       " 'Ti',\n",
       " 'B',\n",
       " 'Si',\n",
       " 'Al',\n",
       " 'Ar',\n",
       " 'P',\n",
       " 'B',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Mg',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Ca',\n",
       " 'F',\n",
       " 'Y',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Y',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Y',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'B',\n",
       " 'P',\n",
       " 'Mg',\n",
       " 'Ar',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'P',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ti',\n",
       " 'Rn',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Y',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'B',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Ti',\n",
       " 'Mg',\n",
       " 'Ar',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'P',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Ti',\n",
       " 'Ti',\n",
       " 'Ti',\n",
       " 'Ti',\n",
       " 'B',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Ca',\n",
       " 'Ca',\n",
       " 'F',\n",
       " 'Y',\n",
       " 'F',\n",
       " 'Ar',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'P',\n",
       " 'Ti',\n",
       " 'B',\n",
       " 'P',\n",
       " 'Ti',\n",
       " 'B',\n",
       " 'Ca',\n",
       " 'Si',\n",
       " 'Th',\n",
       " 'Si',\n",
       " 'Rn',\n",
       " 'Mg',\n",
       " 'Ar',\n",
       " 'Ca',\n",
       " 'F']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# https://adventofcode.com/2015/day/19\n",
    "rules, mol = open('cfg2.txt', 'r').read().split('\\n\\n')\n",
    "newrules = defaultdict(set)\n",
    "counter = 1\n",
    "for line in rules.splitlines():\n",
    "    first, second = line.split(' => ')\n",
    "    molecules = tuple(re.findall('[A-Z][^A-Z]*', second))\n",
    "    newrules[first].add(molecules)\n",
    "\n",
    "mollie = []\n",
    "prev = ''\n",
    "for ch in mol:\n",
    "    if ch.islower():\n",
    "        prev += ch\n",
    "    else:\n",
    "        if prev:\n",
    "            mollie.append(prev)\n",
    "        prev = ch\n",
    "    \n",
    "mollie.append(prev)\n",
    "mollie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse(newrules, mollie, 'e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('.aocenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a292fecb04ead1807198b22395dbb599f43710a25b8e4823a30fedd04cdfd0f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
